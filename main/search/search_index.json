{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":""},{"location":"#overview","title":"Overview","text":"<p><code>startorch</code> is a Python library to generate synthetic time-series. As the name suggest, <code>startorch</code> relies mostly on PyTorch to generate the time series and to control the randomness. <code>startorch</code> is built to be modular, flexible and extensible. For example, it is easy to combine multiple core sequence generator to generate complex sequences. The user is responsible to define the recipe to generate the time series. Below show some generated sequences by <code>startorch</code> where the values are sampled from different distribution.</p> uniform log-uniform sine wave Wiener process"},{"location":"#motivation","title":"Motivation","text":"<p>Collecting datasets to train Machine Learning models can be time consuming. Another alternative is to use synthetic datasets. <code>startorch</code> provides modules to easily generate synthetic time series. The user is responsible to define the recipe to generate the time series. The following example shows how to generate a sequence where the values are sampled from a Normal distribution.</p> <pre><code>from startorch.sequence import RandNormal\n\ngenerator = RandNormal(mean=0.0, std=1.0)\nbatch = generator.generate(seq_len=128, batch_size=4)\n</code></pre> <p>It is possible to combine multiple generators to build a more complex generator. The example below shows how to build a generator that sums multiple the output of three sine wave generators.</p> <pre><code>from startorch.sequence import (\n    Add,\n    Arange,\n    Constant,\n    RandLogUniform,\n    RandUniform,\n    SineWave,\n)\n\ngenerator = Add(\n    (\n        SineWave(\n            value=Arange(),\n            frequency=Constant(RandLogUniform(low=0.01, high=0.1)),\n            phase=Constant(RandUniform(low=-1.0, high=1.0)),\n            amplitude=Constant(RandLogUniform(low=0.1, high=1.0)),\n        ),\n        SineWave(\n            value=Arange(),\n            frequency=Constant(RandLogUniform(low=0.01, high=0.1)),\n            phase=Constant(RandUniform(low=-1.0, high=1.0)),\n            amplitude=Constant(RandLogUniform(low=0.1, high=1.0)),\n        ),\n        SineWave(\n            value=Arange(),\n            frequency=Constant(RandLogUniform(low=0.01, high=0.1)),\n            phase=Constant(RandUniform(low=-1.0, high=1.0)),\n            amplitude=Constant(RandLogUniform(low=0.1, high=1.0)),\n        ),\n    )\n)\nbatch = generator.generate(seq_len=128, batch_size=4)\n</code></pre>"},{"location":"#api-stability","title":"API stability","text":"<p> While <code>startorch</code> is in development stage, no API is guaranteed to be stable from one release to the next. In fact, it is very likely that the API will change multiple times before a stable 1.0.0 release. In practice, this means that upgrading <code>startorch</code> to a new version will possibly break any code that was using the old version of <code>startorch</code>.</p>"},{"location":"#license","title":"License","text":"<p><code>startorch</code> is licensed under BSD 3-Clause \"New\" or \"Revised\" license available in LICENSE file.</p>"},{"location":"get_started/","title":"Get Started","text":"<p>It is highly recommended to install in a virtual environment to keep your system in order.</p>"},{"location":"get_started/#installing-with-pip-recommended","title":"Installing with <code>pip</code> (recommended)","text":"<p>The following command installs the latest version of the library:</p> <pre><code>pip install startorch\n</code></pre> <p>To make the package as slim as possible, only the packages required to use <code>startorch</code> are installed. It is possible to install all the optional dependencies by running the following command:</p> <pre><code>pip install 'startorch[all]'\n</code></pre> <p>This command also install all the optional packages like matplotlib. It is also possible to install the optional packages manually or to select the packages to install. In the following example, only matplotlib is installed:</p> <pre><code>pip install startorch matplotlib\n</code></pre>"},{"location":"get_started/#installing-from-source","title":"Installing from source","text":"<p>To install <code>startorch</code> from source, you can follow the steps below. First, you will need to install <code>poetry</code>. <code>poetry</code> is used to manage and install the dependencies. If <code>poetry</code> is already installed on your machine, you can skip this step. There are several ways to install <code>poetry</code> so you can use the one that you prefer. You can check the <code>poetry</code> installation by running the following command:</p> <pre><code>poetry --version\n</code></pre> <p>Then, you can clone the git repository:</p> <pre><code>git clone git@github.com:durandtibo/startorch.git\n</code></pre> <p>It is recommended to create a Python 3.8+ virtual environment. This step is optional so you can skip it. To create a virtual environment, you can use the following command:</p> <pre><code>make conda\n</code></pre> <p>It automatically creates a conda virtual environment. When the virtual environment is created, you can activate it with the following command:</p> <pre><code>conda activate startorch\n</code></pre> <p>This example uses <code>conda</code> to create a virtual environment, but you can use other tools or configurations. Then, you should install the required package to use <code>startorch</code> with the following command:</p> <pre><code>make install\n</code></pre> <p>This command will install all the required packages. You can also use this command to update the required packages. This command will check if there is a more recent package available and will install it. Finally, you can test the installation with the following command:</p> <pre><code>make unit-test-cov\n</code></pre>"},{"location":"sequence/","title":"Sequence","text":"<p> This page is a quick overview of how to use sequence generators, and how to implement custom sequence generators. This page does not present the implementation of the builtin sequence generators.</p>"},{"location":"sequence/#introduction","title":"Introduction","text":"<p>The main objects to generate synthetic sequences are the sequence generators. The API of the sequence generator is defined in <code>BaseSequenceGenerator</code>. Note that <code>startorch</code> generates sequences by batch to be more efficient. It is not possible to generate a single sequence, but it is possible to generate a batch of one sequence.</p>"},{"location":"sequence/#builtin-sequence-generators","title":"Builtin sequence generators","text":"<p><code>startorch</code> has a lot of builtin sequence generators. Below is a non-exhaustive list of the sequence generators:</p> <ul> <li><code>Abs</code></li> <li><code>Acosh</code></li> <li><code>Add</code></li> <li><code>AddScalar</code></li> <li><code>Arange</code></li> <li><code>Asinh</code></li> <li><code>AsinhUniform</code></li> <li><code>Atanh</code></li> <li><code>AutoRegressive</code></li> <li><code>Cat2</code></li> <li><code>Cauchy</code></li> <li><code>Clamp</code></li> <li><code>Constant</code></li> <li><code>Cosh</code></li> <li><code>Cumsum</code></li> <li><code>Div</code></li> <li><code>Exp</code></li> <li><code>Exponential</code></li> <li><code>Float</code></li> <li><code>Fmod</code></li> <li><code>Full</code></li> <li><code>HalfCauchy</code></li> <li><code>HalfNormal</code></li> <li><code>Linear</code></li> <li><code>Log</code></li> <li><code>LogNormal</code></li> <li><code>LogUniform</code></li> <li><code>Long</code></li> <li><code>Mul</code></li> <li><code>MulScalar</code></li> <li><code>Multinomial</code></li> <li><code>MultinomialChoice</code></li> <li><code>Neg</code></li> <li><code>Normal</code></li> <li><code>Poisson</code></li> <li><code>RandAsinhUniform</code></li> <li><code>RandCauchy</code></li> <li><code>RandExponential</code></li> <li><code>RandHalfCauchy</code></li> <li><code>RandHalfNormal</code></li> <li><code>RandInt</code></li> <li><code>RandLogNormal</code></li> <li><code>RandLogUniform</code></li> <li><code>RandNormal</code></li> <li><code>RandPoisson</code></li> <li><code>RandTruncCauchy</code></li> <li><code>RandTruncExponential</code></li> <li><code>RandTruncHalfCauchy</code></li> <li><code>RandTruncHalfNormal</code></li> <li><code>RandTruncLogNormal</code></li> <li><code>RandTruncNormal</code></li> <li><code>RandUniform</code></li> <li><code>RandWienerProcess</code></li> <li><code>SineWave</code></li> <li><code>Sinh</code></li> <li><code>Sort</code></li> <li><code>Sqrt</code></li> <li><code>Sub</code></li> <li><code>Tanh</code></li> <li><code>TensorSequence</code></li> <li><code>Time</code></li> <li><code>TruncCauchy</code></li> <li><code>TruncExponential</code></li> <li><code>TruncHalfCauchy</code></li> <li><code>TruncHalfNormal</code></li> <li><code>TruncLogNormal</code></li> <li><code>TruncNormal</code></li> <li><code>Uniform</code></li> <li><code>UniformCategorical</code></li> </ul> <p>These builtin sequence generators can been seen as basic blocks to generate sequences, or to build more complex sequence generators.</p>"},{"location":"sequence/#generate-a-batch-of-sequences","title":"Generate a batch of sequences","text":"<p>This section shows how to use a sequence generator to generate a batch of sequences. Let's assume we want to generate a batch of sequences where the value are sampled from a uniform distribution <code>U[-5, 5]</code>. This can be easily done with <code>startorch</code> by writing the following lines.</p> <pre><code>from startorch.sequence import RandUniform\n\ngenerator = RandUniform(low=-5, high=5)\nprint(generator.generate(seq_len=6, batch_size=2))\n</code></pre> <p>Output:</p> <pre><code>tensor([[[ 2.6437],\n         [ 2.1046],\n         [ 3.9529],\n         [-2.9899],\n         [ 3.6624],\n         [-3.8132]],\n\n        [[ 1.9843],\n         [ 3.1455],\n         [ 3.2380],\n         [ 1.3003],\n         [ 1.0235],\n         [-4.7955]]])\n</code></pre> <p><code>seq_len</code> controls the sequence length and <code>batch_size</code> controls the number of sequences in the batch.</p>"},{"location":"sequence/#combining-sequence-generators","title":"Combining sequence generators","text":"<p>A lot of the builtin sequence generators and modular and can be combined to build more complex sequence generators. The following example shows how to build a sequence generator that sums the outputs of three sine wave sequence generators.</p> <pre><code>from startorch.sequence import (\n    Add,\n    Arange,\n    Constant,\n    RandLogUniform,\n    RandUniform,\n    SineWave,\n)\n\ngenerator = Add(\n    (\n        SineWave(\n            value=Arange(),\n            frequency=Constant(RandLogUniform(low=0.01, high=0.1)),\n            phase=Constant(RandUniform(low=-1.0, high=1.0)),\n            amplitude=Constant(RandLogUniform(low=0.1, high=1.0)),\n        ),\n        SineWave(\n            value=Arange(),\n            frequency=Constant(RandLogUniform(low=0.01, high=0.1)),\n            phase=Constant(RandUniform(low=-1.0, high=1.0)),\n            amplitude=Constant(RandLogUniform(low=0.1, high=1.0)),\n        ),\n        SineWave(\n            value=Arange(),\n            frequency=Constant(RandLogUniform(low=0.01, high=0.1)),\n            phase=Constant(RandUniform(low=-1.0, high=1.0)),\n            amplitude=Constant(RandLogUniform(low=0.1, high=1.0)),\n        ),\n    )\n)\nbatch = generator.generate(seq_len=128, batch_size=4)\n</code></pre>"},{"location":"sequence/#randomness","title":"Randomness","text":"<p>It is possible to control the randomness of the sequence generators to make the process reproducible. A <code>torch.Generator</code> object is used to control the randomness. The following example shows how to generate the same batch of sequences.</p> <pre><code>from startorch.sequence import RandUniform\nfrom startorch.utils.seed import get_torch_generator\n\ngenerator = RandUniform(feature_size=())\nprint(generator.generate(seq_len=6, batch_size=2, rng=get_torch_generator(1)))\nprint(generator.generate(seq_len=6, batch_size=2, rng=get_torch_generator(1)))\n</code></pre> <p>Output:</p> <pre><code>tensor([[0.7576, 0.2793, 0.4031, 0.7347, 0.0293, 0.7999],\n        [0.3971, 0.7544, 0.5695, 0.4388, 0.6387, 0.5247]])\ntensor([[0.7576, 0.2793, 0.4031, 0.7347, 0.0293, 0.7999],\n        [0.3971, 0.7544, 0.5695, 0.4388, 0.6387, 0.5247]])\n</code></pre> <p>The two generated tensors have the same values.</p>"},{"location":"sequence/#how-to-implement-a-sequence-generator","title":"How to implement a sequence generator","text":"<p>This section explains how to implement a custom sequence generator. <code>startorch</code> has a lot of builtin sequence generator but it is possible to implement custom sequence generators. A custom sequence generator has to follow the API defined in <code>BaseSequenceGenerator</code>.</p> <p>Let's assume we want to generate a sequence generator that returns sequence filled with only the number 42. The following piece of code shows how to implement this sequence generator.</p> <pre><code>from __future__ import annotations\n\nimport torch\n\nfrom startorch.sequence import BaseSequenceGenerator\nfrom startorch.utils.conversion import to_tuple\n\n\nclass FortyTwoSequenceGenerator(BaseSequenceGenerator):\n    def __init__(\n        self,\n        feature_size: tuple[int, ...] | list[int] | int = 1,\n    ) -&gt; None:\n        super().__init__()\n        self._feature_size = to_tuple(feature_size)\n\n    def __repr__(self) -&gt; str:  # This method is optional but nice to have\n        return f\"{self.__class__.__qualname__}(feature_size={self._feature_size})\"\n\n    def generate(\n        self, seq_len: int, batch_size: int = 1, rng: torch.Generator | None = None\n    ) -&gt; torch.Tensor:\n        return torch.full((batch_size, seq_len) + self._feature_size, 42.0)\n\n\ngenerator = FortyTwoSequenceGenerator(feature_size=())\nprint(generator)\nprint(generator.generate(seq_len=6, batch_size=2))\n</code></pre> <p>Output:</p> <pre><code>FortyTwoSequenceGenerator(feature_size=())\ntensor([[42., 42., 42., 42., 42., 42.],\n        [42., 42., 42., 42., 42., 42.]])\n</code></pre> <p>This implementation allows to configure the feature size.</p>"},{"location":"sequence/#naming-conventions","title":"Naming conventions","text":"<p><code>RandXXX</code> indicates a standalone sequence generator i.e. a sequence generator that does not require sequence generators as input to work. For example, <code>RandUniform</code> is the standalone version of <code>Uniform</code>. <code>Uniform</code> allows to build more complex sequence generators but it can be more difficult to use because it has more parameters to configure.</p> <ul> <li><code>RandUniform</code> example</li> </ul> <pre><code>from startorch.sequence import RandUniform\n\ngenerator = RandUniform(low=-5, high=5)\ngenerator.generate(seq_len=128, batch_size=4)\n</code></pre> <ul> <li><code>Uniform</code> example</li> </ul> <pre><code>from startorch.sequence import RandUniform, Uniform\n\ngenerator = Uniform(low=RandUniform(-1.0, 0.0), high=RandUniform(0.0, 1.0))\ngenerator.generate(seq_len=128, batch_size=4)\n</code></pre> <p><code>TruncXXX</code> indicates the sequence generator sampled value from a truncated distribution. For example, <code>RandTruncCauchy</code> samples values from a truncated Cauchy distribution whereas <code>RandCauchy</code> samples values from a Cauchy distribution.</p> <ul> <li><code>RandCauchy</code> example</li> </ul> <pre><code>from startorch.sequence import RandCauchy\n\ngenerator = RandCauchy()\ngenerator.generate(seq_len=128, batch_size=4)\n</code></pre> <ul> <li><code>RandTruncCauchy</code> example</li> </ul> <pre><code>from startorch.sequence import RandTruncCauchy\n\ngenerator = RandTruncCauchy()\ngenerator.generate(seq_len=128, batch_size=4)\n</code></pre>"},{"location":"refs/example/","title":"example","text":""},{"location":"refs/example/#startorch.example","title":"startorch.example","text":"<p>Contain example generators.</p>"},{"location":"refs/example/#startorch.example.BaseExampleGenerator","title":"startorch.example.BaseExampleGenerator","text":"<p>               Bases: <code>Generic[T]</code>, <code>ABC</code></p> <p>Define the base class to generate examples.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.example import HypercubeClassification\n&gt;&gt;&gt; generator = HypercubeClassification(num_classes=5, feature_size=6)\n&gt;&gt;&gt; generator\nHypercubeClassificationExampleGenerator(num_classes=5, feature_size=6, noise_std=0.2)\n&gt;&gt;&gt; batch = generator.generate(batch_size=10)\n&gt;&gt;&gt; batch\n{'target': tensor([...]), 'feature': tensor([[...]])}\n</code></pre>"},{"location":"refs/example/#startorch.example.BaseExampleGenerator.generate","title":"startorch.example.BaseExampleGenerator.generate  <code>abstractmethod</code>","text":"<pre><code>generate(\n    batch_size: int = 1, rng: Generator | None = None\n) -&gt; dict[Hashable, Tensor]\n</code></pre> <p>Generate a batch of examples.</p> <p>Parameters:</p> Name Type Description Default <code>batch_size</code> <code>int</code> <p>The batch size.</p> <code>1</code> <code>rng</code> <code>Generator | None</code> <p>An optional random number generator.</p> <code>None</code> <p>Returns:</p> Type Description <code>dict[Hashable, Tensor]</code> <p>A batch of examples.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.example import HypercubeClassification\n&gt;&gt;&gt; generator = HypercubeClassification(num_classes=5, feature_size=6)\n&gt;&gt;&gt; batch = generator.generate(batch_size=10)\n&gt;&gt;&gt; batch\n{'target': tensor([...]), 'feature': tensor([[...]])}\n</code></pre>"},{"location":"refs/example/#startorch.example.BlobsClassification","title":"startorch.example.BlobsClassification","text":"<p>               Bases: <code>BaseExampleGenerator</code></p> <p>Implement a binary classification example generator where the data are generated from isotropic Gaussian blobs.</p> <p>The implementation is based on https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_blobs.html</p> <p>Parameters:</p> Name Type Description Default <code>centers</code> <code>Tensor</code> <p>The cluster centers used to generate the examples. It must be a float tensor of shape <code>(num_clusters, feature_size)</code>.</p> required <code>cluster_std</code> <code>Tensor | float</code> <p>The standard deviation of the clusters. It must be a float tensor of shape <code>(num_clusters, feature_size)</code>.</p> <code>1.0</code> <p>Raises:</p> Type Description <code>TypeError</code> <p>if one of the parameters has an invalid type.</p> <code>RuntimeError</code> <p>if one of the parameters is not valid.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; from startorch.example import BlobsClassification\n&gt;&gt;&gt; generator = BlobsClassification(torch.rand(5, 4))\n&gt;&gt;&gt; generator\nBlobsClassificationExampleGenerator(num_clusters=5, feature_size=4)\n&gt;&gt;&gt; batch = generator.generate(batch_size=10)\n&gt;&gt;&gt; batch\n{'target': tensor([...]), 'feature': tensor([[...]])}\n</code></pre>"},{"location":"refs/example/#startorch.example.BlobsClassification.centers","title":"startorch.example.BlobsClassification.centers  <code>property</code>","text":"<pre><code>centers: Tensor\n</code></pre> <p><code>torch.Tensor</code> of type float and shape <code>(num_clusters, feature_size)</code>: The cluster centers.</p>"},{"location":"refs/example/#startorch.example.BlobsClassification.cluster_std","title":"startorch.example.BlobsClassification.cluster_std  <code>property</code>","text":"<pre><code>cluster_std: Tensor\n</code></pre> <p><code>torch.Tensor</code> of type float and shape <code>(num_clusters, feature_size)</code>: The standard deviation for each cluster.</p>"},{"location":"refs/example/#startorch.example.BlobsClassification.feature_size","title":"startorch.example.BlobsClassification.feature_size  <code>property</code>","text":"<pre><code>feature_size: int\n</code></pre> <p>The feature size i.e. the number of features.</p>"},{"location":"refs/example/#startorch.example.BlobsClassification.num_clusters","title":"startorch.example.BlobsClassification.num_clusters  <code>property</code>","text":"<pre><code>num_clusters: int\n</code></pre> <p>The number of clusters i.e. categories.</p>"},{"location":"refs/example/#startorch.example.BlobsClassification.create_uniform_centers","title":"startorch.example.BlobsClassification.create_uniform_centers  <code>classmethod</code>","text":"<pre><code>create_uniform_centers(\n    num_clusters: int = 3,\n    feature_size: int = 2,\n    random_seed: int = 17532042831661189422,\n) -&gt; BlobsClassificationExampleGenerator\n</code></pre> <p>Instantiate a <code>BlobsClassificationExampleGenerator</code> where the centers are sampled from a uniform distribution.</p> <p>Parameters:</p> Name Type Description Default <code>num_clusters</code> <code>int</code> <p>The number of clusters.</p> <code>3</code> <code>feature_size</code> <code>int</code> <p>The feature size.</p> <code>2</code> <code>random_seed</code> <code>int</code> <p>The random seed used to generate the cluster centers.</p> <code>17532042831661189422</code> <p>Returns:</p> Type Description <code>BlobsClassificationExampleGenerator</code> <p>An instantiated example generator.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.example import BlobsClassification\n&gt;&gt;&gt; generator = BlobsClassification.create_uniform_centers()\n&gt;&gt;&gt; generator\nBlobsClassificationExampleGenerator(num_clusters=3, feature_size=2)\n&gt;&gt;&gt; batch = generator.generate(batch_size=10)\n&gt;&gt;&gt; batch\n{'target': tensor([...]), 'feature': tensor([[...]])}\n</code></pre>"},{"location":"refs/example/#startorch.example.BlobsClassificationExampleGenerator","title":"startorch.example.BlobsClassificationExampleGenerator","text":"<p>               Bases: <code>BaseExampleGenerator</code></p> <p>Implement a binary classification example generator where the data are generated from isotropic Gaussian blobs.</p> <p>The implementation is based on https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_blobs.html</p> <p>Parameters:</p> Name Type Description Default <code>centers</code> <code>Tensor</code> <p>The cluster centers used to generate the examples. It must be a float tensor of shape <code>(num_clusters, feature_size)</code>.</p> required <code>cluster_std</code> <code>Tensor | float</code> <p>The standard deviation of the clusters. It must be a float tensor of shape <code>(num_clusters, feature_size)</code>.</p> <code>1.0</code> <p>Raises:</p> Type Description <code>TypeError</code> <p>if one of the parameters has an invalid type.</p> <code>RuntimeError</code> <p>if one of the parameters is not valid.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; from startorch.example import BlobsClassification\n&gt;&gt;&gt; generator = BlobsClassification(torch.rand(5, 4))\n&gt;&gt;&gt; generator\nBlobsClassificationExampleGenerator(num_clusters=5, feature_size=4)\n&gt;&gt;&gt; batch = generator.generate(batch_size=10)\n&gt;&gt;&gt; batch\n{'target': tensor([...]), 'feature': tensor([[...]])}\n</code></pre>"},{"location":"refs/example/#startorch.example.BlobsClassificationExampleGenerator.centers","title":"startorch.example.BlobsClassificationExampleGenerator.centers  <code>property</code>","text":"<pre><code>centers: Tensor\n</code></pre> <p><code>torch.Tensor</code> of type float and shape <code>(num_clusters, feature_size)</code>: The cluster centers.</p>"},{"location":"refs/example/#startorch.example.BlobsClassificationExampleGenerator.cluster_std","title":"startorch.example.BlobsClassificationExampleGenerator.cluster_std  <code>property</code>","text":"<pre><code>cluster_std: Tensor\n</code></pre> <p><code>torch.Tensor</code> of type float and shape <code>(num_clusters, feature_size)</code>: The standard deviation for each cluster.</p>"},{"location":"refs/example/#startorch.example.BlobsClassificationExampleGenerator.feature_size","title":"startorch.example.BlobsClassificationExampleGenerator.feature_size  <code>property</code>","text":"<pre><code>feature_size: int\n</code></pre> <p>The feature size i.e. the number of features.</p>"},{"location":"refs/example/#startorch.example.BlobsClassificationExampleGenerator.num_clusters","title":"startorch.example.BlobsClassificationExampleGenerator.num_clusters  <code>property</code>","text":"<pre><code>num_clusters: int\n</code></pre> <p>The number of clusters i.e. categories.</p>"},{"location":"refs/example/#startorch.example.BlobsClassificationExampleGenerator.create_uniform_centers","title":"startorch.example.BlobsClassificationExampleGenerator.create_uniform_centers  <code>classmethod</code>","text":"<pre><code>create_uniform_centers(\n    num_clusters: int = 3,\n    feature_size: int = 2,\n    random_seed: int = 17532042831661189422,\n) -&gt; BlobsClassificationExampleGenerator\n</code></pre> <p>Instantiate a <code>BlobsClassificationExampleGenerator</code> where the centers are sampled from a uniform distribution.</p> <p>Parameters:</p> Name Type Description Default <code>num_clusters</code> <code>int</code> <p>The number of clusters.</p> <code>3</code> <code>feature_size</code> <code>int</code> <p>The feature size.</p> <code>2</code> <code>random_seed</code> <code>int</code> <p>The random seed used to generate the cluster centers.</p> <code>17532042831661189422</code> <p>Returns:</p> Type Description <code>BlobsClassificationExampleGenerator</code> <p>An instantiated example generator.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.example import BlobsClassification\n&gt;&gt;&gt; generator = BlobsClassification.create_uniform_centers()\n&gt;&gt;&gt; generator\nBlobsClassificationExampleGenerator(num_clusters=3, feature_size=2)\n&gt;&gt;&gt; batch = generator.generate(batch_size=10)\n&gt;&gt;&gt; batch\n{'target': tensor([...]), 'feature': tensor([[...]])}\n</code></pre>"},{"location":"refs/example/#startorch.example.Cache","title":"startorch.example.Cache","text":"<p>               Bases: <code>BaseExampleGenerator</code></p> <p>Implement an example generator that caches the last batch and returns it everytime a batch is generated.</p> <p>A new batch is generated only if the batch size changes.</p> <p>Parameters:</p> Name Type Description Default <code>generator</code> <code>BaseExampleGenerator | dict</code> <p>The example generator or its configuration.</p> required <code>deepcopy</code> <code>bool</code> <p>If <code>True</code>, the cached batch is deepcopied before to be return.</p> <code>False</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.example import Cache, SwissRoll\n&gt;&gt;&gt; generator = Cache(SwissRoll())\n&gt;&gt;&gt; generator\nCacheExampleGenerator(\n  (generator): SwissRollExampleGenerator(noise_std=0.0, spin=1.5, hole=False)\n  (deepcopy): False\n)\n&gt;&gt;&gt; batch = generator.generate(batch_size=10)\n&gt;&gt;&gt; batch\n{'target': tensor([...]), 'feature': tensor([[...]])}\n</code></pre>"},{"location":"refs/example/#startorch.example.CacheExampleGenerator","title":"startorch.example.CacheExampleGenerator","text":"<p>               Bases: <code>BaseExampleGenerator</code></p> <p>Implement an example generator that caches the last batch and returns it everytime a batch is generated.</p> <p>A new batch is generated only if the batch size changes.</p> <p>Parameters:</p> Name Type Description Default <code>generator</code> <code>BaseExampleGenerator | dict</code> <p>The example generator or its configuration.</p> required <code>deepcopy</code> <code>bool</code> <p>If <code>True</code>, the cached batch is deepcopied before to be return.</p> <code>False</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.example import Cache, SwissRoll\n&gt;&gt;&gt; generator = Cache(SwissRoll())\n&gt;&gt;&gt; generator\nCacheExampleGenerator(\n  (generator): SwissRollExampleGenerator(noise_std=0.0, spin=1.5, hole=False)\n  (deepcopy): False\n)\n&gt;&gt;&gt; batch = generator.generate(batch_size=10)\n&gt;&gt;&gt; batch\n{'target': tensor([...]), 'feature': tensor([[...]])}\n</code></pre>"},{"location":"refs/example/#startorch.example.CirclesClassification","title":"startorch.example.CirclesClassification","text":"<p>               Bases: <code>BaseExampleGenerator</code></p> <p>Implements a binary classification example generator where the data are generated with a large circle containing a smaller circle in 2d.</p> <p>The implementation is based on <code>sklearn.datasets.make_circles</code>.</p> <p>Parameters:</p> Name Type Description Default <code>shuffle</code> <code>bool</code> <p>If <code>True</code>, the examples are shuffled.</p> <code>True</code> <code>noise_std</code> <code>float</code> <p>The standard deviation of the Gaussian noise.</p> <code>0.0</code> <code>factor</code> <code>float</code> <p>The scale factor between inner and outer circle in the range <code>[0, 1)</code>.</p> <code>0.8</code> <code>ratio</code> <code>float</code> <p>The ratio between the number of examples in outer circle and inner circle.</p> <code>0.5</code> <p>Raises:</p> Type Description <code>TypeError</code> <p>if one of the parameters is not valid.</p> <code>RuntimeError</code> <p>if one of the parameters is not valid.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.example import CirclesClassification\n&gt;&gt;&gt; generator = CirclesClassification()\n&gt;&gt;&gt; generator\nCirclesClassificationExampleGenerator(shuffle=True, noise_std=0.0, factor=0.8, ratio=0.5)\n&gt;&gt;&gt; batch = generator.generate(batch_size=10)\n&gt;&gt;&gt; batch\n{'target': tensor([...]), 'feature': tensor([[...]])}\n</code></pre>"},{"location":"refs/example/#startorch.example.CirclesClassification.factor","title":"startorch.example.CirclesClassification.factor  <code>property</code>","text":"<pre><code>factor: float\n</code></pre> <p>The scale factor between inner and outer circle.</p>"},{"location":"refs/example/#startorch.example.CirclesClassification.noise_std","title":"startorch.example.CirclesClassification.noise_std  <code>property</code>","text":"<pre><code>noise_std: float\n</code></pre> <p>The standard deviation of the Gaussian noise.</p>"},{"location":"refs/example/#startorch.example.CirclesClassification.ratio","title":"startorch.example.CirclesClassification.ratio  <code>property</code>","text":"<pre><code>ratio: float\n</code></pre> <p>The ratio between the number of examples in outer circle and inner circle.</p>"},{"location":"refs/example/#startorch.example.CirclesClassificationExampleGenerator","title":"startorch.example.CirclesClassificationExampleGenerator","text":"<p>               Bases: <code>BaseExampleGenerator</code></p> <p>Implements a binary classification example generator where the data are generated with a large circle containing a smaller circle in 2d.</p> <p>The implementation is based on <code>sklearn.datasets.make_circles</code>.</p> <p>Parameters:</p> Name Type Description Default <code>shuffle</code> <code>bool</code> <p>If <code>True</code>, the examples are shuffled.</p> <code>True</code> <code>noise_std</code> <code>float</code> <p>The standard deviation of the Gaussian noise.</p> <code>0.0</code> <code>factor</code> <code>float</code> <p>The scale factor between inner and outer circle in the range <code>[0, 1)</code>.</p> <code>0.8</code> <code>ratio</code> <code>float</code> <p>The ratio between the number of examples in outer circle and inner circle.</p> <code>0.5</code> <p>Raises:</p> Type Description <code>TypeError</code> <p>if one of the parameters is not valid.</p> <code>RuntimeError</code> <p>if one of the parameters is not valid.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.example import CirclesClassification\n&gt;&gt;&gt; generator = CirclesClassification()\n&gt;&gt;&gt; generator\nCirclesClassificationExampleGenerator(shuffle=True, noise_std=0.0, factor=0.8, ratio=0.5)\n&gt;&gt;&gt; batch = generator.generate(batch_size=10)\n&gt;&gt;&gt; batch\n{'target': tensor([...]), 'feature': tensor([[...]])}\n</code></pre>"},{"location":"refs/example/#startorch.example.CirclesClassificationExampleGenerator.factor","title":"startorch.example.CirclesClassificationExampleGenerator.factor  <code>property</code>","text":"<pre><code>factor: float\n</code></pre> <p>The scale factor between inner and outer circle.</p>"},{"location":"refs/example/#startorch.example.CirclesClassificationExampleGenerator.noise_std","title":"startorch.example.CirclesClassificationExampleGenerator.noise_std  <code>property</code>","text":"<pre><code>noise_std: float\n</code></pre> <p>The standard deviation of the Gaussian noise.</p>"},{"location":"refs/example/#startorch.example.CirclesClassificationExampleGenerator.ratio","title":"startorch.example.CirclesClassificationExampleGenerator.ratio  <code>property</code>","text":"<pre><code>ratio: float\n</code></pre> <p>The ratio between the number of examples in outer circle and inner circle.</p>"},{"location":"refs/example/#startorch.example.Concatenate","title":"startorch.example.Concatenate","text":"<p>               Bases: <code>BaseExampleGenerator</code></p> <p>Implement an example generator that concatenates the outputs of multiple example generators.</p> <p>Note that the last value is used if there are duplicated keys.</p> <p>Parameters:</p> Name Type Description Default <code>generators</code> <code>Sequence[BaseExampleGenerator | dict]</code> <p>The example generators or their configurations.</p> required <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.example import TensorExampleGenerator, Concatenate\n&gt;&gt;&gt; from startorch.tensor import RandInt, RandUniform\n&gt;&gt;&gt; generator = Concatenate(\n...     [\n...         TensorExampleGenerator(\n...             generators={\"value\": RandUniform(), \"time\": RandUniform()},\n...             size=(6,),\n...         ),\n...         TensorExampleGenerator(\n...             generators={\"label\": RandInt(0, 10)},\n...             size=(),\n...         ),\n...     ]\n... )\n&gt;&gt;&gt; generator\nConcatenateExampleGenerator(\n  (0): TensorExampleGenerator(\n      (value): RandUniformTensorGenerator(low=0.0, high=1.0)\n      (time): RandUniformTensorGenerator(low=0.0, high=1.0)\n      (size): (6,)\n    )\n  (1): TensorExampleGenerator(\n      (label): RandIntTensorGenerator(low=0, high=10)\n      (size): ()\n    )\n)\n&gt;&gt;&gt; generator.generate(batch_size=10)\n{'value': tensor([[...]]), 'time': tensor([[...]]), 'label': tensor([...])}\n</code></pre>"},{"location":"refs/example/#startorch.example.ConcatenateExampleGenerator","title":"startorch.example.ConcatenateExampleGenerator","text":"<p>               Bases: <code>BaseExampleGenerator</code></p> <p>Implement an example generator that concatenates the outputs of multiple example generators.</p> <p>Note that the last value is used if there are duplicated keys.</p> <p>Parameters:</p> Name Type Description Default <code>generators</code> <code>Sequence[BaseExampleGenerator | dict]</code> <p>The example generators or their configurations.</p> required <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.example import TensorExampleGenerator, Concatenate\n&gt;&gt;&gt; from startorch.tensor import RandInt, RandUniform\n&gt;&gt;&gt; generator = Concatenate(\n...     [\n...         TensorExampleGenerator(\n...             generators={\"value\": RandUniform(), \"time\": RandUniform()},\n...             size=(6,),\n...         ),\n...         TensorExampleGenerator(\n...             generators={\"label\": RandInt(0, 10)},\n...             size=(),\n...         ),\n...     ]\n... )\n&gt;&gt;&gt; generator\nConcatenateExampleGenerator(\n  (0): TensorExampleGenerator(\n      (value): RandUniformTensorGenerator(low=0.0, high=1.0)\n      (time): RandUniformTensorGenerator(low=0.0, high=1.0)\n      (size): (6,)\n    )\n  (1): TensorExampleGenerator(\n      (label): RandIntTensorGenerator(low=0, high=10)\n      (size): ()\n    )\n)\n&gt;&gt;&gt; generator.generate(batch_size=10)\n{'value': tensor([[...]]), 'time': tensor([[...]]), 'label': tensor([...])}\n</code></pre>"},{"location":"refs/example/#startorch.example.Friedman1Regression","title":"startorch.example.Friedman1Regression","text":"<p>               Bases: <code>BaseExampleGenerator</code></p> <p>Implement the \"Friedman #1\" regression example generator.</p> <p>The implementation is based on <code>sklearn.datasets.make_friedman1</code>.</p> <p>Parameters:</p> Name Type Description Default <code>feature_size</code> <code>int</code> <p>The feature size. The feature size has to be greater than or equal to 5. Out of all features, only 5 are actually used to compute the targets. The remaining features are independent of targets.</p> <code>10</code> <code>noise_std</code> <code>float</code> <p>The standard deviation of the Gaussian noise.</p> <code>0.0</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>if one of the parameters is not valid.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.example import Friedman1Regression\n&gt;&gt;&gt; generator = Friedman1Regression(feature_size=6)\n&gt;&gt;&gt; generator\nFriedman1RegressionExampleGenerator(feature_size=6, noise_std=0.0)\n&gt;&gt;&gt; batch = generator.generate(batch_size=10)\n&gt;&gt;&gt; batch\n{'target': tensor([...]), 'feature': tensor([[...]])}\n</code></pre>"},{"location":"refs/example/#startorch.example.Friedman1Regression.feature_size","title":"startorch.example.Friedman1Regression.feature_size  <code>property</code>","text":"<pre><code>feature_size: int\n</code></pre> <p>The feature size when the data are created.</p>"},{"location":"refs/example/#startorch.example.Friedman1Regression.noise_std","title":"startorch.example.Friedman1Regression.noise_std  <code>property</code>","text":"<pre><code>noise_std: float\n</code></pre> <p>The standard deviation of the Gaussian noise.</p>"},{"location":"refs/example/#startorch.example.Friedman1RegressionExampleGenerator","title":"startorch.example.Friedman1RegressionExampleGenerator","text":"<p>               Bases: <code>BaseExampleGenerator</code></p> <p>Implement the \"Friedman #1\" regression example generator.</p> <p>The implementation is based on <code>sklearn.datasets.make_friedman1</code>.</p> <p>Parameters:</p> Name Type Description Default <code>feature_size</code> <code>int</code> <p>The feature size. The feature size has to be greater than or equal to 5. Out of all features, only 5 are actually used to compute the targets. The remaining features are independent of targets.</p> <code>10</code> <code>noise_std</code> <code>float</code> <p>The standard deviation of the Gaussian noise.</p> <code>0.0</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>if one of the parameters is not valid.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.example import Friedman1Regression\n&gt;&gt;&gt; generator = Friedman1Regression(feature_size=6)\n&gt;&gt;&gt; generator\nFriedman1RegressionExampleGenerator(feature_size=6, noise_std=0.0)\n&gt;&gt;&gt; batch = generator.generate(batch_size=10)\n&gt;&gt;&gt; batch\n{'target': tensor([...]), 'feature': tensor([[...]])}\n</code></pre>"},{"location":"refs/example/#startorch.example.Friedman1RegressionExampleGenerator.feature_size","title":"startorch.example.Friedman1RegressionExampleGenerator.feature_size  <code>property</code>","text":"<pre><code>feature_size: int\n</code></pre> <p>The feature size when the data are created.</p>"},{"location":"refs/example/#startorch.example.Friedman1RegressionExampleGenerator.noise_std","title":"startorch.example.Friedman1RegressionExampleGenerator.noise_std  <code>property</code>","text":"<pre><code>noise_std: float\n</code></pre> <p>The standard deviation of the Gaussian noise.</p>"},{"location":"refs/example/#startorch.example.Friedman2Regression","title":"startorch.example.Friedman2Regression","text":"<p>               Bases: <code>BaseExampleGenerator</code></p> <p>Implement the \"Friedman #2\" regression example generator.</p> <p>The implementation is based on <code>sklearn.datasets.make_friedman2</code>.</p> <p>Parameters:</p> Name Type Description Default <code>feature_size</code> <code>int</code> <p>The feature size. The feature size has to be greater than or equal to 4. Out of all features, only 4 are actually used to compute the targets. The remaining features are independent of targets.</p> <code>4</code> <code>noise_std</code> <code>float</code> <p>The standard deviation of the Gaussian noise.</p> <code>0.0</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>if one of the parameters is not valid.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.example import Friedman2Regression\n&gt;&gt;&gt; generator = Friedman2Regression(feature_size=6)\n&gt;&gt;&gt; generator\nFriedman2RegressionExampleGenerator(feature_size=6, noise_std=0.0)\n&gt;&gt;&gt; batch = generator.generate(batch_size=10)\n&gt;&gt;&gt; batch\n{'target': tensor([...]), 'feature': tensor([[...]])}\n</code></pre>"},{"location":"refs/example/#startorch.example.Friedman2Regression.feature_size","title":"startorch.example.Friedman2Regression.feature_size  <code>property</code>","text":"<pre><code>feature_size: int\n</code></pre> <p>The feature size when the data are created.</p>"},{"location":"refs/example/#startorch.example.Friedman2Regression.noise_std","title":"startorch.example.Friedman2Regression.noise_std  <code>property</code>","text":"<pre><code>noise_std: float\n</code></pre> <p>The standard deviation of the Gaussian noise.</p>"},{"location":"refs/example/#startorch.example.Friedman2RegressionExampleGenerator","title":"startorch.example.Friedman2RegressionExampleGenerator","text":"<p>               Bases: <code>BaseExampleGenerator</code></p> <p>Implement the \"Friedman #2\" regression example generator.</p> <p>The implementation is based on <code>sklearn.datasets.make_friedman2</code>.</p> <p>Parameters:</p> Name Type Description Default <code>feature_size</code> <code>int</code> <p>The feature size. The feature size has to be greater than or equal to 4. Out of all features, only 4 are actually used to compute the targets. The remaining features are independent of targets.</p> <code>4</code> <code>noise_std</code> <code>float</code> <p>The standard deviation of the Gaussian noise.</p> <code>0.0</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>if one of the parameters is not valid.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.example import Friedman2Regression\n&gt;&gt;&gt; generator = Friedman2Regression(feature_size=6)\n&gt;&gt;&gt; generator\nFriedman2RegressionExampleGenerator(feature_size=6, noise_std=0.0)\n&gt;&gt;&gt; batch = generator.generate(batch_size=10)\n&gt;&gt;&gt; batch\n{'target': tensor([...]), 'feature': tensor([[...]])}\n</code></pre>"},{"location":"refs/example/#startorch.example.Friedman2RegressionExampleGenerator.feature_size","title":"startorch.example.Friedman2RegressionExampleGenerator.feature_size  <code>property</code>","text":"<pre><code>feature_size: int\n</code></pre> <p>The feature size when the data are created.</p>"},{"location":"refs/example/#startorch.example.Friedman2RegressionExampleGenerator.noise_std","title":"startorch.example.Friedman2RegressionExampleGenerator.noise_std  <code>property</code>","text":"<pre><code>noise_std: float\n</code></pre> <p>The standard deviation of the Gaussian noise.</p>"},{"location":"refs/example/#startorch.example.Friedman3Regression","title":"startorch.example.Friedman3Regression","text":"<p>               Bases: <code>BaseExampleGenerator</code></p> <p>Implement the \"Friedman #3\" regression example generator.</p> <p>The implementation is based on <code>sklearn.datasets.make_friedman3</code>.</p> <p>Parameters:</p> Name Type Description Default <code>feature_size</code> <code>int</code> <p>The feature size. The feature size has to be greater than or equal to 4. Out of all features, only 4 are actually used to compute the targets. The remaining features are independent of targets.</p> <code>4</code> <code>noise_std</code> <code>float</code> <p>The standard deviation of the Gaussian noise.</p> <code>0.0</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>if one of the parameters is not valid.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.example import Friedman3Regression\n&gt;&gt;&gt; generator = Friedman3Regression(feature_size=6)\n&gt;&gt;&gt; generator\nFriedman3RegressionExampleGenerator(feature_size=6, noise_std=0.0)\n&gt;&gt;&gt; batch = generator.generate(batch_size=10)\n&gt;&gt;&gt; batch\n{'target': tensor([...]), 'feature': tensor([[...]])}\n</code></pre>"},{"location":"refs/example/#startorch.example.Friedman3Regression.feature_size","title":"startorch.example.Friedman3Regression.feature_size  <code>property</code>","text":"<pre><code>feature_size: int\n</code></pre> <p>The feature size when the data are created.</p>"},{"location":"refs/example/#startorch.example.Friedman3Regression.noise_std","title":"startorch.example.Friedman3Regression.noise_std  <code>property</code>","text":"<pre><code>noise_std: float\n</code></pre> <p>The standard deviation of the Gaussian noise.</p>"},{"location":"refs/example/#startorch.example.Friedman3RegressionExampleGenerator","title":"startorch.example.Friedman3RegressionExampleGenerator","text":"<p>               Bases: <code>BaseExampleGenerator</code></p> <p>Implement the \"Friedman #3\" regression example generator.</p> <p>The implementation is based on <code>sklearn.datasets.make_friedman3</code>.</p> <p>Parameters:</p> Name Type Description Default <code>feature_size</code> <code>int</code> <p>The feature size. The feature size has to be greater than or equal to 4. Out of all features, only 4 are actually used to compute the targets. The remaining features are independent of targets.</p> <code>4</code> <code>noise_std</code> <code>float</code> <p>The standard deviation of the Gaussian noise.</p> <code>0.0</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>if one of the parameters is not valid.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.example import Friedman3Regression\n&gt;&gt;&gt; generator = Friedman3Regression(feature_size=6)\n&gt;&gt;&gt; generator\nFriedman3RegressionExampleGenerator(feature_size=6, noise_std=0.0)\n&gt;&gt;&gt; batch = generator.generate(batch_size=10)\n&gt;&gt;&gt; batch\n{'target': tensor([...]), 'feature': tensor([[...]])}\n</code></pre>"},{"location":"refs/example/#startorch.example.Friedman3RegressionExampleGenerator.feature_size","title":"startorch.example.Friedman3RegressionExampleGenerator.feature_size  <code>property</code>","text":"<pre><code>feature_size: int\n</code></pre> <p>The feature size when the data are created.</p>"},{"location":"refs/example/#startorch.example.Friedman3RegressionExampleGenerator.noise_std","title":"startorch.example.Friedman3RegressionExampleGenerator.noise_std  <code>property</code>","text":"<pre><code>noise_std: float\n</code></pre> <p>The standard deviation of the Gaussian noise.</p>"},{"location":"refs/example/#startorch.example.HypercubeClassification","title":"startorch.example.HypercubeClassification","text":"<p>               Bases: <code>BaseExampleGenerator</code></p> <p>Implement a classification example generator.</p> <p>The data are generated by using a hypercube. The targets are some vertices of the hypercube. Each input feature is a 1-hot representation of the target plus a Gaussian noise. These data can be used for a multi-class classification task.</p> <p>Parameters:</p> Name Type Description Default <code>num_classes</code> <code>int</code> <p>The number of classes.</p> <code>50</code> <code>feature_size</code> <code>int</code> <p>The feature size. The feature size has to be greater than the number of classes.</p> <code>64</code> <code>noise_std</code> <code>float</code> <p>The standard deviation of the Gaussian noise.</p> <code>0.2</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>if one of the parameters is not valid.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.example import HypercubeClassification\n&gt;&gt;&gt; generator = HypercubeClassification(num_classes=5, feature_size=6)\n&gt;&gt;&gt; generator\nHypercubeClassificationExampleGenerator(num_classes=5, feature_size=6, noise_std=0.2)\n&gt;&gt;&gt; batch = generator.generate(batch_size=10)\n&gt;&gt;&gt; batch\n{'target': tensor([...]), 'feature': tensor([[...]])}\n</code></pre>"},{"location":"refs/example/#startorch.example.HypercubeClassification.feature_size","title":"startorch.example.HypercubeClassification.feature_size  <code>property</code>","text":"<pre><code>feature_size: int\n</code></pre> <p>The feature size when the data are created.</p>"},{"location":"refs/example/#startorch.example.HypercubeClassification.noise_std","title":"startorch.example.HypercubeClassification.noise_std  <code>property</code>","text":"<pre><code>noise_std: float\n</code></pre> <p>The standard deviation of the Gaussian noise.</p>"},{"location":"refs/example/#startorch.example.HypercubeClassification.num_classes","title":"startorch.example.HypercubeClassification.num_classes  <code>property</code>","text":"<pre><code>num_classes: int\n</code></pre> <p>The number of classes when the data are created.</p>"},{"location":"refs/example/#startorch.example.HypercubeClassificationExampleGenerator","title":"startorch.example.HypercubeClassificationExampleGenerator","text":"<p>               Bases: <code>BaseExampleGenerator</code></p> <p>Implement a classification example generator.</p> <p>The data are generated by using a hypercube. The targets are some vertices of the hypercube. Each input feature is a 1-hot representation of the target plus a Gaussian noise. These data can be used for a multi-class classification task.</p> <p>Parameters:</p> Name Type Description Default <code>num_classes</code> <code>int</code> <p>The number of classes.</p> <code>50</code> <code>feature_size</code> <code>int</code> <p>The feature size. The feature size has to be greater than the number of classes.</p> <code>64</code> <code>noise_std</code> <code>float</code> <p>The standard deviation of the Gaussian noise.</p> <code>0.2</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>if one of the parameters is not valid.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.example import HypercubeClassification\n&gt;&gt;&gt; generator = HypercubeClassification(num_classes=5, feature_size=6)\n&gt;&gt;&gt; generator\nHypercubeClassificationExampleGenerator(num_classes=5, feature_size=6, noise_std=0.2)\n&gt;&gt;&gt; batch = generator.generate(batch_size=10)\n&gt;&gt;&gt; batch\n{'target': tensor([...]), 'feature': tensor([[...]])}\n</code></pre>"},{"location":"refs/example/#startorch.example.HypercubeClassificationExampleGenerator.feature_size","title":"startorch.example.HypercubeClassificationExampleGenerator.feature_size  <code>property</code>","text":"<pre><code>feature_size: int\n</code></pre> <p>The feature size when the data are created.</p>"},{"location":"refs/example/#startorch.example.HypercubeClassificationExampleGenerator.noise_std","title":"startorch.example.HypercubeClassificationExampleGenerator.noise_std  <code>property</code>","text":"<pre><code>noise_std: float\n</code></pre> <p>The standard deviation of the Gaussian noise.</p>"},{"location":"refs/example/#startorch.example.HypercubeClassificationExampleGenerator.num_classes","title":"startorch.example.HypercubeClassificationExampleGenerator.num_classes  <code>property</code>","text":"<pre><code>num_classes: int\n</code></pre> <p>The number of classes when the data are created.</p>"},{"location":"refs/example/#startorch.example.LinearRegression","title":"startorch.example.LinearRegression","text":"<p>               Bases: <code>BaseExampleGenerator</code></p> <p>Implement a regression example generator where the data are generated with an underlying linear model.</p> <p>The implementation is based on <code>sklearn.datasets.make_regression</code>.</p> <p>Parameters:</p> Name Type Description Default <code>weights</code> <code>Tensor | Sequence[float]</code> <p>The linear weights in the underlying linear model. It must be a float tensor of shape <code>(feature_size,)</code>.</p> required <code>bias</code> <code>float</code> <p>The bias term in the underlying linear model.</p> <code>0.0</code> <code>noise_std</code> <code>float</code> <p>The standard deviation of the Gaussian noise.</p> <code>0.0</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>if one of the parameters is not valid.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.example import LinearRegression\n&gt;&gt;&gt; generator = LinearRegression.create_uniform_weights()\n&gt;&gt;&gt; generator\nLinearRegressionExampleGenerator(feature_size=100, bias=0.0, noise_std=0.0)\n&gt;&gt;&gt; batch = generator.generate(batch_size=10)\n&gt;&gt;&gt; batch\n{'target': tensor([...]), 'feature': tensor([[...]])}\n</code></pre>"},{"location":"refs/example/#startorch.example.LinearRegression.bias","title":"startorch.example.LinearRegression.bias  <code>property</code>","text":"<pre><code>bias: float\n</code></pre> <p>The bias of the underlying linear model.</p>"},{"location":"refs/example/#startorch.example.LinearRegression.feature_size","title":"startorch.example.LinearRegression.feature_size  <code>property</code>","text":"<pre><code>feature_size: int\n</code></pre> <p>The feature size.</p>"},{"location":"refs/example/#startorch.example.LinearRegression.noise_std","title":"startorch.example.LinearRegression.noise_std  <code>property</code>","text":"<pre><code>noise_std: float\n</code></pre> <p>The standard deviation of the Gaussian noise.</p>"},{"location":"refs/example/#startorch.example.LinearRegression.weights","title":"startorch.example.LinearRegression.weights  <code>property</code>","text":"<pre><code>weights: Tensor\n</code></pre> <p><code>torch.Tensor</code>: The weights of the underlying linear model.</p>"},{"location":"refs/example/#startorch.example.LinearRegressionExampleGenerator","title":"startorch.example.LinearRegressionExampleGenerator","text":"<p>               Bases: <code>BaseExampleGenerator</code></p> <p>Implement a regression example generator where the data are generated with an underlying linear model.</p> <p>The implementation is based on <code>sklearn.datasets.make_regression</code>.</p> <p>Parameters:</p> Name Type Description Default <code>weights</code> <code>Tensor | Sequence[float]</code> <p>The linear weights in the underlying linear model. It must be a float tensor of shape <code>(feature_size,)</code>.</p> required <code>bias</code> <code>float</code> <p>The bias term in the underlying linear model.</p> <code>0.0</code> <code>noise_std</code> <code>float</code> <p>The standard deviation of the Gaussian noise.</p> <code>0.0</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>if one of the parameters is not valid.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.example import LinearRegression\n&gt;&gt;&gt; generator = LinearRegression.create_uniform_weights()\n&gt;&gt;&gt; generator\nLinearRegressionExampleGenerator(feature_size=100, bias=0.0, noise_std=0.0)\n&gt;&gt;&gt; batch = generator.generate(batch_size=10)\n&gt;&gt;&gt; batch\n{'target': tensor([...]), 'feature': tensor([[...]])}\n</code></pre>"},{"location":"refs/example/#startorch.example.LinearRegressionExampleGenerator.bias","title":"startorch.example.LinearRegressionExampleGenerator.bias  <code>property</code>","text":"<pre><code>bias: float\n</code></pre> <p>The bias of the underlying linear model.</p>"},{"location":"refs/example/#startorch.example.LinearRegressionExampleGenerator.feature_size","title":"startorch.example.LinearRegressionExampleGenerator.feature_size  <code>property</code>","text":"<pre><code>feature_size: int\n</code></pre> <p>The feature size.</p>"},{"location":"refs/example/#startorch.example.LinearRegressionExampleGenerator.noise_std","title":"startorch.example.LinearRegressionExampleGenerator.noise_std  <code>property</code>","text":"<pre><code>noise_std: float\n</code></pre> <p>The standard deviation of the Gaussian noise.</p>"},{"location":"refs/example/#startorch.example.LinearRegressionExampleGenerator.weights","title":"startorch.example.LinearRegressionExampleGenerator.weights  <code>property</code>","text":"<pre><code>weights: Tensor\n</code></pre> <p><code>torch.Tensor</code>: The weights of the underlying linear model.</p>"},{"location":"refs/example/#startorch.example.MoonsClassification","title":"startorch.example.MoonsClassification","text":"<p>               Bases: <code>BaseExampleGenerator</code></p> <p>Implements a binary classification example generator where the data are generated with a large circle containing a smaller circle in 2d.</p> <p>The implementation is based on <code>sklearn.datasets.make_moons</code>.</p> <p>Parameters:</p> Name Type Description Default <code>shuffle</code> <code>bool</code> <p>If <code>True</code>, the examples are shuffled.</p> <code>True</code> <code>noise_std</code> <code>float</code> <p>The standard deviation of the Gaussian noise.</p> <code>0.0</code> <code>ratio</code> <code>float</code> <p>The ratio between the number of examples in outer circle and inner circle.</p> <code>0.5</code> <p>Raises:</p> Type Description <code>TypeError</code> <p>if one of the parameters has an invalid type.</p> <code>RuntimeError</code> <p>if one of the parameters has an invalid value.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.example import MoonsClassification\n&gt;&gt;&gt; generator = MoonsClassification()\n&gt;&gt;&gt; generator\nMoonsClassificationExampleGenerator(shuffle=True, noise_std=0.0, ratio=0.5)\n&gt;&gt;&gt; batch = generator.generate(batch_size=10)\n&gt;&gt;&gt; batch\n{'target': tensor([...]), 'feature': tensor([[...]])}\n</code></pre>"},{"location":"refs/example/#startorch.example.MoonsClassification.noise_std","title":"startorch.example.MoonsClassification.noise_std  <code>property</code>","text":"<pre><code>noise_std: float\n</code></pre> <p>The standard deviation of the Gaussian noise.</p>"},{"location":"refs/example/#startorch.example.MoonsClassification.ratio","title":"startorch.example.MoonsClassification.ratio  <code>property</code>","text":"<pre><code>ratio: float\n</code></pre> <p>The ratio between the number of examples in outer circle and inner circle.</p>"},{"location":"refs/example/#startorch.example.MoonsClassificationExampleGenerator","title":"startorch.example.MoonsClassificationExampleGenerator","text":"<p>               Bases: <code>BaseExampleGenerator</code></p> <p>Implements a binary classification example generator where the data are generated with a large circle containing a smaller circle in 2d.</p> <p>The implementation is based on <code>sklearn.datasets.make_moons</code>.</p> <p>Parameters:</p> Name Type Description Default <code>shuffle</code> <code>bool</code> <p>If <code>True</code>, the examples are shuffled.</p> <code>True</code> <code>noise_std</code> <code>float</code> <p>The standard deviation of the Gaussian noise.</p> <code>0.0</code> <code>ratio</code> <code>float</code> <p>The ratio between the number of examples in outer circle and inner circle.</p> <code>0.5</code> <p>Raises:</p> Type Description <code>TypeError</code> <p>if one of the parameters has an invalid type.</p> <code>RuntimeError</code> <p>if one of the parameters has an invalid value.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.example import MoonsClassification\n&gt;&gt;&gt; generator = MoonsClassification()\n&gt;&gt;&gt; generator\nMoonsClassificationExampleGenerator(shuffle=True, noise_std=0.0, ratio=0.5)\n&gt;&gt;&gt; batch = generator.generate(batch_size=10)\n&gt;&gt;&gt; batch\n{'target': tensor([...]), 'feature': tensor([[...]])}\n</code></pre>"},{"location":"refs/example/#startorch.example.MoonsClassificationExampleGenerator.noise_std","title":"startorch.example.MoonsClassificationExampleGenerator.noise_std  <code>property</code>","text":"<pre><code>noise_std: float\n</code></pre> <p>The standard deviation of the Gaussian noise.</p>"},{"location":"refs/example/#startorch.example.MoonsClassificationExampleGenerator.ratio","title":"startorch.example.MoonsClassificationExampleGenerator.ratio  <code>property</code>","text":"<pre><code>ratio: float\n</code></pre> <p>The ratio between the number of examples in outer circle and inner circle.</p>"},{"location":"refs/example/#startorch.example.SwissRoll","title":"startorch.example.SwissRoll","text":"<p>               Bases: <code>BaseExampleGenerator</code></p> <p>Implements a manifold example generator based on the Swiss roll pattern.</p> <p>The implementation is based on <code>sklearn.datasets.make_swiss_roll</code>.</p> <p>Parameters:</p> Name Type Description Default <code>noise_std</code> <code>float</code> <p>The standard deviation of the Gaussian noise.</p> <code>0.0</code> <code>spin</code> <code>float</code> <p>The number of spins of the Swiss roll.</p> <code>1.5</code> <code>hole</code> <code>bool</code> <p>If <code>True</code> generates the Swiss roll with a hole.</p> <code>False</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>if one of the parameters is not valid.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.example import SwissRoll\n&gt;&gt;&gt; generator = SwissRoll()\n&gt;&gt;&gt; generator\nSwissRollExampleGenerator(noise_std=0.0, spin=1.5, hole=False)\n&gt;&gt;&gt; batch = generator.generate(batch_size=10)\n&gt;&gt;&gt; batch\n{'target': tensor([...]), 'feature': tensor([[...]])}\n</code></pre>"},{"location":"refs/example/#startorch.example.SwissRoll.noise_std","title":"startorch.example.SwissRoll.noise_std  <code>property</code>","text":"<pre><code>noise_std: float\n</code></pre> <p>The standard deviation of the Gaussian noise.</p>"},{"location":"refs/example/#startorch.example.SwissRoll.spin","title":"startorch.example.SwissRoll.spin  <code>property</code>","text":"<pre><code>spin: float\n</code></pre> <p>The number of spins.</p>"},{"location":"refs/example/#startorch.example.SwissRollExampleGenerator","title":"startorch.example.SwissRollExampleGenerator","text":"<p>               Bases: <code>BaseExampleGenerator</code></p> <p>Implements a manifold example generator based on the Swiss roll pattern.</p> <p>The implementation is based on <code>sklearn.datasets.make_swiss_roll</code>.</p> <p>Parameters:</p> Name Type Description Default <code>noise_std</code> <code>float</code> <p>The standard deviation of the Gaussian noise.</p> <code>0.0</code> <code>spin</code> <code>float</code> <p>The number of spins of the Swiss roll.</p> <code>1.5</code> <code>hole</code> <code>bool</code> <p>If <code>True</code> generates the Swiss roll with a hole.</p> <code>False</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>if one of the parameters is not valid.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.example import SwissRoll\n&gt;&gt;&gt; generator = SwissRoll()\n&gt;&gt;&gt; generator\nSwissRollExampleGenerator(noise_std=0.0, spin=1.5, hole=False)\n&gt;&gt;&gt; batch = generator.generate(batch_size=10)\n&gt;&gt;&gt; batch\n{'target': tensor([...]), 'feature': tensor([[...]])}\n</code></pre>"},{"location":"refs/example/#startorch.example.SwissRollExampleGenerator.noise_std","title":"startorch.example.SwissRollExampleGenerator.noise_std  <code>property</code>","text":"<pre><code>noise_std: float\n</code></pre> <p>The standard deviation of the Gaussian noise.</p>"},{"location":"refs/example/#startorch.example.SwissRollExampleGenerator.spin","title":"startorch.example.SwissRollExampleGenerator.spin  <code>property</code>","text":"<pre><code>spin: float\n</code></pre> <p>The number of spins.</p>"},{"location":"refs/example/#startorch.example.TensorExampleGenerator","title":"startorch.example.TensorExampleGenerator","text":"<p>               Bases: <code>BaseExampleGenerator</code></p> <p>Implement an example generator to generate time series.</p> <p>Parameters:</p> Name Type Description Default <code>generators</code> <code>Mapping[str, BaseTensorGenerator | dict]</code> <p>The tensor generators or their configurations.</p> required <code>size</code> <code>Sequence[int]</code> <p>The output tensor shape excepts the first dimension which is set to <code>batch_size</code>.</p> required <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.example import TensorExampleGenerator\n&gt;&gt;&gt; from startorch.tensor import RandInt, RandUniform\n&gt;&gt;&gt; generator = TensorExampleGenerator(\n...     generators={\"value\": RandUniform(), \"time\": RandUniform()},\n...     size=(6,),\n... )\n&gt;&gt;&gt; generator\nTensorExampleGenerator(\n  (value): RandUniformTensorGenerator(low=0.0, high=1.0)\n  (time): RandUniformTensorGenerator(low=0.0, high=1.0)\n  (size): (6,)\n)\n&gt;&gt;&gt; generator.generate(batch_size=10)\n{'value': tensor([[...]]), 'time': tensor([[...]])}\n</code></pre>"},{"location":"refs/example/#startorch.example.TimeSeries","title":"startorch.example.TimeSeries","text":"<p>               Bases: <code>BaseExampleGenerator</code></p> <p>Implement an example generator to generate time series.</p> <p>Parameters:</p> Name Type Description Default <code>timeseries</code> <code>BaseTimeSeriesGenerator | dict</code> <p>A time series generator or its configuration.</p> required <code>seq_len</code> <code>BaseTensorGenerator | dict</code> <p>The sequence length sampler or its configuration. This sampler is used to sample the sequence length at each batch.</p> required <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.example import TimeSeriesExampleGenerator\n&gt;&gt;&gt; from startorch.timeseries import TimeSeriesGenerator\n&gt;&gt;&gt; from startorch.sequence import Periodic, RandUniform\n&gt;&gt;&gt; from startorch.tensor import RandInt\n&gt;&gt;&gt; generator = TimeSeriesExampleGenerator(\n...     timeseries=TimeSeriesGenerator({\"value\": RandUniform(), \"time\": RandUniform()}),\n...     seq_len=RandInt(2, 5),\n... )\n&gt;&gt;&gt; generator\nTimeSeriesExampleGenerator(\n  (timeseries): TimeSeriesGenerator(\n      (value): RandUniformSequenceGenerator(low=0.0, high=1.0, feature_size=(1,))\n      (time): RandUniformSequenceGenerator(low=0.0, high=1.0, feature_size=(1,))\n    )\n  (seq_len): RandIntTensorGenerator(low=2, high=5)\n)\n&gt;&gt;&gt; generator.generate(batch_size=10)\n{'value': tensor([[...]]), 'time': tensor([[...]])}\n</code></pre>"},{"location":"refs/example/#startorch.example.TimeSeriesExampleGenerator","title":"startorch.example.TimeSeriesExampleGenerator","text":"<p>               Bases: <code>BaseExampleGenerator</code></p> <p>Implement an example generator to generate time series.</p> <p>Parameters:</p> Name Type Description Default <code>timeseries</code> <code>BaseTimeSeriesGenerator | dict</code> <p>A time series generator or its configuration.</p> required <code>seq_len</code> <code>BaseTensorGenerator | dict</code> <p>The sequence length sampler or its configuration. This sampler is used to sample the sequence length at each batch.</p> required <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.example import TimeSeriesExampleGenerator\n&gt;&gt;&gt; from startorch.timeseries import TimeSeriesGenerator\n&gt;&gt;&gt; from startorch.sequence import Periodic, RandUniform\n&gt;&gt;&gt; from startorch.tensor import RandInt\n&gt;&gt;&gt; generator = TimeSeriesExampleGenerator(\n...     timeseries=TimeSeriesGenerator({\"value\": RandUniform(), \"time\": RandUniform()}),\n...     seq_len=RandInt(2, 5),\n... )\n&gt;&gt;&gt; generator\nTimeSeriesExampleGenerator(\n  (timeseries): TimeSeriesGenerator(\n      (value): RandUniformSequenceGenerator(low=0.0, high=1.0, feature_size=(1,))\n      (time): RandUniformSequenceGenerator(low=0.0, high=1.0, feature_size=(1,))\n    )\n  (seq_len): RandIntTensorGenerator(low=2, high=5)\n)\n&gt;&gt;&gt; generator.generate(batch_size=10)\n{'value': tensor([[...]]), 'time': tensor([[...]])}\n</code></pre>"},{"location":"refs/example/#startorch.example.Transformed","title":"startorch.example.Transformed","text":"<p>               Bases: <code>BaseExampleGenerator</code></p> <p>Implement an example generator that generates examples, and then transformes them.</p> <p>Parameters:</p> Name Type Description Default <code>generator</code> <code>BaseExampleGenerator | dict</code> <p>The example generator or its configuration.</p> required <code>transformer</code> <code>BaseTransformer | dict</code> <p>The data transformer or its configuration.</p> required <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.example import TransformedExampleGenerator, HypercubeClassification\n&gt;&gt;&gt; from startorch.transformer import Abs\n&gt;&gt;&gt; generator = TransformedExampleGenerator(\n...     generator=HypercubeClassification(num_classes=5, feature_size=6),\n...     transformer=Abs(input=\"feature\", output=\"feature_transformed\"),\n... )\n&gt;&gt;&gt; generator\nTransformedExampleGenerator(\n  (generator): HypercubeClassificationExampleGenerator(num_classes=5, feature_size=6, noise_std=0.2)\n  (transformer): AbsTransformer(input=feature, output=feature_transformed, exist_ok=False)\n)\n&gt;&gt;&gt; generator.generate(batch_size=10)\n{'target': tensor([...]), 'feature': tensor([[...]]), 'feature_transformed': tensor([[...]])}\n</code></pre>"},{"location":"refs/example/#startorch.example.TransformedExampleGenerator","title":"startorch.example.TransformedExampleGenerator","text":"<p>               Bases: <code>BaseExampleGenerator</code></p> <p>Implement an example generator that generates examples, and then transformes them.</p> <p>Parameters:</p> Name Type Description Default <code>generator</code> <code>BaseExampleGenerator | dict</code> <p>The example generator or its configuration.</p> required <code>transformer</code> <code>BaseTransformer | dict</code> <p>The data transformer or its configuration.</p> required <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.example import TransformedExampleGenerator, HypercubeClassification\n&gt;&gt;&gt; from startorch.transformer import Abs\n&gt;&gt;&gt; generator = TransformedExampleGenerator(\n...     generator=HypercubeClassification(num_classes=5, feature_size=6),\n...     transformer=Abs(input=\"feature\", output=\"feature_transformed\"),\n... )\n&gt;&gt;&gt; generator\nTransformedExampleGenerator(\n  (generator): HypercubeClassificationExampleGenerator(num_classes=5, feature_size=6, noise_std=0.2)\n  (transformer): AbsTransformer(input=feature, output=feature_transformed, exist_ok=False)\n)\n&gt;&gt;&gt; generator.generate(batch_size=10)\n{'target': tensor([...]), 'feature': tensor([[...]]), 'feature_transformed': tensor([[...]])}\n</code></pre>"},{"location":"refs/example/#startorch.example.VanillaExampleGenerator","title":"startorch.example.VanillaExampleGenerator","text":"<p>               Bases: <code>BaseExampleGenerator</code></p> <p>Implement an example generator to \"generate\" the input data.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>dict[Hashable, Tensor]</code> <p>The data to generate. The dictionary cannot be empty.</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>if <code>data</code> is an empty dictionary.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; from startorch.example import VanillaExampleGenerator\n&gt;&gt;&gt; generator = VanillaExampleGenerator(\n...     data={\"value\": torch.ones(10, 3), \"time\": torch.arange(10)}\n... )\n&gt;&gt;&gt; generator\nVanillaExampleGenerator(batch_size=10)\n&gt;&gt;&gt; generator.generate(batch_size=5)\n{'value': tensor([[1., 1., 1.],\n                  [1., 1., 1.],\n                  [1., 1., 1.],\n                  [1., 1., 1.],\n                  [1., 1., 1.]]),\n 'time': tensor([0, 1, 2, 3, 4])}\n</code></pre>"},{"location":"refs/example/#startorch.example.is_example_generator_config","title":"startorch.example.is_example_generator_config","text":"<pre><code>is_example_generator_config(config: dict) -&gt; bool\n</code></pre> <p>Indicate if the input configuration is a configuration for a <code>BaseExampleGenerator</code>.</p> <p>This function only checks if the value of the key  <code>_target_</code> is valid. It does not check the other values. If <code>_target_</code> indicates a function, the returned type hint is used to check the class.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>dict</code> <p>The configuration to check.</p> required <p>Returns:</p> Type Description <code>bool</code> <p><code>True</code> if the input configuration is a configuration for a <code>BaseExampleGenerator</code> object.</p> <p>Example usage:</p> <p>```pycon</p> <pre><code>&gt;&gt;&gt; from startorch.example import is_example_generator_config\n&gt;&gt;&gt; is_example_generator_config({\"_target_\": \"startorch.example.HypercubeClassification\"})\nTrue\n</code></pre>"},{"location":"refs/example/#startorch.example.make_blobs_classification","title":"startorch.example.make_blobs_classification","text":"<pre><code>make_blobs_classification(\n    num_examples: int,\n    centers: Tensor,\n    cluster_std: Tensor | float = 1.0,\n    generator: Generator | None = None,\n) -&gt; dict[str, Tensor]\n</code></pre> <p>Generate a classification dataset where the data are gnerated from isotropic Gaussian blobs for clustering.</p> <p>The implementation is based on https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_blobs.html</p> <p>Parameters:</p> Name Type Description Default <code>num_examples</code> <code>int</code> <p>The number of examples.</p> required <code>centers</code> <code>Tensor</code> <p>The cluster centers used to generate the examples. It must be a float tensor of shape <code>(num_clusters, feature_size)</code>.</p> required <code>cluster_std</code> <code>Tensor | float</code> <p>The standard deviation of the clusters. It must be a float tensor of shape <code>(num_clusters, feature_size)</code>.</p> <code>1.0</code> <code>generator</code> <code>Generator | None</code> <p>An optional random number generator.</p> <code>None</code> <p>Returns:</p> Type Description <code>dict[str, Tensor]</code> <p>A dictionary with two items: - <code>'input'</code>: a <code>BatchedTensor</code> of type float and     shape <code>(num_examples, feature_size)</code>. This     tensor represents the input features. - <code>'target'</code>: a <code>BatchedTensor</code> of type long and     shape <code>(num_examples,)</code>. This tensor represents     the targets.</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>if one of the parameters is not valid.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; from startorch.example import make_blobs_classification\n&gt;&gt;&gt; batch = make_blobs_classification(num_examples=10, centers=torch.rand(5, 2))\n&gt;&gt;&gt; batch\n{'target': tensor([...]), 'feature': tensor([[...]])}\n</code></pre>"},{"location":"refs/example/#startorch.example.make_circles_classification","title":"startorch.example.make_circles_classification","text":"<pre><code>make_circles_classification(\n    num_examples: int = 100,\n    shuffle: bool = True,\n    noise_std: float = 0.0,\n    factor: float = 0.8,\n    ratio: float = 0.5,\n    generator: Generator | None = None,\n) -&gt; dict[str, Tensor]\n</code></pre> <p>Generate a binary classification dataset where the data are generated with a large circle containing a smaller circle in 2d.</p> <p>The implementation is based on <code>sklearn.datasets.make_circles</code>.</p> <p>Parameters:</p> Name Type Description Default <code>num_examples</code> <code>int</code> <p>The number of examples.</p> <code>100</code> <code>shuffle</code> <code>bool</code> <p>If <code>True</code>, the examples are shuffled.</p> <code>True</code> <code>noise_std</code> <code>float</code> <p>The standard deviation of the Gaussian noise.</p> <code>0.0</code> <code>factor</code> <code>float</code> <p>The scale factor between inner and outer circle in the range <code>[0, 1)</code>.</p> <code>0.8</code> <code>ratio</code> <code>float</code> <p>The ratio between the number of examples in outer circle and inner circle.</p> <code>0.5</code> <code>generator</code> <code>Generator | None</code> <p>An optional random generator.</p> <code>None</code> <p>Returns:</p> Type Description <code>dict[str, Tensor]</code> <p>A dictionary with two items: - <code>'input'</code>: a <code>BatchedTensor</code> of type float and     shape <code>(num_examples, 2)</code>. This     tensor represents the input features. - <code>'target'</code>: a <code>BatchedTensor</code> of type long and     shape <code>(num_examples,)</code>. This tensor represents     the targets.</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>if one of the parameters is not valid.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.example import make_circles_classification\n&gt;&gt;&gt; batch = make_circles_classification(num_examples=10)\n&gt;&gt;&gt; batch\n{'target': tensor([...]), 'feature': tensor([[...]])}\n</code></pre>"},{"location":"refs/example/#startorch.example.make_friedman1_regression","title":"startorch.example.make_friedman1_regression","text":"<pre><code>make_friedman1_regression(\n    num_examples: int = 100,\n    feature_size: int = 10,\n    noise_std: float = 0.0,\n    generator: Generator | None = None,\n) -&gt; dict[str, Tensor]\n</code></pre> <p>Generate the \"Friedman #1\" regression data.</p> <p>The implementation is based on <code>sklearn.datasets.make_friedman1</code>.</p> <p>Parameters:</p> Name Type Description Default <code>num_examples</code> <code>int</code> <p>The number of examples.</p> <code>100</code> <code>feature_size</code> <code>int</code> <p>The feature size. The feature size has to be greater than or equal to 5. Out of all features, only 5 are actually used to compute the targets. The remaining features are independent of targets.</p> <code>10</code> <code>noise_std</code> <code>float</code> <p>The standard deviation of the Gaussian noise.</p> <code>0.0</code> <code>generator</code> <code>Generator | None</code> <p>An optional random number generator.</p> <code>None</code> <p>Returns:</p> Type Description <code>dict[str, Tensor]</code> <p>A dictionary with two items: - <code>'input'</code>: a <code>BatchedTensor</code> of type float and     shape <code>(num_examples, feature_size)</code>. This     tensor represents the input features. - <code>'target'</code>: a <code>BatchedTensor</code> of type float and     shape <code>(num_examples,)</code>. This tensor represents     the targets.</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>if one of the parameters is not valid.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.example import make_friedman1_regression\n&gt;&gt;&gt; batch = make_friedman1_regression(num_examples=10)\n&gt;&gt;&gt; batch\n{'target': tensor([...]), 'feature': tensor([[...]])}\n</code></pre>"},{"location":"refs/example/#startorch.example.make_friedman2_regression","title":"startorch.example.make_friedman2_regression","text":"<pre><code>make_friedman2_regression(\n    num_examples: int = 100,\n    feature_size: int = 4,\n    noise_std: float = 0.0,\n    generator: Generator | None = None,\n) -&gt; dict[str, Tensor]\n</code></pre> <p>Generate the \"Friedman #2\" regression data.</p> <p>The implementation is based on <code>sklearn.datasets.make_friedman2</code>.</p> <p>Parameters:</p> Name Type Description Default <code>num_examples</code> <code>int</code> <p>The number of examples.</p> <code>100</code> <code>feature_size</code> <code>int</code> <p>The feature size. The feature size has to be greater than or equal to 4. Out of all features, only 4 are actually used to compute the targets. The remaining features are independent of targets.</p> <code>4</code> <code>noise_std</code> <code>float</code> <p>The standard deviation of the Gaussian noise.</p> <code>0.0</code> <code>generator</code> <code>Generator | None</code> <p>An optional random number generator.</p> <code>None</code> <p>Returns:</p> Type Description <code>dict[str, Tensor]</code> <p>A dictionary with two items: - <code>'input'</code>: a <code>BatchedTensor</code> of type float and     shape <code>(num_examples, feature_size)</code>. This     tensor represents the input features. - <code>'target'</code>: a <code>BatchedTensor</code> of type float and     shape <code>(num_examples,)</code>. This tensor represents     the targets.</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>if one of the parameters is not valid.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.example import make_friedman2_regression\n&gt;&gt;&gt; batch = make_friedman2_regression(num_examples=10)\n&gt;&gt;&gt; batch\n{'target': tensor([...]), 'feature': tensor([[...]])}\n</code></pre>"},{"location":"refs/example/#startorch.example.make_friedman3_regression","title":"startorch.example.make_friedman3_regression","text":"<pre><code>make_friedman3_regression(\n    num_examples: int = 100,\n    feature_size: int = 4,\n    noise_std: float = 0.0,\n    generator: Generator | None = None,\n) -&gt; dict[str, Tensor]\n</code></pre> <p>Generate the \"Friedman #3\" regression problem.</p> <p>The implementation is based on <code>sklearn.datasets.make_friedman3</code>.</p> <p>Parameters:</p> Name Type Description Default <code>num_examples</code> <code>int</code> <p>The number of examples.</p> <code>100</code> <code>feature_size</code> <code>int</code> <p>The feature size. The feature size has to be greater than or equal to 4. Out of all features, only 4 are actually used to compute the targets. The remaining features are independent of targets.</p> <code>4</code> <code>noise_std</code> <code>float</code> <p>The standard deviation of the Gaussian noise.</p> <code>0.0</code> <code>generator</code> <code>Generator | None</code> <p>An optional random number generator.</p> <code>None</code> <p>Returns:</p> Type Description <code>dict[str, Tensor]</code> <p>A dictionary with two items: - <code>'input'</code>: a <code>BatchedTensor</code> of type float and     shape <code>(num_examples, feature_size)</code>. This     tensor represents the input features. - <code>'target'</code>: a <code>BatchedTensor</code> of type float and     shape <code>(num_examples,)</code>. This tensor represents     the targets.</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>if one of the parameters is not valid.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.example import make_friedman3_regression\n&gt;&gt;&gt; batch = make_friedman3_regression(num_examples=10)\n&gt;&gt;&gt; batch\n{'target': tensor([...]), 'feature': tensor([[...]])}\n</code></pre>"},{"location":"refs/example/#startorch.example.make_hypercube_classification","title":"startorch.example.make_hypercube_classification","text":"<pre><code>make_hypercube_classification(\n    num_examples: int = 1000,\n    num_classes: int = 50,\n    feature_size: int = 64,\n    noise_std: float = 0.2,\n    generator: Generator | None = None,\n) -&gt; dict[str, Tensor]\n</code></pre> <p>Generate a synthetic classification dataset based on hypercube vertex structure.</p> <p>The data are generated by using a hypercube. The targets are some vertices of the hypercube. Each input feature is a 1-hot representation of the target plus a Gaussian noise. These data can be used for a multi-class classification task.</p> <p>Parameters:</p> Name Type Description Default <code>num_examples</code> <code>int</code> <p>The number of examples.</p> <code>1000</code> <code>num_classes</code> <code>int</code> <p>The number of classes.</p> <code>50</code> <code>feature_size</code> <code>int</code> <p>The feature size. The feature size has to be greater than the number of classes.</p> <code>64</code> <code>noise_std</code> <code>float</code> <p>The standard deviation of the Gaussian noise.</p> <code>0.2</code> <code>generator</code> <code>Generator | None</code> <p>An optional random generator.</p> <code>None</code> <p>Returns:</p> Type Description <code>dict[str, Tensor]</code> <p>A dictionary with two items: - <code>'input'</code>: a <code>torch.Tensor</code> of type float and     shape <code>(num_examples, feature_size)</code>. This     tensor represents the input features. - <code>'target'</code>: a <code>torch.Tensor</code> of type long and     shape <code>(num_examples,)</code>. This tensor represents     the targets.</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>if one of the parameters is not valid.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.example.hypercube import make_hypercube_classification\n&gt;&gt;&gt; batch = make_hypercube_classification(num_examples=10, num_classes=5, feature_size=10)\n&gt;&gt;&gt; batch\n{'target': tensor([...]), 'feature': tensor([[...]])}\n</code></pre>"},{"location":"refs/example/#startorch.example.make_linear_regression","title":"startorch.example.make_linear_regression","text":"<pre><code>make_linear_regression(\n    weights: Tensor,\n    bias: float = 0.0,\n    num_examples: int = 100,\n    noise_std: float = 0.0,\n    generator: Generator | None = None,\n) -&gt; dict[str, Tensor]\n</code></pre> <p>Generate a regression dataset where the data are generated with an underlying linear model.</p> <p>The features are sampled from a Normal distribution. Then, the targets are generated by applying a random linear regression model.</p> <p>Parameters:</p> Name Type Description Default <code>weights</code> <code>Tensor</code> <p>The linear weights in the underlying linear model. It must be a float tensor of shape <code>(feature_size,)</code>.</p> required <code>bias</code> <code>float</code> <p>The bias term in the underlying linear model.</p> <code>0.0</code> <code>num_examples</code> <code>int</code> <p>The number of examples to generate.</p> <code>100</code> <code>noise_std</code> <code>float</code> <p>The standard deviation of the Gaussian noise.</p> <code>0.0</code> <code>generator</code> <code>Generator | None</code> <p>An optional random generator.</p> <code>None</code> <p>Returns:</p> Type Description <code>dict[str, Tensor]</code> <p>A dictionary with two items: - <code>'input'</code>: a <code>BatchedTensor</code> of type float and     shape <code>(num_examples, feature_size)</code>. This     tensor represents the input features. - <code>'target'</code>: a <code>BatchedTensor</code> of type float and     shape <code>(num_examples,)</code>. This tensor represents     the targets.</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>if one of the parameters is not valid.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.example import make_linear_regression\n&gt;&gt;&gt; batch = make_linear_regression(weights=torch.rand(10), num_examples=10)\n&gt;&gt;&gt; batch\n{'target': tensor([...]), 'feature': tensor([[...]])}\n</code></pre>"},{"location":"refs/example/#startorch.example.make_moons_classification","title":"startorch.example.make_moons_classification","text":"<pre><code>make_moons_classification(\n    num_examples: int = 100,\n    shuffle: bool = True,\n    noise_std: float = 0.0,\n    ratio: float = 0.5,\n    generator: Generator | None = None,\n) -&gt; dict[str, Tensor]\n</code></pre> <p>Generate a binary classification dataset where the data are two interleaving half circles in 2d.</p> <p>The implementation is based on <code>sklearn.datasets.make_moons</code>.</p> <p>Parameters:</p> Name Type Description Default <code>num_examples</code> <code>int</code> <p>The number of examples.</p> <code>100</code> <code>shuffle</code> <code>bool</code> <p>If <code>True</code>, the examples are shuffled.</p> <code>True</code> <code>noise_std</code> <code>float</code> <p>The standard deviation of the Gaussian noise.</p> <code>0.0</code> <code>ratio</code> <code>float</code> <p>The ratio between the number of examples in outer circle and inner circle.</p> <code>0.5</code> <code>generator</code> <code>Generator | None</code> <p>An optional random generator.</p> <code>None</code> <p>Returns:</p> Type Description <code>dict[str, Tensor]</code> <p>A dictionary with two items: - <code>'input'</code>: a <code>BatchedTensor</code> of type float and     shape <code>(num_examples, 2)</code>. This     tensor represents the input features. - <code>'target'</code>: a <code>BatchedTensor</code> of type long and     shape <code>(num_examples,)</code>. This tensor represents     the targets.</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>if one of the parameters is not valid.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.example import make_moons_classification\n&gt;&gt;&gt; batch = make_moons_classification(num_examples=10)\n&gt;&gt;&gt; batch\n{'target': tensor([...]), 'feature': tensor([[...]])}\n</code></pre>"},{"location":"refs/example/#startorch.example.make_sparse_uncorrelated_regression","title":"startorch.example.make_sparse_uncorrelated_regression","text":"<pre><code>make_sparse_uncorrelated_regression(\n    num_examples: int = 100,\n    feature_size: int = 4,\n    noise_std: float = 0.0,\n    generator: Generator | None = None,\n) -&gt; dict[str, Tensor]\n</code></pre> <p>Generate a random regression problem with sparse uncorrelated design.</p> <p>The implementation is based on <code>sklearn.datasets.make_sparse_uncorrelated</code>.</p> <p>Parameters:</p> Name Type Description Default <code>num_examples</code> <code>int</code> <p>The number of examples.</p> <code>100</code> <code>feature_size</code> <code>int</code> <p>The feature size. The feature size has to be greater than or equal to 4. Out of all features, only 4 are actually used to compute the targets. The remaining features are independent of targets.</p> <code>4</code> <code>noise_std</code> <code>float</code> <p>The standard deviation of the Gaussian noise.</p> <code>0.0</code> <code>generator</code> <code>Generator | None</code> <p>An optional random generator.</p> <code>None</code> <p>Returns:</p> Type Description <code>dict[str, Tensor]</code> <p>A batch with two items: - <code>'input'</code>: a <code>BatchedTensor</code> of type float and     shape <code>(num_examples, feature_size)</code>. This     tensor represents the input features. - <code>'target'</code>: a <code>BatchedTensor</code> of type float and     shape <code>(num_examples,)</code>. This tensor represents     the targets.</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>if one of the parameters is not valid.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.example import make_sparse_uncorrelated_regression\n&gt;&gt;&gt; data = make_sparse_uncorrelated_regression(num_examples=10)\n&gt;&gt;&gt; data\n{'target': tensor([...]), 'feature': tensor([[...]])}\n</code></pre>"},{"location":"refs/example/#startorch.example.make_swiss_roll","title":"startorch.example.make_swiss_roll","text":"<pre><code>make_swiss_roll(\n    num_examples: int = 100,\n    noise_std: float = 0.0,\n    spin: float = 1.5,\n    hole: bool = False,\n    generator: Generator | None = None,\n) -&gt; dict[str, Tensor]\n</code></pre> <p>Generate a toy manifold dataset based on Swiss roll pattern.</p> <p>The implementation is based on <code>sklearn.datasets.make_swiss_roll</code>.</p> <p>Parameters:</p> Name Type Description Default <code>num_examples</code> <code>int</code> <p>The number of examples.</p> <code>100</code> <code>noise_std</code> <code>float</code> <p>The standard deviation of the Gaussian noise.</p> <code>0.0</code> <code>spin</code> <code>float</code> <p>The number of spins of the Swiss roll.</p> <code>1.5</code> <code>hole</code> <code>bool</code> <p>If <code>True</code> generates the Swiss roll with hole dataset.</p> <code>False</code> <code>generator</code> <code>Generator | None</code> <p>An optional random generator.</p> <code>None</code> <p>Returns:</p> Type Description <code>dict[str, Tensor]</code> <p>A batch with two items: - <code>'input'</code>: a <code>BatchedTensor</code> of type float and     shape <code>(num_examples, 3)</code>. This     tensor represents the input features. - <code>'target'</code>: a <code>BatchedTensor</code> of type float and     shape <code>(num_examples,)</code>. This tensor represents     the targets.</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>if one of the parameters is not valid.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.example import make_swiss_roll\n&gt;&gt;&gt; batch = make_swiss_roll(num_examples=10)\n&gt;&gt;&gt; batch\n{'target': tensor([...]), 'feature': tensor([[...]])}\n</code></pre>"},{"location":"refs/example/#startorch.example.setup_example_generator","title":"startorch.example.setup_example_generator","text":"<pre><code>setup_example_generator(\n    generator: BaseExampleGenerator | dict,\n) -&gt; BaseExampleGenerator\n</code></pre> <p>Set up an example generator.</p> <p>The time series generator is instantiated from its configuration by using the <code>BaseExampleGenerator</code> factory function.</p> <p>Parameters:</p> Name Type Description Default <code>generator</code> <code>BaseExampleGenerator | dict</code> <p>An example generator or its configuration.</p> required <p>Returns:</p> Type Description <code>BaseExampleGenerator</code> <p>An example generator.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.example import setup_example_generator\n&gt;&gt;&gt; generator = setup_example_generator(\n...     {\"_target_\": \"startorch.example.HypercubeClassification\"}\n... )\n&gt;&gt;&gt; generator\nHypercubeClassificationExampleGenerator(num_classes=50, feature_size=64, noise_std=0.2)\n</code></pre>"},{"location":"refs/periodic/","title":"periodic","text":""},{"location":"refs/periodic/#startorch.periodic.sequence","title":"startorch.periodic.sequence","text":"<p>Contain some periodic sequence generators.</p>"},{"location":"refs/periodic/#startorch.periodic.sequence.BasePeriodicSequenceGenerator","title":"startorch.periodic.sequence.BasePeriodicSequenceGenerator","text":"<p>               Bases: <code>ABC</code></p> <p>Define the base class to generate periodic sequences.</p> <p>A child class has to implement the <code>generate</code> method.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; from startorch.periodic.sequence import Repeat\n&gt;&gt;&gt; from startorch.sequence import RandUniform\n&gt;&gt;&gt; generator = Repeat(RandUniform())\n&gt;&gt;&gt; generator\nRepeatPeriodicSequenceGenerator(\n  (generator): RandUniformSequenceGenerator(low=0.0, high=1.0, feature_size=(1,))\n)\n&gt;&gt;&gt; generator.generate(seq_len=12, period=4, batch_size=4)\ntensor([[...]])\n</code></pre>"},{"location":"refs/periodic/#startorch.periodic.sequence.BasePeriodicSequenceGenerator.generate","title":"startorch.periodic.sequence.BasePeriodicSequenceGenerator.generate  <code>abstractmethod</code>","text":"<pre><code>generate(\n    seq_len: int,\n    period: int,\n    batch_size: int = 1,\n    rng: Generator | None = None,\n) -&gt; Tensor\n</code></pre> <p>Generate a batch of periodic sequences.</p> <p>All the sequences in the batch have the same length.</p> <p>Parameters:</p> Name Type Description Default <code>seq_len</code> <code>int</code> <p>The sequence length.</p> required <code>period</code> <code>int</code> <p>The period.</p> required <code>batch_size</code> <code>int</code> <p>The batch size.</p> <code>1</code> <code>rng</code> <code>Generator | None</code> <p>An optional random number generator.</p> <code>None</code> <p>Returns:</p> Type Description <code>Tensor</code> <p>A batch of sequences represented as a tensor of shape <code>(batch_size, sequence_length, *)</code> where <code>*</code> means any number of dimensions.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; from startorch.periodic.sequence import Repeat\n&gt;&gt;&gt; from startorch.sequence import RandUniform\n&gt;&gt;&gt; generator = Repeat(RandUniform())\n&gt;&gt;&gt; generator.generate(seq_len=12, period=4, batch_size=4)\ntensor([[...]])\n</code></pre>"},{"location":"refs/periodic/#startorch.periodic.sequence.Repeat","title":"startorch.periodic.sequence.Repeat","text":"<p>               Bases: <code>BasePeriodicSequenceGenerator</code></p> <p>Implement a class to generate periodic sequences by using a <code>BaseSequenceGenerator</code> object and repeating the generated sequence.</p> <p>Parameters:</p> Name Type Description Default <code>generator</code> <code>BaseSequenceGenerator | dict</code> <p>A sequence generator or its configuration.</p> required <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; from startorch.periodic.sequence import Repeat\n&gt;&gt;&gt; from startorch.sequence import RandUniform\n&gt;&gt;&gt; generator = Repeat(RandUniform())\n&gt;&gt;&gt; generator\nRepeatPeriodicSequenceGenerator(\n  (generator): RandUniformSequenceGenerator(low=0.0, high=1.0, feature_size=(1,))\n)\n&gt;&gt;&gt; generator.generate(seq_len=12, period=4, batch_size=4)\ntensor([[...]])\n</code></pre>"},{"location":"refs/periodic/#startorch.periodic.sequence.RepeatPeriodicSequenceGenerator","title":"startorch.periodic.sequence.RepeatPeriodicSequenceGenerator","text":"<p>               Bases: <code>BasePeriodicSequenceGenerator</code></p> <p>Implement a class to generate periodic sequences by using a <code>BaseSequenceGenerator</code> object and repeating the generated sequence.</p> <p>Parameters:</p> Name Type Description Default <code>generator</code> <code>BaseSequenceGenerator | dict</code> <p>A sequence generator or its configuration.</p> required <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; from startorch.periodic.sequence import Repeat\n&gt;&gt;&gt; from startorch.sequence import RandUniform\n&gt;&gt;&gt; generator = Repeat(RandUniform())\n&gt;&gt;&gt; generator\nRepeatPeriodicSequenceGenerator(\n  (generator): RandUniformSequenceGenerator(low=0.0, high=1.0, feature_size=(1,))\n)\n&gt;&gt;&gt; generator.generate(seq_len=12, period=4, batch_size=4)\ntensor([[...]])\n</code></pre>"},{"location":"refs/periodic/#startorch.periodic.sequence.SineWave","title":"startorch.periodic.sequence.SineWave","text":"<p>               Bases: <code>BasePeriodicSequenceGenerator</code></p> <p>Implement a periodic sequence generator that generates periodic sequence by sampling values with a sine wave pattern.</p> <p>The sequences are generated by using the following formula:</p> <p><code>output = amplitude * sin(2 * pi * frequency * value + phase)</code></p> <p>Parameters:</p> Name Type Description Default <code>value</code> <code>BasePeriodicSequenceGenerator | dict</code> <p>A sequence generator (or its configuration) to generate the sequence values.</p> required <code>phase</code> <code>BasePeriodicSequenceGenerator | dict</code> <p>A sequence generator (or its configuration) to generate the phase values.</p> required <code>amplitude</code> <code>BasePeriodicSequenceGenerator | dict</code> <p>A sequence generator (or its configuration) to generate the amplitude values.</p> required <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; from startorch.periodic.sequence import Repeat, SineWave\n&gt;&gt;&gt; from startorch.sequence import RandUniform\n&gt;&gt;&gt; generator = SineWave(\n...     value=Repeat(RandUniform(low=-1.0, high=1.0)),\n...     phase=Repeat(RandUniform(low=-1.0, high=1.0)),\n...     amplitude=Repeat(RandUniform(low=-1.0, high=1.0)),\n... )\n&gt;&gt;&gt; generator\nSineWavePeriodicSequenceGenerator(\n  (value): RepeatPeriodicSequenceGenerator(\n      (generator): RandUniformSequenceGenerator(low=-1.0, high=1.0, feature_size=(1,))\n    )\n  (phase): RepeatPeriodicSequenceGenerator(\n      (generator): RandUniformSequenceGenerator(low=-1.0, high=1.0, feature_size=(1,))\n    )\n  (amplitude): RepeatPeriodicSequenceGenerator(\n      (generator): RandUniformSequenceGenerator(low=-1.0, high=1.0, feature_size=(1,))\n    )\n)\n&gt;&gt;&gt; generator.generate(seq_len=12, period=4, batch_size=4)\ntensor([[...]])\n</code></pre>"},{"location":"refs/periodic/#startorch.periodic.sequence.SineWavePeriodicSequenceGenerator","title":"startorch.periodic.sequence.SineWavePeriodicSequenceGenerator","text":"<p>               Bases: <code>BasePeriodicSequenceGenerator</code></p> <p>Implement a periodic sequence generator that generates periodic sequence by sampling values with a sine wave pattern.</p> <p>The sequences are generated by using the following formula:</p> <p><code>output = amplitude * sin(2 * pi * frequency * value + phase)</code></p> <p>Parameters:</p> Name Type Description Default <code>value</code> <code>BasePeriodicSequenceGenerator | dict</code> <p>A sequence generator (or its configuration) to generate the sequence values.</p> required <code>phase</code> <code>BasePeriodicSequenceGenerator | dict</code> <p>A sequence generator (or its configuration) to generate the phase values.</p> required <code>amplitude</code> <code>BasePeriodicSequenceGenerator | dict</code> <p>A sequence generator (or its configuration) to generate the amplitude values.</p> required <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; from startorch.periodic.sequence import Repeat, SineWave\n&gt;&gt;&gt; from startorch.sequence import RandUniform\n&gt;&gt;&gt; generator = SineWave(\n...     value=Repeat(RandUniform(low=-1.0, high=1.0)),\n...     phase=Repeat(RandUniform(low=-1.0, high=1.0)),\n...     amplitude=Repeat(RandUniform(low=-1.0, high=1.0)),\n... )\n&gt;&gt;&gt; generator\nSineWavePeriodicSequenceGenerator(\n  (value): RepeatPeriodicSequenceGenerator(\n      (generator): RandUniformSequenceGenerator(low=-1.0, high=1.0, feature_size=(1,))\n    )\n  (phase): RepeatPeriodicSequenceGenerator(\n      (generator): RandUniformSequenceGenerator(low=-1.0, high=1.0, feature_size=(1,))\n    )\n  (amplitude): RepeatPeriodicSequenceGenerator(\n      (generator): RandUniformSequenceGenerator(low=-1.0, high=1.0, feature_size=(1,))\n    )\n)\n&gt;&gt;&gt; generator.generate(seq_len=12, period=4, batch_size=4)\ntensor([[...]])\n</code></pre>"},{"location":"refs/periodic/#startorch.periodic.sequence.is_periodic_sequence_generator_config","title":"startorch.periodic.sequence.is_periodic_sequence_generator_config","text":"<pre><code>is_periodic_sequence_generator_config(config: dict) -&gt; bool\n</code></pre> <p>Indicate if the input configuration is a configuration for a <code>BasePeriodicSequenceGenerator</code>.</p> <p>This function only checks if the value of the key  <code>_target_</code> is valid. It does not check the other values. If <code>_target_</code> indicates a function, the returned type hint is used to check the class.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>dict</code> <p>The configuration to check.</p> required <p>Returns:</p> Type Description <code>bool</code> <p><code>True</code> if the input configuration is a configuration for a <code>BasePeriodicSequenceGenerator</code> object.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.periodic.sequence import is_periodic_sequence_generator_config\n&gt;&gt;&gt; is_periodic_sequence_generator_config(\n...     {\n...         \"_target_\": \"startorch.periodic.sequence.Repeat\",\n...         \"generator\": {\"_target_\": \"startorch.sequence.RandUniform\"},\n...     }\n... )\nTrue\n</code></pre>"},{"location":"refs/periodic/#startorch.periodic.sequence.setup_periodic_sequence_generator","title":"startorch.periodic.sequence.setup_periodic_sequence_generator","text":"<pre><code>setup_periodic_sequence_generator(\n    generator: BasePeriodicSequenceGenerator | dict,\n) -&gt; BasePeriodicSequenceGenerator\n</code></pre> <p>Set up a periodic sequence generator.</p> <p>The sequence generator is instantiated from its configuration by using the <code>BasePeriodicSequenceGenerator</code> factory function.</p> <p>Parameters:</p> Name Type Description Default <code>generator</code> <code>BasePeriodicSequenceGenerator | dict</code> <p>A periodic sequence generator or its configuration.</p> required <p>Returns:</p> Type Description <code>BasePeriodicSequenceGenerator</code> <p>A periodic sequence generator.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.periodic.sequence import setup_periodic_sequence_generator\n&gt;&gt;&gt; setup_periodic_sequence_generator(\n...     {\n...         \"_target_\": \"startorch.periodic.sequence.Repeat\",\n...         \"generator\": {\"_target_\": \"startorch.sequence.RandUniform\"},\n...     }\n... )\nRepeatPeriodicSequenceGenerator(\n  (generator): RandUniformSequenceGenerator(low=0.0, high=1.0, feature_size=(1,))\n)\n</code></pre>"},{"location":"refs/periodic/#startorch.periodic.timeseries","title":"startorch.periodic.timeseries","text":"<p>Contain some periodic time series generators.</p>"},{"location":"refs/periodic/#startorch.periodic.timeseries.BasePeriodicTimeSeriesGenerator","title":"startorch.periodic.timeseries.BasePeriodicTimeSeriesGenerator","text":"<p>               Bases: <code>ABC</code></p> <p>Define the base class to generate periodic time series.</p> <p>A child class has to implement the <code>generate</code> method.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.periodic.timeseries import Repeat\n&gt;&gt;&gt; from startorch.timeseries import TimeSeries\n&gt;&gt;&gt; from startorch.sequence import RandUniform\n&gt;&gt;&gt; generator = Repeat(TimeSeries({\"value\": RandUniform(), \"time\": RandUniform()}))\n&gt;&gt;&gt; generator\nRepeatPeriodicTimeSeriesGenerator(\n  (generator): TimeSeriesGenerator(\n      (value): RandUniformSequenceGenerator(low=0.0, high=1.0, feature_size=(1,))\n      (time): RandUniformSequenceGenerator(low=0.0, high=1.0, feature_size=(1,))\n    )\n)\n&gt;&gt;&gt; generator.generate(seq_len=12, period=4, batch_size=4)\n{'value': tensor([[...]]), 'time': tensor([[...]])}\n</code></pre>"},{"location":"refs/periodic/#startorch.periodic.timeseries.BasePeriodicTimeSeriesGenerator.generate","title":"startorch.periodic.timeseries.BasePeriodicTimeSeriesGenerator.generate  <code>abstractmethod</code>","text":"<pre><code>generate(\n    seq_len: int,\n    period: int,\n    batch_size: int = 1,\n    rng: Generator | None = None,\n) -&gt; dict[Hashable, Tensor]\n</code></pre> <p>Generate a batch of periodic time series.</p> <p>All the time series in the batch have the same length.</p> <p>Parameters:</p> Name Type Description Default <code>seq_len</code> <code>int</code> <p>The sequence length.</p> required <code>period</code> <code>int</code> <p>The period.</p> required <code>batch_size</code> <code>int</code> <p>The batch size.</p> <code>1</code> <code>rng</code> <code>Generator | None</code> <p>An optional random number generator.</p> <code>None</code> <p>Returns:</p> Type Description <code>dict[Hashable, Tensor]</code> <p>A batch of periodic time series.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.periodic.timeseries import Repeat\n&gt;&gt;&gt; from startorch.timeseries import TimeSeries\n&gt;&gt;&gt; from startorch.sequence import RandUniform\n&gt;&gt;&gt; generator = Repeat(TimeSeries({\"value\": RandUniform(), \"time\": RandUniform()}))\n&gt;&gt;&gt; generator.generate(seq_len=12, period=4, batch_size=4)\n{'value': tensor([[...]]), 'time': tensor([[...]])}\n</code></pre>"},{"location":"refs/periodic/#startorch.periodic.timeseries.Repeat","title":"startorch.periodic.timeseries.Repeat","text":"<p>               Bases: <code>BasePeriodicTimeSeriesGenerator</code></p> <p>Implement a class to generate periodic sequences by using a <code>BaseTimeSeriesGenerator</code> object and repeating the generated sequence.</p> <p>Parameters:</p> Name Type Description Default <code>generator</code> <code>BaseTimeSeriesGenerator | dict</code> <p>A sequence generator or its configuration.</p> required <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.periodic.timeseries import Repeat\n&gt;&gt;&gt; from startorch.timeseries import TimeSeries\n&gt;&gt;&gt; from startorch.sequence import RandUniform\n&gt;&gt;&gt; generator = Repeat(TimeSeries({\"value\": RandUniform(), \"time\": RandUniform()}))\n&gt;&gt;&gt; generator\nRepeatPeriodicTimeSeriesGenerator(\n  (generator): TimeSeriesGenerator(\n      (value): RandUniformSequenceGenerator(low=0.0, high=1.0, feature_size=(1,))\n      (time): RandUniformSequenceGenerator(low=0.0, high=1.0, feature_size=(1,))\n    )\n)\n&gt;&gt;&gt; generator.generate(seq_len=12, period=4, batch_size=4)\n{'value': tensor([[...]]), 'time': tensor([[...]])}\n</code></pre>"},{"location":"refs/periodic/#startorch.periodic.timeseries.RepeatPeriodicTimeSeriesGenerator","title":"startorch.periodic.timeseries.RepeatPeriodicTimeSeriesGenerator","text":"<p>               Bases: <code>BasePeriodicTimeSeriesGenerator</code></p> <p>Implement a class to generate periodic sequences by using a <code>BaseTimeSeriesGenerator</code> object and repeating the generated sequence.</p> <p>Parameters:</p> Name Type Description Default <code>generator</code> <code>BaseTimeSeriesGenerator | dict</code> <p>A sequence generator or its configuration.</p> required <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.periodic.timeseries import Repeat\n&gt;&gt;&gt; from startorch.timeseries import TimeSeries\n&gt;&gt;&gt; from startorch.sequence import RandUniform\n&gt;&gt;&gt; generator = Repeat(TimeSeries({\"value\": RandUniform(), \"time\": RandUniform()}))\n&gt;&gt;&gt; generator\nRepeatPeriodicTimeSeriesGenerator(\n  (generator): TimeSeriesGenerator(\n      (value): RandUniformSequenceGenerator(low=0.0, high=1.0, feature_size=(1,))\n      (time): RandUniformSequenceGenerator(low=0.0, high=1.0, feature_size=(1,))\n    )\n)\n&gt;&gt;&gt; generator.generate(seq_len=12, period=4, batch_size=4)\n{'value': tensor([[...]]), 'time': tensor([[...]])}\n</code></pre>"},{"location":"refs/periodic/#startorch.periodic.timeseries.is_periodic_timeseries_generator_config","title":"startorch.periodic.timeseries.is_periodic_timeseries_generator_config","text":"<pre><code>is_periodic_timeseries_generator_config(\n    config: dict,\n) -&gt; bool\n</code></pre> <p>Indicate if the input configuration is a configuration for a <code>BasePeriodicTimeSeriesGenerator</code>.</p> <p>This function only checks if the value of the key  <code>_target_</code> is valid. It does not check the other values. If <code>_target_</code> indicates a function, the returned type hint is used to check the class.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>dict</code> <p>The configuration to check.</p> required <p>Returns:</p> Type Description <code>bool</code> <p><code>True</code> if the input configuration is a configuration for a <code>BasePeriodicTimeSeriesGenerator</code> object.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.periodic.timeseries import is_periodic_timeseries_generator_config\n&gt;&gt;&gt; is_periodic_timeseries_generator_config(\n...     {\n...         \"_target_\": \"startorch.periodic.timeseries.Repeat\",\n...         \"generator\": {\n...             \"_target_\": \"startorch.timeseries.TimeSeries\",\n...             \"sequences\": {\n...                 \"value\": {\"_target_\": \"startorch.sequence.RandUniform\"},\n...                 \"time\": {\"_target_\": \"startorch.sequence.RandUniform\"},\n...             },\n...         },\n...     }\n... )\nTrue\n</code></pre>"},{"location":"refs/periodic/#startorch.periodic.timeseries.setup_periodic_timeseries_generator","title":"startorch.periodic.timeseries.setup_periodic_timeseries_generator","text":"<pre><code>setup_periodic_timeseries_generator(\n    generator: BasePeriodicTimeSeriesGenerator | dict,\n) -&gt; BasePeriodicTimeSeriesGenerator\n</code></pre> <p>Set up a periodic time series generator.</p> <p>The time series generator is instantiated from its configuration by using the <code>BasePeriodicTimeSeriesGenerator</code> factory function.</p> <p>Parameters:</p> Name Type Description Default <code>generator</code> <code>BasePeriodicTimeSeriesGenerator | dict</code> <p>A periodic time series generator or its configuration.</p> required <p>Returns:</p> Type Description <code>BasePeriodicTimeSeriesGenerator</code> <p>A periodic time series generator.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.periodic.timeseries import setup_periodic_timeseries_generator\n&gt;&gt;&gt; setup_periodic_timeseries_generator(\n...     {\n...         \"_target_\": \"startorch.periodic.timeseries.Repeat\",\n...         \"generator\": {\n...             \"_target_\": \"startorch.timeseries.TimeSeries\",\n...             \"sequences\": {\n...                 \"value\": {\"_target_\": \"startorch.sequence.RandUniform\"},\n...                 \"time\": {\"_target_\": \"startorch.sequence.RandUniform\"},\n...             },\n...         },\n...     }\n... )\nRepeatPeriodicTimeSeriesGenerator(\n  (generator): TimeSeriesGenerator(\n      (value): RandUniformSequenceGenerator(low=0.0, high=1.0, feature_size=(1,))\n      (time): RandUniformSequenceGenerator(low=0.0, high=1.0, feature_size=(1,))\n    )\n)\n</code></pre>"},{"location":"refs/plot/","title":"plot","text":""},{"location":"refs/plot/#startorch.plot.matplotlib","title":"startorch.plot.matplotlib","text":"<p>Contain functions to plot the generated data with <code>matplotlib</code>.</p>"},{"location":"refs/plot/#startorch.plot.matplotlib.hist_feature","title":"startorch.plot.matplotlib.hist_feature","text":"<pre><code>hist_feature(\n    features: Tensor | ndarray,\n    feature_names: Sequence[str] | None = None,\n    ncols: int = 2,\n    figsize: tuple[float, float] = (6, 4),\n    **kwargs: Any\n) -&gt; Figure\n</code></pre> <p>Plot the distribution of each feature.</p> <p>If the input has <code>n</code> features, this function returns a figure with <code>n</code> histograms: one for each features.</p> <p>Parameters:</p> Name Type Description Default <code>features</code> <code>Tensor | ndarray</code> <p>The features. It must be a tensor of shape <code>(d0, d1, ..., dn)</code>.</p> required <code>feature_names</code> <code>Sequence[str] | None</code> <p>The feature names. If <code>None</code>, the feature names are generated automatically.</p> <code>None</code> <code>ncols</code> <code>int</code> <p>The number of columns.</p> <code>2</code> <code>figsize</code> <code>tuple[float, float]</code> <p>The individual figure size in pixels. The first dimension is the width and the second is the height.</p> <code>(6, 4)</code> <code>**kwargs</code> <code>Any</code> <p>Additional keyword arguments for <code>plt.hist</code>.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Figure</code> <p><code>matplotlib.pyplot.Figure</code>: The generated figure.</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>if the <code>features</code> shape is invalid</p> <code>RuntimeError</code> <p>if <code>features</code> and <code>feature_names</code> are not consistent</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.plot.matplotlib import hist_feature\n&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; fig = hist_feature(np.random.rand(10, 5))\n</code></pre>"},{"location":"refs/plot/#startorch.plot.matplotlib.hist_sequence","title":"startorch.plot.matplotlib.hist_sequence","text":"<pre><code>hist_sequence(\n    sequence: BaseSequenceGenerator,\n    bins: int = 500,\n    seq_len: int = 1000,\n    batch_size: int = 10000,\n    num_batches: int = 1,\n    rng: int | Generator = 13683624337160779813,\n    figsize: tuple[float, float] = (16, 5),\n    scale: str = \"identity\",\n    **kwargs: Any\n) -&gt; Figure\n</code></pre> <p>Plot the distribution from a sequence generator.</p> <p>Parameters:</p> Name Type Description Default <code>sequence</code> <code>BaseSequenceGenerator</code> <p>The sequence generator.</p> required <code>bins</code> <code>int</code> <p>The number of histogram bins.</p> <code>500</code> <code>seq_len</code> <code>int</code> <p>The sequence length.</p> <code>1000</code> <code>batch_size</code> <code>int</code> <p>The batch size.</p> <code>10000</code> <code>num_batches</code> <code>int</code> <p>The number of batches to generate.</p> <code>1</code> <code>rng</code> <code>int | Generator</code> <p>A random number generator or a random seed.</p> <code>13683624337160779813</code> <code>figsize</code> <code>tuple[float, float]</code> <p>The figure size.</p> <code>(16, 5)</code> <code>scale</code> <code>str</code> <p>The transformation scale of the features.</p> <code>'identity'</code> <code>**kwargs</code> <code>Any</code> <p>Additional keyword arguments for <code>plt.hist</code>.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Figure</code> <p>The generated figure.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.plot.matplotlib import hist_sequence\n&gt;&gt;&gt; from startorch.sequence import RandUniform\n&gt;&gt;&gt; fig = hist_sequence(RandUniform(low=-5, high=5))\n</code></pre>"},{"location":"refs/plot/#startorch.plot.matplotlib.plot_sequence","title":"startorch.plot.matplotlib.plot_sequence","text":"<pre><code>plot_sequence(\n    sequence: BaseSequenceGenerator,\n    seq_len: int = 128,\n    batch_size: int = 1,\n    num_batches: int = 1,\n    rng: int | Generator = 13683624337160779813,\n    figsize: tuple[float, float] = (16, 5),\n    xscale: str = \"linear\",\n    yscale: str = \"linear\",\n    **kwargs: Any\n) -&gt; Figure\n</code></pre> <p>Plot some sequences generated from a sequence generator.</p> <p>Parameters:</p> Name Type Description Default <code>sequence</code> <code>BaseSequenceGenerator</code> <p>The sequence generator.</p> required <code>seq_len</code> <code>int</code> <p>The sequence length.</p> <code>128</code> <code>batch_size</code> <code>int</code> <p>The batch size.</p> <code>1</code> <code>num_batches</code> <code>int</code> <p>The number of batches.</p> <code>1</code> <code>rng</code> <code>int | Generator</code> <p>A random number generator or a random seed.</p> <code>13683624337160779813</code> <code>figsize</code> <code>tuple[float, float]</code> <p>The figure size.</p> <code>(16, 5)</code> <code>xscale</code> <code>str</code> <p>The x-axis scale.</p> <code>'linear'</code> <code>yscale</code> <code>str</code> <p>The y-axis scale.</p> <code>'linear'</code> <code>**kwargs</code> <code>Any</code> <p>Additional keyword arguments for <code>plt.plot</code>.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Figure</code> <p>The generated figure.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.plot.matplotlib import plot_sequence\n&gt;&gt;&gt; from startorch.sequence import RandUniform\n&gt;&gt;&gt; fig = plot_sequence(RandUniform(low=-5, high=5), batch_size=4)\n</code></pre>"},{"location":"refs/plot/#startorch.plot.plotly","title":"startorch.plot.plotly","text":"<p>Contain functions to plot the generated data with <code>plotly</code>.</p>"},{"location":"refs/plot/#startorch.plot.plotly.hist_feature","title":"startorch.plot.plotly.hist_feature","text":"<pre><code>hist_feature(\n    features: Tensor | ndarray,\n    feature_names: Sequence[str] | None = None,\n    ncols: int = 2,\n    figsize: tuple[int, int] = (250, 200),\n    **kwargs: Any\n) -&gt; Figure\n</code></pre> <p>Plot the distribution of each feature.</p> <p>If the input has <code>n</code> features, this function returns a figure with <code>n</code> histograms: one for each feature.</p> <p>Parameters:</p> Name Type Description Default <code>features</code> <code>Tensor | ndarray</code> <p>The features. It must be a tensor of shape <code>(d0, d1, ..., dn)</code>.</p> required <code>feature_names</code> <code>Sequence[str] | None</code> <p>The feature names. If <code>None</code>, the feature names are generated automatically.</p> <code>None</code> <code>ncols</code> <code>int</code> <p>The number of columns.</p> <code>2</code> <code>figsize</code> <code>tuple[int, int]</code> <p>The individual figure size in pixels. The first dimension is the width and the second is the height.</p> <code>(250, 200)</code> <code>**kwargs</code> <code>Any</code> <p>Additional keyword arguments for <code>plotly.graph_objects.Histogram</code>.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Figure</code> <p>The generated figure.</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>if the <code>features</code> shape is invalid</p> <code>RuntimeError</code> <p>if <code>features</code> and <code>feature_names</code> are not consistent</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.plot.plotly import hist_feature\n&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; fig = hist_feature(np.random.rand(10, 5))\n</code></pre>"},{"location":"refs/plot/#startorch.plot.plotly.hist_sequence","title":"startorch.plot.plotly.hist_sequence","text":"<pre><code>hist_sequence(\n    sequence: BaseSequenceGenerator,\n    bins: int = 500,\n    seq_len: int = 1000,\n    batch_size: int = 10000,\n    num_batches: int = 1,\n    rng: int | Generator = 13683624337160779813,\n    figsize: tuple[int, int] = (800, 600),\n    scale: str = \"identity\",\n    **kwargs: Any\n) -&gt; Figure\n</code></pre> <p>Plot the distribution from a sequence generator.</p> <p>Parameters:</p> Name Type Description Default <code>sequence</code> <code>BaseSequenceGenerator</code> <p>The sequence generator.</p> required <code>bins</code> <code>int</code> <p>The number of histogram bins.</p> <code>500</code> <code>seq_len</code> <code>int</code> <p>The sequence length.</p> <code>1000</code> <code>batch_size</code> <code>int</code> <p>The batch size.</p> <code>10000</code> <code>num_batches</code> <code>int</code> <p>The number of batches to generate.</p> <code>1</code> <code>rng</code> <code>int | Generator</code> <p>A random number generator or a random seed.</p> <code>13683624337160779813</code> <code>figsize</code> <code>tuple[int, int]</code> <p>The figure size.</p> <code>(800, 600)</code> <code>scale</code> <code>str</code> <p>A scale transformation of the features.</p> <code>'identity'</code> <code>**kwargs</code> <code>Any</code> <p>Additional keyword arguments for <code>plotly.graph_objects.Histogram</code>.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Figure</code> <p>The generated figure.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.plot.plotly import hist_sequence\n&gt;&gt;&gt; from startorch.sequence import RandUniform\n&gt;&gt;&gt; fig = hist_sequence(RandUniform(low=-5, high=5))\n</code></pre>"},{"location":"refs/plot/#startorch.plot.plotly.plot_sequence","title":"startorch.plot.plotly.plot_sequence","text":"<pre><code>plot_sequence(\n    sequence: BaseSequenceGenerator,\n    seq_len: int = 128,\n    batch_size: int = 1,\n    num_batches: int = 1,\n    rng: int | Generator = 13683624337160779813,\n    **kwargs: Any\n) -&gt; Figure\n</code></pre> <p>Plot some sequences generated from a sequence generator.</p> <p>Parameters:</p> Name Type Description Default <code>sequence</code> <code>BaseSequenceGenerator</code> <p>The sequence generator.</p> required <code>seq_len</code> <code>int</code> <p>The sequence length.</p> <code>128</code> <code>batch_size</code> <code>int</code> <p>The batch size.</p> <code>1</code> <code>num_batches</code> <code>int</code> <p>The number of batches.</p> <code>1</code> <code>rng</code> <code>int | Generator</code> <p>A random number generator or a random seed.</p> <code>13683624337160779813</code> <code>**kwargs</code> <code>Any</code> <p>Additional keyword arguments for <code>plt.plot</code>.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Figure</code> <p>The generated figure.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.plot.plotly import plot_sequence\n&gt;&gt;&gt; from startorch.sequence import RandUniform\n&gt;&gt;&gt; fig = plot_sequence(RandUniform(low=-5, high=5), batch_size=4)\n</code></pre>"},{"location":"refs/random/","title":"random","text":""},{"location":"refs/random/#startorch.random","title":"startorch.random","text":"<p>Contain functions to generate tensors filled with random values.</p>"},{"location":"refs/random/#startorch.random.asinh_uniform","title":"startorch.random.asinh_uniform","text":"<pre><code>asinh_uniform(\n    low: Tensor,\n    high: Tensor,\n    generator: Generator | None = None,\n) -&gt; Tensor\n</code></pre> <p>Create a tensor filled with values sampled from a uniform distribution in the inverse hyperbolic sine space.</p> <p>Parameters:</p> Name Type Description Default <code>low</code> <code>Tensor</code> <p>The minimum values (inclusive). It must be a float tensor of shape <code>(d0, d1, ..., dn)</code>.</p> required <code>high</code> <code>Tensor</code> <p>The maximum values (exclusive). It must be a float tensor of shape <code>(d0, d1, ..., dn)</code>.</p> required <code>generator</code> <code>Generator | None</code> <p>An optional random generator.</p> <code>None</code> <p>Returns:</p> Type Description <code>Tensor</code> <p>A tensor of shape <code>(d0, d1, ..., dn)</code> filled with values sampled from a uniform distribution in the inverse hyperbolic sine space where the minimum and maximum values are given as input.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>if the <code>low</code> and  <code>high</code> parameters  are not valid.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.random import asinh_uniform\n&gt;&gt;&gt; asinh_uniform(\n...     low=torch.tensor([-10.0, 0.0, 1.0]),\n...     high=torch.tensor([1.0, 10.0, 100.0]),\n... )\ntensor([...])\n</code></pre>"},{"location":"refs/random/#startorch.random.cauchy","title":"startorch.random.cauchy","text":"<pre><code>cauchy(\n    loc: Tensor,\n    scale: Tensor,\n    generator: Generator | None = None,\n) -&gt; Tensor\n</code></pre> <p>Create a tensor filled with values sampled from a Cauchy distribution.</p> <p>Unlike <code>rand_cauchy</code>, this function allows to sample values from different Cauchy distributions at the same time. The shape of the <code>loc</code> and <code>scale</code> tensors are used to infer the output size.</p> <p>Parameters:</p> Name Type Description Default <code>loc</code> <code>Tensor</code> <p>The location/median of the Cauchy distribution. It must be a float tensor of shape <code>(d0, d1, ..., dn)</code>.</p> required <code>scale</code> <code>Tensor</code> <p>The standard deviation of the Cauchy distribution. It must be a float tensor of shape <code>(d0, d1, ..., dn)</code>.</p> required <code>generator</code> <code>Generator | None</code> <p>An optional random generator.</p> <code>None</code> <p>Returns:</p> Type Description <code>Tensor</code> <p>A tensor of shape <code>(d0, d1, ..., dn)</code> filled with values sampled from a Cauchy distribution.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>if the <code>loc</code> and <code>scale</code> parameters are not valid.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; from startorch.random import cauchy\n&gt;&gt;&gt; cauchy(loc=torch.tensor([-1.0, 0.0, 1.0]), scale=torch.tensor([1.0, 3.0, 5.0]))\ntensor([...])\n</code></pre>"},{"location":"refs/random/#startorch.random.exponential","title":"startorch.random.exponential","text":"<pre><code>exponential(\n    rate: Tensor, generator: Generator | None = None\n) -&gt; Tensor\n</code></pre> <p>Create a tensor filled with values sampled from an Exponential distribution.</p> <p>Unlike <code>rand_exponential</code>, this function allows to sample values from different Exponential distributions at the same time. The shape of the <code>rate</code> tensor is used to infer the output size.</p> <p>Parameters:</p> Name Type Description Default <code>rate</code> <code>Tensor</code> <p>The rates of the Exponential distribution. It must be a float tensor of shape <code>(d0, d1, ..., dn)</code>.</p> required <code>generator</code> <code>Generator | None</code> <p>An optional random generator.</p> <code>None</code> <p>Returns:</p> Type Description <code>Tensor</code> <p>A tensor of shape <code>(d0, d1, ..., dn)</code> filled with values sampled from an Exponential distribution.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>if the <code>rate</code> parameter is not valid.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; from startorch.random import exponential\n&gt;&gt;&gt; exponential(torch.tensor([1.0, 3.0, 5.0]))\ntensor([...])\n</code></pre>"},{"location":"refs/random/#startorch.random.half_cauchy","title":"startorch.random.half_cauchy","text":"<pre><code>half_cauchy(\n    scale: Tensor, generator: Generator | None = None\n) -&gt; Tensor\n</code></pre> <p>Create a tensor filled with values sampled from a half-Cauchy distribution.</p> <p>Unlike <code>rand_half_cauchy</code>, this function allows to sample values from different half-Cauchy distributions at the same time. The shape of the <code>scale</code> tensor is used to infer the output size.</p> <p>Parameters:</p> Name Type Description Default <code>scale</code> <code>Tensor</code> <p>The scale of the half-Cauchy distribution. It must be a float tensor of shape <code>(d0, d1, ..., dn)</code>.</p> required <code>generator</code> <code>Generator | None</code> <p>An optional random generator.</p> <code>None</code> <p>Returns:</p> Type Description <code>Tensor</code> <p>A tensor of shape <code>(d0, d1, ..., dn)</code> filled with values sampled from a half-Cauchy distribution.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>if the <code>scale</code> parameter is not valid.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; from startorch.random import half_cauchy\n&gt;&gt;&gt; half_cauchy(torch.tensor([1.0, 3.0, 5.0]))\ntensor([...])\n</code></pre>"},{"location":"refs/random/#startorch.random.half_normal","title":"startorch.random.half_normal","text":"<pre><code>half_normal(\n    std: Tensor, generator: Generator | None = None\n) -&gt; Tensor\n</code></pre> <p>Create a tensor filled with values sampled from a half-Normal distribution.</p> <p>Unlike <code>rand_half_normal</code>, this function allows to sample values from different half-Normal distributions at the same time. The shape of the <code>std</code> tensor is used to infer the output size.</p> <p>Parameters:</p> Name Type Description Default <code>std</code> <code>Tensor</code> <p>The standard deviation of the half-Normal distribution. It must be a float tensor of shape <code>(d0, d1, ..., dn)</code>.</p> required <code>generator</code> <code>Generator | None</code> <p>Specifies an optional random generator.</p> <code>None</code> <p>Returns:</p> Type Description <code>Tensor</code> <p>A tensor of shape <code>(d0, d1, ..., dn)</code> filled with values sampled from a half-Normal distribution.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>if the <code>std</code> parameter is not valid.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; from startorch.random import half_normal\n&gt;&gt;&gt; half_normal(torch.tensor([1.0, 3.0, 5.0]))\ntensor([...])\n</code></pre>"},{"location":"refs/random/#startorch.random.log_normal","title":"startorch.random.log_normal","text":"<pre><code>log_normal(\n    mean: Tensor,\n    std: Tensor,\n    generator: Generator | None = None,\n) -&gt; Tensor\n</code></pre> <p>Create a tensor filled with values sampled from a log-Normal distribution.</p> <p>Unlike <code>rand_log_normal</code>, this function allows to sample values from different log-Normal distributions at the same time. The shape of the <code>mean</code> and <code>std</code> tensors are used to infer the output size.</p> <p>Parameters:</p> Name Type Description Default <code>mean</code> <code>Tensor</code> <p>The mean of the log-Normal distribution. It must be a float tensor of shape <code>(d0, d1, ..., dn)</code>.</p> required <code>std</code> <code>Tensor</code> <p>The standard deviation of the log-Normal distribution. It must be a float tensor of shape <code>(d0, d1, ..., dn)</code>.</p> required <code>generator</code> <code>Generator | None</code> <p>An optional random generator.</p> <code>None</code> <p>Returns:</p> Type Description <code>Tensor</code> <p>A tensor of shape <code>(d0, d1, ..., dn)</code> filled with values sampled from a log-Normal distribution.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>if the <code>mean</code> and <code>std</code> parametera are not valid.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; from startorch.random import log_normal\n&gt;&gt;&gt; log_normal(torch.tensor([-1.0, 0.0, 1.0]), torch.tensor([1.0, 3.0, 5.0]))\ntensor([...])\n</code></pre>"},{"location":"refs/random/#startorch.random.log_uniform","title":"startorch.random.log_uniform","text":"<pre><code>log_uniform(\n    low: Tensor,\n    high: Tensor,\n    generator: Generator | None = None,\n) -&gt; Tensor\n</code></pre> <p>Create a tensor filled with values sampled from a uniform distribution in the log space.</p> <p>Parameters:</p> Name Type Description Default <code>low</code> <code>Tensor</code> <p>The minimum values (inclusive). It must be a float tensor of shape <code>(d0, d1, ..., dn)</code>.</p> required <code>high</code> <code>Tensor</code> <p>The maximum values (exclusive). It must be a float tensor of shape <code>(d0, d1, ..., dn)</code>.</p> required <code>generator</code> <code>Generator | None</code> <p>An optional random generator.</p> <code>None</code> <p>Returns:</p> Type Description <code>Tensor</code> <p>A tensor of shape <code>(d0, d1, ..., dn)</code> filled with values sampled from a uniform distribution in the log space where the minimum and maximum values are given as input.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>if the <code>low</code> and  <code>high</code> parameters  are not valid.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.random import log_uniform\n&gt;&gt;&gt; log_uniform(low=torch.tensor([0.01, 0.1, 1.0]), high=torch.tensor([1.0, 10.0, 100.0]))\ntensor([...])\n</code></pre>"},{"location":"refs/random/#startorch.random.normal","title":"startorch.random.normal","text":"<pre><code>normal(\n    mean: Tensor,\n    std: Tensor,\n    generator: Generator | None = None,\n) -&gt; Tensor\n</code></pre> <p>Create a tensor filled with values sampled from a Normal distribution.</p> <p>Parameters:</p> Name Type Description Default <code>mean</code> <code>Tensor</code> <p>The mean. It must be a float tensor of shape <code>(d0, d1, ..., dn)</code>.</p> required <code>std</code> <code>Tensor</code> <p>The standard deviation. It must be a float tensor of shape <code>(d0, d1, ..., dn)</code>.</p> required <code>generator</code> <code>Generator | None</code> <p>An optional random generator.</p> <code>None</code> <p>Returns:</p> Type Description <code>Tensor</code> <p>A tensor of shape <code>(d0, d1, ..., dn)</code> filled with values sampled from a Normal distribution.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>if the <code>mean</code> and <code>std</code> parameters are not valid.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; from startorch.random import normal\n&gt;&gt;&gt; normal(mean=torch.tensor([-1.0, 0.0, 1.0]), std=torch.tensor([1.0, 3.0, 5.0]))\ntensor([...])\n</code></pre>"},{"location":"refs/random/#startorch.random.rand_asinh_uniform","title":"startorch.random.rand_asinh_uniform","text":"<pre><code>rand_asinh_uniform(\n    size: list[int] | tuple[int, ...],\n    low: float,\n    high: float,\n    generator: Generator | None = None,\n) -&gt; Tensor\n</code></pre> <p>Create a tensor filled with values sampled from a uniform distribution in the inverse hyperbolic sine space.</p> <p>Parameters:</p> Name Type Description Default <code>size</code> <code>list[int] | tuple[int, ...]</code> <p>The tensor shape.</p> required <code>low</code> <code>float</code> <p>The minimum value (inclusive). This value needs to be positive.</p> required <code>high</code> <code>float</code> <p>The maximum value (exclusive).</p> required <code>generator</code> <code>Generator | None</code> <p>An optional random generator.</p> <code>None</code> <p>Returns:</p> Type Description <code>Tensor</code> <p>A tensor filled with values sampled from a uniform distribution in the inverse hyperbolic sine space.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>if the <code>low</code> and  <code>high</code> parameters  are not valid.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.random import rand_asinh_uniform\n&gt;&gt;&gt; rand_asinh_uniform((2, 3), low=-1000.0, high=1000.0)\ntensor([[...]])\n</code></pre>"},{"location":"refs/random/#startorch.random.rand_cauchy","title":"startorch.random.rand_cauchy","text":"<pre><code>rand_cauchy(\n    size: list[int] | tuple[int, ...],\n    loc: float = 0.0,\n    scale: float = 1.0,\n    generator: Generator | None = None,\n) -&gt; Tensor\n</code></pre> <p>Create a sequence of continuous variables sampled from a Cauchy distribution.</p> <p>Parameters:</p> Name Type Description Default <code>size</code> <code>list[int] | tuple[int, ...]</code> <p>The tensor shape.</p> required <code>loc</code> <code>float</code> <p>The location/median of the Cauchy distribution.</p> <code>0.0</code> <code>scale</code> <code>float</code> <p>The scale of the Cauchy distribution. This value has to be greater than 0.</p> <code>1.0</code> <code>generator</code> <code>Generator | None</code> <p>An optional random generator.</p> <code>None</code> <p>Returns:</p> Type Description <code>Tensor</code> <p>A tensor filled with values sampled from a Cauchy distribution.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>if the <code>scale</code> parameter is not valid.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; from startorch.random import rand_cauchy\n&gt;&gt;&gt; rand_cauchy((2, 3), loc=1.0, scale=2.0)\ntensor([[...]])\n</code></pre>"},{"location":"refs/random/#startorch.random.rand_exponential","title":"startorch.random.rand_exponential","text":"<pre><code>rand_exponential(\n    size: list[int] | tuple[int, ...],\n    rate: float = 1.0,\n    generator: Generator | None = None,\n) -&gt; Tensor\n</code></pre> <p>Create a tensor filled with values sampled from an Exponential distribution.</p> <p>Parameters:</p> Name Type Description Default <code>size</code> <code>list[int] | tuple[int, ...]</code> <p>The tensor shape.</p> required <code>rate</code> <code>float</code> <p>The rate of the Exponential distribution.</p> <code>1.0</code> <code>generator</code> <code>Generator | None</code> <p>An optional random generator.</p> <code>None</code> <p>Returns:</p> Type Description <code>Tensor</code> <p>A tensor filled with values sampled from an Exponential distribution.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>if the <code>rate</code> parameter is not valid.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; from startorch.random import rand_exponential\n&gt;&gt;&gt; rand_exponential((2, 3), rate=1.0)\ntensor([[...]])\n</code></pre>"},{"location":"refs/random/#startorch.random.rand_half_cauchy","title":"startorch.random.rand_half_cauchy","text":"<pre><code>rand_half_cauchy(\n    size: list[int] | tuple[int, ...],\n    scale: float = 1.0,\n    generator: Generator | None = None,\n) -&gt; Tensor\n</code></pre> <p>Create a tensor filled with values sampled from a half-Cauchy distribution.</p> <p>Parameters:</p> Name Type Description Default <code>size</code> <code>list[int] | tuple[int, ...]</code> <p>The tensor shape.</p> required <code>scale</code> <code>float</code> <p>The scale of the half-Cauchy distribution. This value has to be greater than 0.</p> <code>1.0</code> <code>generator</code> <code>Generator | None</code> <p>An optional random generator.</p> <code>None</code> <p>Returns:</p> Type Description <code>Tensor</code> <p>A tensor filled with values sampled from a half-Cauchy distribution.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>if the <code>scale</code> parameter is not valid.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; from startorch.random import rand_half_cauchy\n&gt;&gt;&gt; rand_half_cauchy((2, 3), scale=1.0)\ntensor([[...]])\n</code></pre>"},{"location":"refs/random/#startorch.random.rand_half_normal","title":"startorch.random.rand_half_normal","text":"<pre><code>rand_half_normal(\n    size: list[int] | tuple[int, ...],\n    std: float = 1.0,\n    generator: Generator | None = None,\n) -&gt; Tensor\n</code></pre> <p>Create a tensor filled with values sampled from a half-Normal distribution.</p> <p>Parameters:</p> Name Type Description Default <code>size</code> <code>list[int] | tuple[int, ...]</code> <p>The tensor shape.</p> required <code>std</code> <code>float</code> <p>The standard deviation of the half-Normal distribution.</p> <code>1.0</code> <code>generator</code> <code>Generator | None</code> <p>An optional random generator.</p> <code>None</code> <p>Returns:</p> Type Description <code>Tensor</code> <p>A tensor filled with values sampled from a half-Normal distribution.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>if the <code>std</code> parameter is not valid.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; from startorch.random import rand_half_normal\n&gt;&gt;&gt; rand_half_normal((2, 3), std=1.0)\ntensor([[...]])\n</code></pre>"},{"location":"refs/random/#startorch.random.rand_log_normal","title":"startorch.random.rand_log_normal","text":"<pre><code>rand_log_normal(\n    size: list[int] | tuple[int, ...],\n    mean: float = 0.0,\n    std: float = 1.0,\n    generator: Generator | None = None,\n) -&gt; Tensor\n</code></pre> <p>Create a tensor filled with values sampled from a log-Normal distribution.</p> <p>Parameters:</p> Name Type Description Default <code>size</code> <code>list[int] | tuple[int, ...]</code> <p>The tensor shape.</p> required <code>mean</code> <code>float</code> <p>The mean of the underlying Normal distribution.</p> <code>0.0</code> <code>std</code> <code>float</code> <p>The standard deviation of the underlying Normal distribution.</p> <code>1.0</code> <code>generator</code> <code>Generator | None</code> <p>An optional random generator.</p> <code>None</code> <p>Returns:</p> Type Description <code>Tensor</code> <p>A tensor of shape <code>(d0, d1, ..., dn)</code> filled with values sampled from a log-Normal distribution.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>if the <code>mean</code> and <code>std</code> parametera are not valid.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; from startorch.random import rand_log_normal\n&gt;&gt;&gt; rand_log_normal((2, 3), mean=1.0, std=2.0)\ntensor([[...]])\n</code></pre>"},{"location":"refs/random/#startorch.random.rand_log_uniform","title":"startorch.random.rand_log_uniform","text":"<pre><code>rand_log_uniform(\n    size: list[int] | tuple[int, ...],\n    low: float,\n    high: float,\n    generator: Generator | None = None,\n) -&gt; Tensor\n</code></pre> <p>Create a tensor filled with values sampled from a uniform distribution in the log space.</p> <p>Parameters:</p> Name Type Description Default <code>size</code> <code>list[int] | tuple[int, ...]</code> <p>The tensor shape.</p> required <code>low</code> <code>float</code> <p>The minimum value (inclusive). This value needs to be positive.</p> required <code>high</code> <code>float</code> <p>The maximum value (exclusive).</p> required <code>generator</code> <code>Generator | None</code> <p>An optional random generator.</p> <code>None</code> <p>Returns:</p> Type Description <code>Tensor</code> <p>A tensor filled with values sampled from a uniform distribution in the log space.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>if the <code>low</code> and  <code>high</code> parameters  are not valid.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.random import rand_log_uniform\n&gt;&gt;&gt; rand_log_uniform((2, 3), low=0.1, high=1000.0)\ntensor([[...]])\n</code></pre>"},{"location":"refs/random/#startorch.random.rand_normal","title":"startorch.random.rand_normal","text":"<pre><code>rand_normal(\n    size: list[int] | tuple[int, ...],\n    mean: float = 0.0,\n    std: float = 1.0,\n    generator: Generator | None = None,\n) -&gt; Tensor\n</code></pre> <p>Create a tensor filled with values sampled from a Normal distribution.</p> <p>Parameters:</p> Name Type Description Default <code>size</code> <code>list[int] | tuple[int, ...]</code> <p>The tensor shape.</p> required <code>mean</code> <code>float</code> <p>The mean of the Normal distribution.</p> <code>0.0</code> <code>std</code> <code>float</code> <p>The standard deviation of the Normal distribution.</p> <code>1.0</code> <code>generator</code> <code>Generator | None</code> <p>An optional random generator.</p> <code>None</code> <p>Returns:</p> Type Description <code>Tensor</code> <p>A tensor filled with values sampled from a Normal distribution.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>if the <code>std</code> parameter is not valid.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; from startorch.random import rand_normal\n&gt;&gt;&gt; rand_normal((2, 3), mean=1.0, std=2.0)\ntensor([[...]])\n</code></pre>"},{"location":"refs/random/#startorch.random.rand_poisson","title":"startorch.random.rand_poisson","text":"<pre><code>rand_poisson(\n    size: list[int] | tuple[int, ...],\n    rate: float = 1.0,\n    generator: Generator | None = None,\n) -&gt; Tensor\n</code></pre> <p>Create a tensor filled with values sampled from a Poisson distribution.</p> <p>Parameters:</p> Name Type Description Default <code>size</code> <code>list[int] | tuple[int, ...]</code> <p>The tensor shape.</p> required <code>rate</code> <code>float</code> <p>The rate of the Poisson distribution. This value has to be greater than 0.</p> <code>1.0</code> <code>generator</code> <code>Generator | None</code> <p>An optional random generator.</p> <code>None</code> <p>Returns:</p> Type Description <code>Tensor</code> <p><code>torch.Tensor</code> of type float: A tensor filled with values sampled from a Poisson distribution.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>if the <code>rate</code> parameter is not valid.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; from startorch.random import rand_poisson\n&gt;&gt;&gt; rand_poisson(size=(2, 3), rate=2.0)\ntensor([...])\n</code></pre>"},{"location":"refs/random/#startorch.random.rand_trunc_cauchy","title":"startorch.random.rand_trunc_cauchy","text":"<pre><code>rand_trunc_cauchy(\n    size: list[int] | tuple[int, ...],\n    loc: float = 0.0,\n    scale: float = 1.0,\n    min_value: float = -2.0,\n    max_value: float = 2.0,\n    generator: Generator | None = None,\n) -&gt; Tensor\n</code></pre> <p>Create a tensor filled with values sampled from a truncated Cauchy distribution.</p> <p>Parameters:</p> Name Type Description Default <code>size</code> <code>list[int] | tuple[int, ...]</code> <p>The tensor shape.</p> required <code>loc</code> <code>float</code> <p>The location of the Cauchy distribution.</p> <code>0.0</code> <code>scale</code> <code>float</code> <p>The scale of the Cauchy distribution.</p> <code>1.0</code> <code>min_value</code> <code>float</code> <p>The minimum value.</p> <code>-2.0</code> <code>max_value</code> <code>float</code> <p>The maximum value.</p> <code>2.0</code> <code>generator</code> <code>Generator | None</code> <p>An optional random generator.</p> <code>None</code> <p>Returns:</p> Type Description <code>Tensor</code> <p>A tensor filled with values sampled from a truncated Cauchy distribution</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>if the <code>max_value</code> and <code>min_value</code> parameters are not valid.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; from startorch.random import rand_trunc_cauchy\n&gt;&gt;&gt; rand_trunc_cauchy((2, 3), loc=1.0, scale=2.0, min_value=-3.0, max_value=3.0)\ntensor([[...]])\n</code></pre>"},{"location":"refs/random/#startorch.random.rand_trunc_exponential","title":"startorch.random.rand_trunc_exponential","text":"<pre><code>rand_trunc_exponential(\n    size: list[int] | tuple[int, ...],\n    rate: float = 1.0,\n    max_value: float = 5.0,\n    generator: Generator | None = None,\n) -&gt; Tensor\n</code></pre> <p>Create a tensor filled with values sampled from a truncated Exponential distribution.</p> <p>Parameters:</p> Name Type Description Default <code>size</code> <code>list[int] | tuple[int, ...]</code> <p>The tensor shape.</p> required <code>rate</code> <code>float</code> <p>The rate of the Exponential distribution.</p> <code>1.0</code> <code>max_value</code> <code>float</code> <p>The maximum value.</p> <code>5.0</code> <code>generator</code> <code>Generator | None</code> <p>An optional random generator.</p> <code>None</code> <p>Returns:</p> Type Description <code>Tensor</code> <p>A tensor filled with values sampled from a truncated Exponential distribution</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>if the <code>max_value</code> parameter is not valid.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; from startorch.random import rand_trunc_exponential\n&gt;&gt;&gt; rand_trunc_exponential((2, 3), rate=1.0, max_value=3.0)\ntensor([[...]])\n</code></pre>"},{"location":"refs/random/#startorch.random.rand_trunc_half_cauchy","title":"startorch.random.rand_trunc_half_cauchy","text":"<pre><code>rand_trunc_half_cauchy(\n    size: list[int] | tuple[int, ...],\n    scale: float = 1.0,\n    max_value: float = 4.0,\n    generator: Generator | None = None,\n) -&gt; Tensor\n</code></pre> <p>Create a tensor filled with values sampled from a truncated half- Cauchy distribution.</p> <p>Parameters:</p> Name Type Description Default <code>size</code> <code>list[int] | tuple[int, ...]</code> <p>The tensor shape.</p> required <code>scale</code> <code>float</code> <p>The scale of the half-Cauchy distribution.</p> <code>1.0</code> <code>max_value</code> <code>float</code> <p>The maximum value.</p> <code>4.0</code> <code>generator</code> <code>Generator | None</code> <p>An optional random generator.</p> <code>None</code> <p>Returns:</p> Type Description <code>Tensor</code> <p>A tensor filled with values sampled from a truncated half-Cauchy distribution.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>if the <code>max_value</code> parameter is not valid.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; from startorch.random import rand_trunc_half_cauchy\n&gt;&gt;&gt; rand_trunc_half_cauchy((2, 3), scale=1.0, max_value=3.0)\ntensor([[...]])\n</code></pre>"},{"location":"refs/random/#startorch.random.rand_trunc_half_normal","title":"startorch.random.rand_trunc_half_normal","text":"<pre><code>rand_trunc_half_normal(\n    size: list[int] | tuple[int, ...],\n    std: float = 1.0,\n    max_value: float = 5.0,\n    generator: Generator | None = None,\n) -&gt; Tensor\n</code></pre> <p>Create a tensor filled with values sampled from a truncated half- Normal distribution.</p> <p>Parameters:</p> Name Type Description Default <code>size</code> <code>list[int] | tuple[int, ...]</code> <p>The tensor shape.</p> required <code>std</code> <code>float</code> <p>The standard deviation of the half-Normal distribution.</p> <code>1.0</code> <code>max_value</code> <code>float</code> <p>The maximum value.</p> <code>5.0</code> <code>generator</code> <code>Generator | None</code> <p>An optional random generator.</p> <code>None</code> <p>Returns:</p> Type Description <code>Tensor</code> <p>A tensor filled with values sampled from a truncated half-Normal distribution.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>if the <code>max_value</code> parameter is not valid.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; from startorch.random import rand_trunc_half_normal\n&gt;&gt;&gt; rand_trunc_half_normal((2, 3), std=1.0, max_value=3.0)\ntensor([[...]])\n</code></pre>"},{"location":"refs/random/#startorch.random.rand_trunc_log_normal","title":"startorch.random.rand_trunc_log_normal","text":"<pre><code>rand_trunc_log_normal(\n    size: list[int] | tuple[int, ...],\n    mean: float = 0.0,\n    std: float = 1.0,\n    min_value: float = 0.0,\n    max_value: float = 5.0,\n    generator: Generator | None = None,\n) -&gt; Tensor\n</code></pre> <p>Create a tensor filled with values sampled from a truncated log- Normal distribution.</p> <p>Parameters:</p> Name Type Description Default <code>size</code> <code>list[int] | tuple[int, ...]</code> <p>The tensor shape.</p> required <code>mean</code> <code>float</code> <p>The mean of the underlying Normal distribution.</p> <code>0.0</code> <code>std</code> <code>float</code> <p>The standard deviation of the underlying Normal distribution.</p> <code>1.0</code> <code>min_value</code> <code>float</code> <p>The minimum value.</p> <code>0.0</code> <code>max_value</code> <code>float</code> <p>The maximum value.</p> <code>5.0</code> <code>generator</code> <code>Generator | None</code> <p>An optional random generator.</p> <code>None</code> <p>Returns:</p> Type Description <code>Tensor</code> <p>A tensor filled with values sampled from a truncated log-Normal distribution.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>if the <code>min_value</code> and <code>max_value</code> parameters are not valid.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; from startorch.random import rand_trunc_log_normal\n&gt;&gt;&gt; rand_trunc_log_normal((2, 3), mean=0.0, std=1.0, min_value=1.0, max_value=4.0)\ntensor([[...]])\n</code></pre>"},{"location":"refs/random/#startorch.random.rand_trunc_normal","title":"startorch.random.rand_trunc_normal","text":"<pre><code>rand_trunc_normal(\n    size: list[int] | tuple[int, ...],\n    mean: float = 0.0,\n    std: float = 1.0,\n    min_value: float = -3.0,\n    max_value: float = 3.0,\n    generator: Generator | None = None,\n) -&gt; Tensor\n</code></pre> <p>Create a tensor filled with values sampled from a truncated Normal distribution.</p> <p>Parameters:</p> Name Type Description Default <code>size</code> <code>list[int] | tuple[int, ...]</code> <p>The tensor shape.</p> required <code>mean</code> <code>float</code> <p>The mean of the Normal distribution.</p> <code>0.0</code> <code>std</code> <code>float</code> <p>The standard deviation of the Normal distribution.</p> <code>1.0</code> <code>min_value</code> <code>float</code> <p>The minimum value.</p> <code>-3.0</code> <code>max_value</code> <code>float</code> <p>The maximum value.</p> <code>3.0</code> <code>generator</code> <code>Generator | None</code> <p>An optional random generator.</p> <code>None</code> <p>Returns:</p> Type Description <code>Tensor</code> <p>A tensor filled with values sampled from a truncated Normal distribution.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>if the <code>min_value</code> and  <code>max_value</code> parameters are not valid.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; from startorch.random import rand_trunc_normal\n&gt;&gt;&gt; rand_trunc_normal((2, 3), mean=1.0, std=2.0, min_value=-5.0, max_value=5.0)\ntensor([[...]])\n</code></pre>"},{"location":"refs/random/#startorch.random.rand_uniform","title":"startorch.random.rand_uniform","text":"<pre><code>rand_uniform(\n    size: list[int] | tuple[int, ...],\n    low: float = 0.0,\n    high: float = 1.0,\n    generator: Generator | None = None,\n) -&gt; Tensor\n</code></pre> <p>Create a tensor filled with values sampled from a uniform distribution.</p> <p>Parameters:</p> Name Type Description Default <code>size</code> <code>list[int] | tuple[int, ...]</code> <p>The tensor shape.</p> required <code>low</code> <code>float</code> <p>The minimum value (inclusive).</p> <code>0.0</code> <code>high</code> <code>float</code> <p>The maximum value (exclusive).</p> <code>1.0</code> <code>generator</code> <code>Generator | None</code> <p>An optional random generator.</p> <code>None</code> <p>Returns:</p> Type Description <code>Tensor</code> <p>A tensor filled with values sampled from a uniform distribution.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>if the <code>low</code> and  <code>high</code> parameters  are not valid.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; from startorch.random import rand_uniform\n&gt;&gt;&gt; rand_uniform((2, 3), low=-1.0, high=2.0)\ntensor([[...]])\n</code></pre>"},{"location":"refs/random/#startorch.random.trunc_cauchy","title":"startorch.random.trunc_cauchy","text":"<pre><code>trunc_cauchy(\n    loc: Tensor,\n    scale: Tensor,\n    min_value: Tensor,\n    max_value: Tensor,\n    generator: Generator | None = None,\n) -&gt; Tensor\n</code></pre> <p>Create a tensor filled with values sampled from a truncated Cauchy distribution.</p> <p>Parameters:</p> Name Type Description Default <code>loc</code> <code>Tensor</code> <p>The location/median of the Cauchy distribution. It must be a float tensor of shape <code>(d0, d1, ..., dn)</code>.</p> required <code>scale</code> <code>Tensor</code> <p>The scale of the Cauchy distribution. It must be a float tensor of shape <code>(d0, d1, ..., dn)</code>.</p> required <code>min_value</code> <code>Tensor</code> <p>The minimum value. It must be a float tensor of shape <code>(d0, d1, ..., dn)</code>.</p> required <code>max_value</code> <code>Tensor</code> <p>The maximum value. It must be a float tensor of shape <code>(d0, d1, ..., dn)</code>.</p> required <code>generator</code> <code>Generator | None</code> <p>An optional random generator.</p> <code>None</code> <p>Returns:</p> Type Description <code>Tensor</code> <p>A tensor of shape <code>(d0, d1, ..., dn)</code> filled with values sampled from a truncated Cauchy distribution</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>if the <code>loc</code>, <code>scale</code>, <code>max_value</code> and <code>min_value</code> parameters are not valid.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; from startorch.random import trunc_cauchy\n&gt;&gt;&gt; trunc_cauchy(\n...     loc=torch.tensor([1.0, 0.0, -1.0]),\n...     scale=torch.tensor([1.0, 3.0, 5.0]),\n...     min_value=torch.tensor([-5.0, -10.0, -15.0]),\n...     max_value=torch.tensor([5.0, 10.0, 15.0]),\n... )\ntensor([...])\n</code></pre>"},{"location":"refs/random/#startorch.random.trunc_exponential","title":"startorch.random.trunc_exponential","text":"<pre><code>trunc_exponential(\n    rate: Tensor,\n    max_value: Tensor,\n    generator: Generator | None = None,\n) -&gt; Tensor\n</code></pre> <p>Create a tensor filled with values sampled from a truncated Exponential distribution.</p> <p>Parameters:</p> Name Type Description Default <code>rate</code> <code>Tensor</code> <p>The rate of the Exponential distribution. It must be a float tensor of shape <code>(d0, d1, ..., dn)</code>.</p> required <code>max_value</code> <code>Tensor</code> <p>The maximum value. It must be a float tensor of shape <code>(d0, d1, ..., dn)</code>.</p> required <code>generator</code> <code>Generator | None</code> <p>An optional random generator.</p> <code>None</code> <p>Returns:</p> Type Description <code>Tensor</code> <p>A tensor of shape <code>(d0, d1, ..., dn)</code> filled with values sampled from a truncated Exponential distribution.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>if the <code>rate</code> and <code>max_value</code> parameter are not valid.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; from startorch.random import trunc_exponential\n&gt;&gt;&gt; trunc_exponential(\n...     rate=torch.tensor([1.0, 3.0, 5.0]),\n...     max_value=torch.tensor([5.0, 10.0, 15.0]),\n... )\ntensor([...])\n</code></pre>"},{"location":"refs/random/#startorch.random.trunc_half_cauchy","title":"startorch.random.trunc_half_cauchy","text":"<pre><code>trunc_half_cauchy(\n    scale: Tensor,\n    max_value: Tensor,\n    generator: Generator | None = None,\n) -&gt; Tensor\n</code></pre> <p>Create a tensor filled with values sampled from a truncated half- Cauchy distribution.</p> <p>Parameters:</p> Name Type Description Default <code>scale</code> <code>Tensor</code> <p>The scale of the half-Cauchy distribution. It must be a float tensor of shape <code>(d0, d1, ..., dn)</code>.</p> required <code>max_value</code> <code>Tensor</code> <p>The maximum value. It must be a float tensor of shape <code>(d0, d1, ..., dn)</code>.</p> required <code>generator</code> <code>Generator | None</code> <p>An optional random generator.</p> <code>None</code> <p>Returns:</p> Type Description <code>Tensor</code> <p>A tensor of shape <code>(d0, d1, ..., dn)</code> filled with values sampled from a truncated Cauchy distribution.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>if the <code>scale</code> and <code>max_value</code> parameter are not valid.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; from startorch.random import trunc_half_cauchy\n&gt;&gt;&gt; trunc_half_cauchy(\n...     scale=torch.tensor([1.0, 3.0, 5.0]),\n...     max_value=torch.tensor([5.0, 10.0, 15.0]),\n... )\ntensor([...])\n</code></pre>"},{"location":"refs/random/#startorch.random.trunc_half_normal","title":"startorch.random.trunc_half_normal","text":"<pre><code>trunc_half_normal(\n    std: Tensor,\n    max_value: Tensor,\n    generator: Generator | None = None,\n) -&gt; Tensor\n</code></pre> <p>Create a tensor filled with values sampled from a truncated half- Normal distribution.</p> <p>Parameters:</p> Name Type Description Default <code>std</code> <code>Tensor</code> <p>The standard deviation of the half-Normal distribution. It must be a float tensor of shape <code>(d0, d1, ..., dn)</code>.</p> required <code>max_value</code> <code>Tensor</code> <p>The maximum value. It must be a float tensor of shape <code>(d0, d1, ..., dn)</code>.</p> required <code>generator</code> <code>Generator | None</code> <p>An optional random generator.</p> <code>None</code> <p>Returns:</p> Type Description <code>Tensor</code> <p>A tensor of shape <code>(d0, d1, ..., dn)</code> filled with values sampled from a truncated half-Normal distribution.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>if the <code>std</code> and <code>max_value</code> parameters are not valid.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; from startorch.random import trunc_half_normal\n&gt;&gt;&gt; trunc_half_normal(\n...     std=torch.tensor([1.0, 3.0, 5.0]), max_value=torch.tensor([5.0, 10.0, 15.0])\n... )\ntensor([...])\n</code></pre>"},{"location":"refs/random/#startorch.random.trunc_log_normal","title":"startorch.random.trunc_log_normal","text":"<pre><code>trunc_log_normal(\n    mean: Tensor,\n    std: Tensor,\n    min_value: Tensor,\n    max_value: Tensor,\n    generator: Generator | None = None,\n) -&gt; Tensor\n</code></pre> <p>Create a tensor filled with values sampled from a truncated log- Normal distribution.</p> <p>Parameters:</p> Name Type Description Default <code>mean</code> <code>Tensor</code> <p>The mean of the underlying Normal distribution. It must be a float tensor of shape <code>(d0, d1, ..., dn)</code>.</p> required <code>std</code> <code>Tensor</code> <p>The standard deviation of the underlying Normal distribution. It must be a float tensor of shape <code>(d0, d1, ..., dn)</code>.</p> required <code>min_value</code> <code>Tensor</code> <p>The minimum value. It must be a float tensor of shape <code>(d0, d1, ..., dn)</code>.</p> required <code>max_value</code> <code>Tensor</code> <p>The maximum value. It must be a float tensor of shape <code>(d0, d1, ..., dn)</code>.</p> required <code>generator</code> <code>Generator | None</code> <p>An optional random generator.</p> <code>None</code> <p>Returns:</p> Type Description <code>Tensor</code> <p>A tensor of shape <code>(d0, d1, ..., dn)</code> filled with values sampled from a truncated log-Normal distribution.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>if the <code>mean</code>, <code>std</code>, <code>min_value</code> and <code>max_value</code> parameters are not valid.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; from startorch.random import trunc_log_normal\n&gt;&gt;&gt; trunc_log_normal(\n...     mean=torch.tensor([-1.0, 0.0, 1.0]),\n...     std=torch.tensor([1.0, 3.0, 5.0]),\n...     min_value=torch.tensor([0.0, 1.0, 2.0]),\n...     max_value=torch.tensor([5.0, 10.0, 15.0]),\n... )\ntensor([...])\n</code></pre>"},{"location":"refs/random/#startorch.random.trunc_normal","title":"startorch.random.trunc_normal","text":"<pre><code>trunc_normal(\n    mean: Tensor,\n    std: Tensor,\n    min_value: Tensor,\n    max_value: Tensor,\n    generator: Generator | None = None,\n) -&gt; Tensor\n</code></pre> <p>Create a tensor filled with values sampled from a truncated Normal distribution.</p> <p>Parameters:</p> Name Type Description Default <code>mean</code> <code>Tensor</code> <p>The mean of the Normal distribution. It must be a float tensor of shape <code>(d0, d1, ..., dn)</code>.</p> required <code>std</code> <code>Tensor</code> <p>The standard deviation of the Normal distribution. It must be a float tensor of shape <code>(d0, d1, ..., dn)</code>.</p> required <code>min_value</code> <code>Tensor</code> <p>The minimum value. It must be a float tensor of shape <code>(d0, d1, ..., dn)</code>.</p> required <code>max_value</code> <code>Tensor</code> <p>The maximum value. It must be a float tensor of shape <code>(d0, d1, ..., dn)</code>.</p> required <code>generator</code> <code>Generator | None</code> <p>An optional random generator.</p> <code>None</code> <p>Returns:</p> Type Description <code>Tensor</code> <p>A tensor of shape <code>(d0, d1, ..., dn)</code> filled with values sampled from a truncated Normal distribution.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>if the <code>min_value</code> and  <code>max_value</code> parameters are not valid.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; from startorch.random import trunc_normal\n&gt;&gt;&gt; trunc_normal(\n...     mean=torch.tensor([1.0, 0.0, -1.0]),\n...     std=torch.tensor([1.0, 3.0, 5.0]),\n...     min_value=torch.tensor([-5.0, -10.0, -15.0]),\n...     max_value=torch.tensor([5.0, 10.0, 15.0]),\n... )\ntensor([...])\n</code></pre>"},{"location":"refs/random/#startorch.random.uniform","title":"startorch.random.uniform","text":"<pre><code>uniform(\n    low: Tensor,\n    high: Tensor,\n    generator: Generator | None = None,\n) -&gt; Tensor\n</code></pre> <p>Create a tensor filled with values sampled from a uniform distribution.</p> <p>Unlike <code>rand_uniform</code>, this function allows to sample values from different uniform distributions at the same time. The shape of the <code>low</code> and <code>high</code> tensors are used to infer the output size.</p> <p>Parameters:</p> Name Type Description Default <code>low</code> <code>Tensor</code> <p>The minimum values (inclusive). It must be a float tensor of shape <code>(d0, d1, ..., dn)</code>.</p> required <code>high</code> <code>Tensor</code> <p>The maximum values (exclusive). It must be a float tensor of shape <code>(d0, d1, ..., dn)</code>.</p> required <code>generator</code> <code>Generator | None</code> <p>An optional random generator.</p> <code>None</code> <p>Returns:</p> Type Description <code>Tensor</code> <p>A tensor of shape <code>(d0, d1, ..., dn)</code> filled with values sampled from a uniform distribution where the minimum and maximum values are given as input.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>if the input tensor shapes do not match or if at least one value in <code>low</code> tensor is higher than its associated high value in <code>high</code></p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; from startorch.random import uniform\n&gt;&gt;&gt; uniform(low=torch.tensor([-1.0, 0.0, 1.0]), high=torch.tensor([1.0, 3.0, 5.0]))\ntensor([...])\n</code></pre>"},{"location":"refs/sequence/","title":"sequence","text":""},{"location":"refs/sequence/#startorch.sequence","title":"startorch.sequence","text":"<p>Contain sequence generators.</p>"},{"location":"refs/sequence/#startorch.sequence.Abs","title":"startorch.sequence.Abs","text":"<p>               Bases: <code>BaseWrapperSequenceGenerator</code></p> <p>Implement a sequence generator that computes the absolute value of a generated sequence.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; from startorch.sequence import Abs, RandNormal\n&gt;&gt;&gt; generator = Abs(RandNormal())\n&gt;&gt;&gt; generator\nAbsSequenceGenerator(\n  (sequence): RandNormalSequenceGenerator(mean=0.0, std=1.0, feature_size=(1,))\n)\n&gt;&gt;&gt; generator.generate(seq_len=12, batch_size=4)\ntensor([[...]])\n</code></pre>"},{"location":"refs/sequence/#startorch.sequence.AbsSequenceGenerator","title":"startorch.sequence.AbsSequenceGenerator","text":"<p>               Bases: <code>BaseWrapperSequenceGenerator</code></p> <p>Implement a sequence generator that computes the absolute value of a generated sequence.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; from startorch.sequence import Abs, RandNormal\n&gt;&gt;&gt; generator = Abs(RandNormal())\n&gt;&gt;&gt; generator\nAbsSequenceGenerator(\n  (sequence): RandNormalSequenceGenerator(mean=0.0, std=1.0, feature_size=(1,))\n)\n&gt;&gt;&gt; generator.generate(seq_len=12, batch_size=4)\ntensor([[...]])\n</code></pre>"},{"location":"refs/sequence/#startorch.sequence.Acosh","title":"startorch.sequence.Acosh","text":"<p>               Bases: <code>BaseWrapperSequenceGenerator</code></p> <p>Implement a sequence generator that computes the inverse hyperbolic cosine (arccosh) of each value.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; from startorch.sequence import Acosh, RandUniform\n&gt;&gt;&gt; generator = Acosh(RandUniform())\n&gt;&gt;&gt; generator\nAcoshSequenceGenerator(\n  (sequence): RandUniformSequenceGenerator(low=0.0, high=1.0, feature_size=(1,))\n)\n&gt;&gt;&gt; generator.generate(seq_len=12, batch_size=4)\ntensor([[...]])\n</code></pre>"},{"location":"refs/sequence/#startorch.sequence.AcoshSequenceGenerator","title":"startorch.sequence.AcoshSequenceGenerator","text":"<p>               Bases: <code>BaseWrapperSequenceGenerator</code></p> <p>Implement a sequence generator that computes the inverse hyperbolic cosine (arccosh) of each value.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; from startorch.sequence import Acosh, RandUniform\n&gt;&gt;&gt; generator = Acosh(RandUniform())\n&gt;&gt;&gt; generator\nAcoshSequenceGenerator(\n  (sequence): RandUniformSequenceGenerator(low=0.0, high=1.0, feature_size=(1,))\n)\n&gt;&gt;&gt; generator.generate(seq_len=12, batch_size=4)\ntensor([[...]])\n</code></pre>"},{"location":"refs/sequence/#startorch.sequence.Add","title":"startorch.sequence.Add","text":"<p>               Bases: <code>BaseSequenceGenerator</code></p> <p>Implement a sequence generator that adds multiple sequences.</p> <p><code>sequence = sequence_1 + sequence_2 + ... + sequence_n</code></p> <p>Parameters:</p> Name Type Description Default <code>sequences</code> <code>Sequence[BaseSequenceGenerator | dict]</code> <p>The sequence generators or their configuration.</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>if no sequence generator is provided.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; from startorch.sequence import Add, RandUniform, RandNormal\n&gt;&gt;&gt; generator = Add([RandUniform(), RandNormal()])\n&gt;&gt;&gt; generator\nAddSequenceGenerator(\n  (0): RandUniformSequenceGenerator(low=0.0, high=1.0, feature_size=(1,))\n  (1): RandNormalSequenceGenerator(mean=0.0, std=1.0, feature_size=(1,))\n)\n&gt;&gt;&gt; generator.generate(seq_len=12, batch_size=4)\ntensor([[...]])\n</code></pre>"},{"location":"refs/sequence/#startorch.sequence.AddScalar","title":"startorch.sequence.AddScalar","text":"<p>               Bases: <code>BaseWrapperSequenceGenerator</code></p> <p>Implement a sequence generator that adds a scalar value to a generated batch of sequences.</p> <p>Parameters:</p> Name Type Description Default <code>generator</code> <code>BaseSequenceGenerator | dict</code> <p>The sequence generator or its configuration.</p> required <code>value</code> <code>float</code> <p>The scalar value to add.</p> required <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; from startorch.sequence import AddScalar, RandUniform, RandNormal\n&gt;&gt;&gt; generator = AddScalar(RandUniform(), 42.0)\n&gt;&gt;&gt; generator\nAddScalarSequenceGenerator(\n  (sequence): RandUniformSequenceGenerator(low=0.0, high=1.0, feature_size=(1,))\n  (value): 42.0\n)\n&gt;&gt;&gt; generator.generate(seq_len=12, batch_size=4)\ntensor([[...]])\n</code></pre>"},{"location":"refs/sequence/#startorch.sequence.AddScalarSequenceGenerator","title":"startorch.sequence.AddScalarSequenceGenerator","text":"<p>               Bases: <code>BaseWrapperSequenceGenerator</code></p> <p>Implement a sequence generator that adds a scalar value to a generated batch of sequences.</p> <p>Parameters:</p> Name Type Description Default <code>generator</code> <code>BaseSequenceGenerator | dict</code> <p>The sequence generator or its configuration.</p> required <code>value</code> <code>float</code> <p>The scalar value to add.</p> required <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; from startorch.sequence import AddScalar, RandUniform, RandNormal\n&gt;&gt;&gt; generator = AddScalar(RandUniform(), 42.0)\n&gt;&gt;&gt; generator\nAddScalarSequenceGenerator(\n  (sequence): RandUniformSequenceGenerator(low=0.0, high=1.0, feature_size=(1,))\n  (value): 42.0\n)\n&gt;&gt;&gt; generator.generate(seq_len=12, batch_size=4)\ntensor([[...]])\n</code></pre>"},{"location":"refs/sequence/#startorch.sequence.AddSequenceGenerator","title":"startorch.sequence.AddSequenceGenerator","text":"<p>               Bases: <code>BaseSequenceGenerator</code></p> <p>Implement a sequence generator that adds multiple sequences.</p> <p><code>sequence = sequence_1 + sequence_2 + ... + sequence_n</code></p> <p>Parameters:</p> Name Type Description Default <code>sequences</code> <code>Sequence[BaseSequenceGenerator | dict]</code> <p>The sequence generators or their configuration.</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>if no sequence generator is provided.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; from startorch.sequence import Add, RandUniform, RandNormal\n&gt;&gt;&gt; generator = Add([RandUniform(), RandNormal()])\n&gt;&gt;&gt; generator\nAddSequenceGenerator(\n  (0): RandUniformSequenceGenerator(low=0.0, high=1.0, feature_size=(1,))\n  (1): RandNormalSequenceGenerator(mean=0.0, std=1.0, feature_size=(1,))\n)\n&gt;&gt;&gt; generator.generate(seq_len=12, batch_size=4)\ntensor([[...]])\n</code></pre>"},{"location":"refs/sequence/#startorch.sequence.Arange","title":"startorch.sequence.Arange","text":"<p>               Bases: <code>BaseSequenceGenerator</code></p> <p>Implement a class to generate sequence of consecutive integer values between <code>0</code> and <code>seq_len-1</code>.</p> <p>Parameters:</p> Name Type Description Default <code>feature_size</code> <code>tuple[int, ...] | list[int] | int</code> <p>The feature size.</p> <code>1</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.sequence import Arange\n&gt;&gt;&gt; generator = Arange(feature_size=())\n&gt;&gt;&gt; generator\nArangeSequenceGenerator(feature_size=())\n&gt;&gt;&gt; generator.generate(seq_len=6, batch_size=2)\ntensor([[0, 1, 2, 3, 4, 5],\n        [0, 1, 2, 3, 4, 5]])\n</code></pre>"},{"location":"refs/sequence/#startorch.sequence.ArangeSequenceGenerator","title":"startorch.sequence.ArangeSequenceGenerator","text":"<p>               Bases: <code>BaseSequenceGenerator</code></p> <p>Implement a class to generate sequence of consecutive integer values between <code>0</code> and <code>seq_len-1</code>.</p> <p>Parameters:</p> Name Type Description Default <code>feature_size</code> <code>tuple[int, ...] | list[int] | int</code> <p>The feature size.</p> <code>1</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.sequence import Arange\n&gt;&gt;&gt; generator = Arange(feature_size=())\n&gt;&gt;&gt; generator\nArangeSequenceGenerator(feature_size=())\n&gt;&gt;&gt; generator.generate(seq_len=6, batch_size=2)\ntensor([[0, 1, 2, 3, 4, 5],\n        [0, 1, 2, 3, 4, 5]])\n</code></pre>"},{"location":"refs/sequence/#startorch.sequence.Asinh","title":"startorch.sequence.Asinh","text":"<p>               Bases: <code>BaseWrapperSequenceGenerator</code></p> <p>Implement a sequence generator that computes the inverse hyperbolic sine (arcsinh) of each value.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; from startorch.sequence import Asinh, RandUniform\n&gt;&gt;&gt; generator = Asinh(RandUniform())\n&gt;&gt;&gt; generator\nAsinhSequenceGenerator(\n  (sequence): RandUniformSequenceGenerator(low=0.0, high=1.0, feature_size=(1,))\n)\n&gt;&gt;&gt; generator.generate(seq_len=12, batch_size=4)\ntensor([[...]])\n</code></pre>"},{"location":"refs/sequence/#startorch.sequence.AsinhSequenceGenerator","title":"startorch.sequence.AsinhSequenceGenerator","text":"<p>               Bases: <code>BaseWrapperSequenceGenerator</code></p> <p>Implement a sequence generator that computes the inverse hyperbolic sine (arcsinh) of each value.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; from startorch.sequence import Asinh, RandUniform\n&gt;&gt;&gt; generator = Asinh(RandUniform())\n&gt;&gt;&gt; generator\nAsinhSequenceGenerator(\n  (sequence): RandUniformSequenceGenerator(low=0.0, high=1.0, feature_size=(1,))\n)\n&gt;&gt;&gt; generator.generate(seq_len=12, batch_size=4)\ntensor([[...]])\n</code></pre>"},{"location":"refs/sequence/#startorch.sequence.AsinhUniform","title":"startorch.sequence.AsinhUniform","text":"<p>               Bases: <code>BaseSequenceGenerator</code></p> <p>Implement a sequence generator to generate sequences by sampling values from an asinh-uniform distribution.</p> <p>Parameters:</p> Name Type Description Default <code>low</code> <code>BaseSequenceGenerator | dict</code> <p>A sequence generator (or its configuration) to generate the minimum value (inclusive).</p> required <code>high</code> <code>BaseSequenceGenerator | dict</code> <p>A sequence generator (or its configuration) to generate the maximum value (exclusive).</p> required <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; from startorch.sequence import AsinhUniform, RandUniform\n&gt;&gt;&gt; generator = AsinhUniform(low=RandUniform(-1.0, 0.0), high=RandUniform(0.0, 1.0))\n&gt;&gt;&gt; generator\nAsinhUniformSequenceGenerator(\n  (low): RandUniformSequenceGenerator(low=-1.0, high=0.0, feature_size=(1,))\n  (high): RandUniformSequenceGenerator(low=0.0, high=1.0, feature_size=(1,))\n)\n&gt;&gt;&gt; generator.generate(seq_len=12, batch_size=4)\ntensor([[...]])\n</code></pre>"},{"location":"refs/sequence/#startorch.sequence.AsinhUniformSequenceGenerator","title":"startorch.sequence.AsinhUniformSequenceGenerator","text":"<p>               Bases: <code>BaseSequenceGenerator</code></p> <p>Implement a sequence generator to generate sequences by sampling values from an asinh-uniform distribution.</p> <p>Parameters:</p> Name Type Description Default <code>low</code> <code>BaseSequenceGenerator | dict</code> <p>A sequence generator (or its configuration) to generate the minimum value (inclusive).</p> required <code>high</code> <code>BaseSequenceGenerator | dict</code> <p>A sequence generator (or its configuration) to generate the maximum value (exclusive).</p> required <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; from startorch.sequence import AsinhUniform, RandUniform\n&gt;&gt;&gt; generator = AsinhUniform(low=RandUniform(-1.0, 0.0), high=RandUniform(0.0, 1.0))\n&gt;&gt;&gt; generator\nAsinhUniformSequenceGenerator(\n  (low): RandUniformSequenceGenerator(low=-1.0, high=0.0, feature_size=(1,))\n  (high): RandUniformSequenceGenerator(low=0.0, high=1.0, feature_size=(1,))\n)\n&gt;&gt;&gt; generator.generate(seq_len=12, batch_size=4)\ntensor([[...]])\n</code></pre>"},{"location":"refs/sequence/#startorch.sequence.Atanh","title":"startorch.sequence.Atanh","text":"<p>               Bases: <code>BaseWrapperSequenceGenerator</code></p> <p>Implement a sequence generator that computes the inverse hyperbolic tangent (arctanh) of each value.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; from startorch.sequence import Atanh, RandUniform\n&gt;&gt;&gt; generator = Atanh(RandUniform())\n&gt;&gt;&gt; generator\nAtanhSequenceGenerator(\n  (sequence): RandUniformSequenceGenerator(low=0.0, high=1.0, feature_size=(1,))\n)\n&gt;&gt;&gt; generator.generate(seq_len=12, batch_size=4)\ntensor([[...]])\n</code></pre>"},{"location":"refs/sequence/#startorch.sequence.AtanhSequenceGenerator","title":"startorch.sequence.AtanhSequenceGenerator","text":"<p>               Bases: <code>BaseWrapperSequenceGenerator</code></p> <p>Implement a sequence generator that computes the inverse hyperbolic tangent (arctanh) of each value.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; from startorch.sequence import Atanh, RandUniform\n&gt;&gt;&gt; generator = Atanh(RandUniform())\n&gt;&gt;&gt; generator\nAtanhSequenceGenerator(\n  (sequence): RandUniformSequenceGenerator(low=0.0, high=1.0, feature_size=(1,))\n)\n&gt;&gt;&gt; generator.generate(seq_len=12, batch_size=4)\ntensor([[...]])\n</code></pre>"},{"location":"refs/sequence/#startorch.sequence.AutoRegressive","title":"startorch.sequence.AutoRegressive","text":"<p>               Bases: <code>BaseSequenceGenerator</code></p> <p>Implement a class to generate sequence by sampling values from an autoregressive process.</p> <p>Parameters:</p> Name Type Description Default <code>value</code> <code>BaseSequenceGenerator | dict</code> <p>A sequence generator (or its configuration) used to generate the initial sequence values. These values are used to start the AR.</p> required <code>coefficient</code> <code>BaseSequenceGenerator | dict</code> <p>A sequence generator (or its configuration) used to generate the coefficients.</p> required <code>noise</code> <code>BaseSequenceGenerator | dict</code> <p>A sequence generator (or its configuration) used to generate the noise values.</p> required <code>order</code> <code>BaseTensorGenerator | dict</code> <p>A tensor generator (or its configuration) used to generate the order of the AR.</p> required <code>max_abs_value</code> <code>float</code> <p>The maximum absolute value. This argument ensures the values stay in the range <code>[-max_abs_value, max_abs_value]</code>.</p> required <code>warmup</code> <code>int</code> <p>The number of cycles used to initiate the AR. The initial value sampled do not follow an AR, so using warmup allows to initialize the AR so each value follows an AR.</p> <code>10</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>if <code>max_abs_value</code> is not a positive number.</p> <code>ValueError</code> <p>if <code>warmup</code> is not a positive number.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; from startorch.sequence import AutoRegressive, RandUniform, RandNormal, Full\n&gt;&gt;&gt; from startorch.tensor import RandInt\n&gt;&gt;&gt; generator = AutoRegressive(\n...     value=RandNormal(),\n...     coefficient=RandUniform(low=-1.0, high=1.0),\n...     noise=Full(0.0),\n...     order=RandInt(low=1, high=6),\n...     max_abs_value=100.0,\n... )\n&gt;&gt;&gt; generator\nAutoRegressiveSequenceGenerator(\n  (value): RandNormalSequenceGenerator(mean=0.0, std=1.0, feature_size=(1,))\n  (coefficient): RandUniformSequenceGenerator(low=-1.0, high=1.0, feature_size=(1,))\n  (noise): FullSequenceGenerator(value=0.0, feature_size=(1,))\n  (order): RandIntTensorGenerator(low=1, high=6)\n  (max_abs_value): 100.0\n  (warmup): 10\n)\n&gt;&gt;&gt; generator.generate(seq_len=12, batch_size=4)\ntensor([[...]])\n</code></pre>"},{"location":"refs/sequence/#startorch.sequence.AutoRegressiveSequenceGenerator","title":"startorch.sequence.AutoRegressiveSequenceGenerator","text":"<p>               Bases: <code>BaseSequenceGenerator</code></p> <p>Implement a class to generate sequence by sampling values from an autoregressive process.</p> <p>Parameters:</p> Name Type Description Default <code>value</code> <code>BaseSequenceGenerator | dict</code> <p>A sequence generator (or its configuration) used to generate the initial sequence values. These values are used to start the AR.</p> required <code>coefficient</code> <code>BaseSequenceGenerator | dict</code> <p>A sequence generator (or its configuration) used to generate the coefficients.</p> required <code>noise</code> <code>BaseSequenceGenerator | dict</code> <p>A sequence generator (or its configuration) used to generate the noise values.</p> required <code>order</code> <code>BaseTensorGenerator | dict</code> <p>A tensor generator (or its configuration) used to generate the order of the AR.</p> required <code>max_abs_value</code> <code>float</code> <p>The maximum absolute value. This argument ensures the values stay in the range <code>[-max_abs_value, max_abs_value]</code>.</p> required <code>warmup</code> <code>int</code> <p>The number of cycles used to initiate the AR. The initial value sampled do not follow an AR, so using warmup allows to initialize the AR so each value follows an AR.</p> <code>10</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>if <code>max_abs_value</code> is not a positive number.</p> <code>ValueError</code> <p>if <code>warmup</code> is not a positive number.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; from startorch.sequence import AutoRegressive, RandUniform, RandNormal, Full\n&gt;&gt;&gt; from startorch.tensor import RandInt\n&gt;&gt;&gt; generator = AutoRegressive(\n...     value=RandNormal(),\n...     coefficient=RandUniform(low=-1.0, high=1.0),\n...     noise=Full(0.0),\n...     order=RandInt(low=1, high=6),\n...     max_abs_value=100.0,\n... )\n&gt;&gt;&gt; generator\nAutoRegressiveSequenceGenerator(\n  (value): RandNormalSequenceGenerator(mean=0.0, std=1.0, feature_size=(1,))\n  (coefficient): RandUniformSequenceGenerator(low=-1.0, high=1.0, feature_size=(1,))\n  (noise): FullSequenceGenerator(value=0.0, feature_size=(1,))\n  (order): RandIntTensorGenerator(low=1, high=6)\n  (max_abs_value): 100.0\n  (warmup): 10\n)\n&gt;&gt;&gt; generator.generate(seq_len=12, batch_size=4)\ntensor([[...]])\n</code></pre>"},{"location":"refs/sequence/#startorch.sequence.BaseSequenceGenerator","title":"startorch.sequence.BaseSequenceGenerator","text":"<p>               Bases: <code>ABC</code></p> <p>Define the base class to generate sequences.</p> <p>A child class has to implement the <code>generate</code> method.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; from startorch.sequence import RandUniform\n&gt;&gt;&gt; generator = RandUniform()\n&gt;&gt;&gt; generator\nRandUniformSequenceGenerator(low=0.0, high=1.0, feature_size=(1,))\n&gt;&gt;&gt; generator.generate(seq_len=12, batch_size=4)\ntensor([[...]])\n</code></pre>"},{"location":"refs/sequence/#startorch.sequence.BaseSequenceGenerator.generate","title":"startorch.sequence.BaseSequenceGenerator.generate  <code>abstractmethod</code>","text":"<pre><code>generate(\n    seq_len: int,\n    batch_size: int = 1,\n    rng: Generator | None = None,\n) -&gt; Tensor\n</code></pre> <p>Generate a batch of sequences.</p> <p>All the sequences in the batch must have the same length.</p> <p>Parameters:</p> Name Type Description Default <code>seq_len</code> <code>int</code> <p>The sequence length.</p> required <code>batch_size</code> <code>int</code> <p>The batch size.</p> <code>1</code> <code>rng</code> <code>Generator | None</code> <p>An optional random number generator.</p> <code>None</code> <p>Returns:</p> Type Description <code>Tensor</code> <p>A batch of sequences. The data in the batch are represented as a <code>torch.Tensor</code> of shape <code>(batch_size, sequence_length, *)</code> where <code>*</code> means any number of dimensions.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; from startorch.sequence import RandUniform\n&gt;&gt;&gt; generator = RandUniform()\n&gt;&gt;&gt; generator.generate(seq_len=12, batch_size=4)\ntensor([[...]])\n</code></pre>"},{"location":"refs/sequence/#startorch.sequence.BaseWrapperSequenceGenerator","title":"startorch.sequence.BaseWrapperSequenceGenerator","text":"<p>               Bases: <code>BaseSequenceGenerator</code></p> <p>Define a base class to easily wrap a sequence generator.</p> Note <p>It is possible to wrap a sequence generator into another sequence generator without using this base class. This class makes it more convenient and reduce duplicate code.</p> <p>Parameters:</p> Name Type Description Default <code>generator</code> <code>BaseSequenceGenerator | dict</code> <p>The sequence generator or its configuration.</p> required"},{"location":"refs/sequence/#startorch.sequence.Cat2","title":"startorch.sequence.Cat2","text":"<p>               Bases: <code>BaseSequenceGenerator</code></p> <p>Implement a sequence generator that concatenate two sequences along the sequence dimension.</p> <p><code>ouput = [sequence1, sequence2]</code></p> <p>Parameters:</p> Name Type Description Default <code>generator1</code> <code>BaseSequenceGenerator | dict</code> <p>The first sequence generator or its configuration.</p> required <code>generator2</code> <code>BaseSequenceGenerator | dict</code> <p>The second sequence generator or its configuration.</p> required <code>changepoint</code> <code>BaseTensorGenerator | dict</code> <p>The change point generator or its configuration.</p> required <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; from startorch.sequence import Cat2, RandUniform, RandNormal\n&gt;&gt;&gt; from startorch.tensor import RandInt\n&gt;&gt;&gt; generator = Cat2(\n...     generator1=RandUniform(), generator2=RandNormal(), changepoint=RandInt(0, 12)\n... )\n&gt;&gt;&gt; generator\nCat2SequenceGenerator(\n  (generator1): RandUniformSequenceGenerator(low=0.0, high=1.0, feature_size=(1,))\n  (generator2): RandNormalSequenceGenerator(mean=0.0, std=1.0, feature_size=(1,))\n  (changepoint): RandIntTensorGenerator(low=0, high=12)\n)\n&gt;&gt;&gt; generator.generate(seq_len=12, batch_size=4)\ntensor([[...]])\n</code></pre>"},{"location":"refs/sequence/#startorch.sequence.Cat2SequenceGenerator","title":"startorch.sequence.Cat2SequenceGenerator","text":"<p>               Bases: <code>BaseSequenceGenerator</code></p> <p>Implement a sequence generator that concatenate two sequences along the sequence dimension.</p> <p><code>ouput = [sequence1, sequence2]</code></p> <p>Parameters:</p> Name Type Description Default <code>generator1</code> <code>BaseSequenceGenerator | dict</code> <p>The first sequence generator or its configuration.</p> required <code>generator2</code> <code>BaseSequenceGenerator | dict</code> <p>The second sequence generator or its configuration.</p> required <code>changepoint</code> <code>BaseTensorGenerator | dict</code> <p>The change point generator or its configuration.</p> required <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; from startorch.sequence import Cat2, RandUniform, RandNormal\n&gt;&gt;&gt; from startorch.tensor import RandInt\n&gt;&gt;&gt; generator = Cat2(\n...     generator1=RandUniform(), generator2=RandNormal(), changepoint=RandInt(0, 12)\n... )\n&gt;&gt;&gt; generator\nCat2SequenceGenerator(\n  (generator1): RandUniformSequenceGenerator(low=0.0, high=1.0, feature_size=(1,))\n  (generator2): RandNormalSequenceGenerator(mean=0.0, std=1.0, feature_size=(1,))\n  (changepoint): RandIntTensorGenerator(low=0, high=12)\n)\n&gt;&gt;&gt; generator.generate(seq_len=12, batch_size=4)\ntensor([[...]])\n</code></pre>"},{"location":"refs/sequence/#startorch.sequence.Cauchy","title":"startorch.sequence.Cauchy","text":"<p>               Bases: <code>BaseSequenceGenerator</code></p> <p>Implement a class to generate sequence by sampling values from a Cauchy distribution.</p> <p>Parameters:</p> Name Type Description Default <code>loc</code> <code>BaseSequenceGenerator | dict</code> <p>A sequence generator (or its configuration) to generate the location.</p> required <code>scale</code> <code>BaseSequenceGenerator | dict</code> <p>A sequence generator (or its configuration) to generate the scale.</p> required <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.sequence import Cauchy, RandUniform\n&gt;&gt;&gt; generator = Cauchy(\n...     loc=RandUniform(low=-1.0, high=1.0),\n...     scale=RandUniform(low=1.0, high=2.0),\n... )\n&gt;&gt;&gt; generator\nCauchySequenceGenerator(\n  (loc): RandUniformSequenceGenerator(low=-1.0, high=1.0, feature_size=(1,))\n  (scale): RandUniformSequenceGenerator(low=1.0, high=2.0, feature_size=(1,))\n)\n&gt;&gt;&gt; generator.generate(seq_len=6, batch_size=2)\ntensor([[...]])\n</code></pre>"},{"location":"refs/sequence/#startorch.sequence.CauchySequenceGenerator","title":"startorch.sequence.CauchySequenceGenerator","text":"<p>               Bases: <code>BaseSequenceGenerator</code></p> <p>Implement a class to generate sequence by sampling values from a Cauchy distribution.</p> <p>Parameters:</p> Name Type Description Default <code>loc</code> <code>BaseSequenceGenerator | dict</code> <p>A sequence generator (or its configuration) to generate the location.</p> required <code>scale</code> <code>BaseSequenceGenerator | dict</code> <p>A sequence generator (or its configuration) to generate the scale.</p> required <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.sequence import Cauchy, RandUniform\n&gt;&gt;&gt; generator = Cauchy(\n...     loc=RandUniform(low=-1.0, high=1.0),\n...     scale=RandUniform(low=1.0, high=2.0),\n... )\n&gt;&gt;&gt; generator\nCauchySequenceGenerator(\n  (loc): RandUniformSequenceGenerator(low=-1.0, high=1.0, feature_size=(1,))\n  (scale): RandUniformSequenceGenerator(low=1.0, high=2.0, feature_size=(1,))\n)\n&gt;&gt;&gt; generator.generate(seq_len=6, batch_size=2)\ntensor([[...]])\n</code></pre>"},{"location":"refs/sequence/#startorch.sequence.Clamp","title":"startorch.sequence.Clamp","text":"<p>               Bases: <code>BaseWrapperSequenceGenerator</code></p> <p>Implement a sequence generator to generate a batch of sequences where the values are clamped.</p> <p>Note: <code>min_value</code> and <code>max_value</code> cannot be both <code>None</code>.</p> <p>Parameters:</p> Name Type Description Default <code>generator</code> <code>BaseSequenceGenerator | dict</code> <p>The sequence generator or its configuration.</p> required <code>min</code> <code>float | None</code> <p>The lower bound. If <code>min_value</code> is <code>None</code>, there is no lower bound.</p> required <code>max</code> <code>float | None</code> <p>The upper bound. If <code>max_value</code> is <code>None</code>, there is no upper bound.</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>if both <code>min</code> and <code>max</code> are <code>None</code></p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; from startorch.sequence import Clamp, RandNormal\n&gt;&gt;&gt; generator = Clamp(RandNormal(), -1.0, 1.0)\n&gt;&gt;&gt; generator\nClampSequenceGenerator(\n  (sequence): RandNormalSequenceGenerator(mean=0.0, std=1.0, feature_size=(1,))\n  (min): -1.0\n  (max): 1.0\n)\n&gt;&gt;&gt; generator.generate(seq_len=12, batch_size=4)\ntensor([[...]])\n</code></pre>"},{"location":"refs/sequence/#startorch.sequence.ClampSequenceGenerator","title":"startorch.sequence.ClampSequenceGenerator","text":"<p>               Bases: <code>BaseWrapperSequenceGenerator</code></p> <p>Implement a sequence generator to generate a batch of sequences where the values are clamped.</p> <p>Note: <code>min_value</code> and <code>max_value</code> cannot be both <code>None</code>.</p> <p>Parameters:</p> Name Type Description Default <code>generator</code> <code>BaseSequenceGenerator | dict</code> <p>The sequence generator or its configuration.</p> required <code>min</code> <code>float | None</code> <p>The lower bound. If <code>min_value</code> is <code>None</code>, there is no lower bound.</p> required <code>max</code> <code>float | None</code> <p>The upper bound. If <code>max_value</code> is <code>None</code>, there is no upper bound.</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>if both <code>min</code> and <code>max</code> are <code>None</code></p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; from startorch.sequence import Clamp, RandNormal\n&gt;&gt;&gt; generator = Clamp(RandNormal(), -1.0, 1.0)\n&gt;&gt;&gt; generator\nClampSequenceGenerator(\n  (sequence): RandNormalSequenceGenerator(mean=0.0, std=1.0, feature_size=(1,))\n  (min): -1.0\n  (max): 1.0\n)\n&gt;&gt;&gt; generator.generate(seq_len=12, batch_size=4)\ntensor([[...]])\n</code></pre>"},{"location":"refs/sequence/#startorch.sequence.Constant","title":"startorch.sequence.Constant","text":"<p>               Bases: <code>BaseWrapperSequenceGenerator</code></p> <p>Implement a sequence generator to generate a batch of sequences with constant values where the values for each sequence are sampled from another sequence generator.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.sequence import Constant, RandUniform\n&gt;&gt;&gt; generator = Constant(RandUniform())\n&gt;&gt;&gt; generator\nConstantSequenceGenerator(\n  (sequence): RandUniformSequenceGenerator(low=0.0, high=1.0, feature_size=(1,))\n)\n&gt;&gt;&gt; generator.generate(seq_len=6, batch_size=2)\ntensor([[...]])\n</code></pre>"},{"location":"refs/sequence/#startorch.sequence.ConstantSequenceGenerator","title":"startorch.sequence.ConstantSequenceGenerator","text":"<p>               Bases: <code>BaseWrapperSequenceGenerator</code></p> <p>Implement a sequence generator to generate a batch of sequences with constant values where the values for each sequence are sampled from another sequence generator.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.sequence import Constant, RandUniform\n&gt;&gt;&gt; generator = Constant(RandUniform())\n&gt;&gt;&gt; generator\nConstantSequenceGenerator(\n  (sequence): RandUniformSequenceGenerator(low=0.0, high=1.0, feature_size=(1,))\n)\n&gt;&gt;&gt; generator.generate(seq_len=6, batch_size=2)\ntensor([[...]])\n</code></pre>"},{"location":"refs/sequence/#startorch.sequence.Cosh","title":"startorch.sequence.Cosh","text":"<p>               Bases: <code>BaseWrapperSequenceGenerator</code></p> <p>Implement a sequence generator that computes the hyperbolic cosine (cosh) of each value.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; from startorch.sequence import Cosh, RandUniform\n&gt;&gt;&gt; generator = Cosh(RandUniform())\n&gt;&gt;&gt; generator\nCoshSequenceGenerator(\n  (sequence): RandUniformSequenceGenerator(low=0.0, high=1.0, feature_size=(1,))\n)\n&gt;&gt;&gt; generator.generate(seq_len=12, batch_size=4)\ntensor([[...]])\n</code></pre>"},{"location":"refs/sequence/#startorch.sequence.CoshSequenceGenerator","title":"startorch.sequence.CoshSequenceGenerator","text":"<p>               Bases: <code>BaseWrapperSequenceGenerator</code></p> <p>Implement a sequence generator that computes the hyperbolic cosine (cosh) of each value.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; from startorch.sequence import Cosh, RandUniform\n&gt;&gt;&gt; generator = Cosh(RandUniform())\n&gt;&gt;&gt; generator\nCoshSequenceGenerator(\n  (sequence): RandUniformSequenceGenerator(low=0.0, high=1.0, feature_size=(1,))\n)\n&gt;&gt;&gt; generator.generate(seq_len=12, batch_size=4)\ntensor([[...]])\n</code></pre>"},{"location":"refs/sequence/#startorch.sequence.Cumsum","title":"startorch.sequence.Cumsum","text":"<p>               Bases: <code>BaseWrapperSequenceGenerator</code></p> <p>Implement a sequence generator that computes the cumulative sum of a generated sequence.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; from startorch.sequence import Cumsum, RandUniform\n&gt;&gt;&gt; generator = Cumsum(RandUniform())\n&gt;&gt;&gt; generator\nCumsumSequenceGenerator(\n  (sequence): RandUniformSequenceGenerator(low=0.0, high=1.0, feature_size=(1,))\n)\n&gt;&gt;&gt; generator.generate(seq_len=12, batch_size=4)\ntensor([[...]])\n</code></pre>"},{"location":"refs/sequence/#startorch.sequence.CumsumSequenceGenerator","title":"startorch.sequence.CumsumSequenceGenerator","text":"<p>               Bases: <code>BaseWrapperSequenceGenerator</code></p> <p>Implement a sequence generator that computes the cumulative sum of a generated sequence.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; from startorch.sequence import Cumsum, RandUniform\n&gt;&gt;&gt; generator = Cumsum(RandUniform())\n&gt;&gt;&gt; generator\nCumsumSequenceGenerator(\n  (sequence): RandUniformSequenceGenerator(low=0.0, high=1.0, feature_size=(1,))\n)\n&gt;&gt;&gt; generator.generate(seq_len=12, batch_size=4)\ntensor([[...]])\n</code></pre>"},{"location":"refs/sequence/#startorch.sequence.Div","title":"startorch.sequence.Div","text":"<p>               Bases: <code>BaseSequenceGenerator</code></p> <p>Implement a sequence generator that divides one sequence by another one.</p> <p><code>sequence = dividend / divisor</code> (a.k.a. true division)</p> <p>Parameters:</p> Name Type Description Default <code>dividend</code> <code>BaseSequenceGenerator | dict</code> <p>The dividend sequence generator or its configuration.</p> required <code>divisor</code> <code>BaseSequenceGenerator | dict</code> <p>The divisor sequence generator or its configuration.</p> required <code>rounding_mode</code> <code>str | None</code> <p>The type of rounding applied to the result:     - <code>None</code>: true division.     - <code>\"trunc\"</code>: rounds the results of the division         towards zero.     - <code>\"floor\"</code>: floor division.</p> <code>None</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; from startorch.sequence import Div, RandUniform, RandNormal\n&gt;&gt;&gt; generator = Div(RandNormal(), RandUniform(1.0, 10.0))\n&gt;&gt;&gt; generator\nDivSequenceGenerator(\n  (dividend): RandNormalSequenceGenerator(mean=0.0, std=1.0, feature_size=(1,))\n  (divisor): RandUniformSequenceGenerator(low=1.0, high=10.0, feature_size=(1,))\n  (rounding_mode): None\n)\n&gt;&gt;&gt; generator.generate(seq_len=12, batch_size=4)\ntensor([[...]])\n</code></pre>"},{"location":"refs/sequence/#startorch.sequence.DivSequenceGenerator","title":"startorch.sequence.DivSequenceGenerator","text":"<p>               Bases: <code>BaseSequenceGenerator</code></p> <p>Implement a sequence generator that divides one sequence by another one.</p> <p><code>sequence = dividend / divisor</code> (a.k.a. true division)</p> <p>Parameters:</p> Name Type Description Default <code>dividend</code> <code>BaseSequenceGenerator | dict</code> <p>The dividend sequence generator or its configuration.</p> required <code>divisor</code> <code>BaseSequenceGenerator | dict</code> <p>The divisor sequence generator or its configuration.</p> required <code>rounding_mode</code> <code>str | None</code> <p>The type of rounding applied to the result:     - <code>None</code>: true division.     - <code>\"trunc\"</code>: rounds the results of the division         towards zero.     - <code>\"floor\"</code>: floor division.</p> <code>None</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; from startorch.sequence import Div, RandUniform, RandNormal\n&gt;&gt;&gt; generator = Div(RandNormal(), RandUniform(1.0, 10.0))\n&gt;&gt;&gt; generator\nDivSequenceGenerator(\n  (dividend): RandNormalSequenceGenerator(mean=0.0, std=1.0, feature_size=(1,))\n  (divisor): RandUniformSequenceGenerator(low=1.0, high=10.0, feature_size=(1,))\n  (rounding_mode): None\n)\n&gt;&gt;&gt; generator.generate(seq_len=12, batch_size=4)\ntensor([[...]])\n</code></pre>"},{"location":"refs/sequence/#startorch.sequence.Exp","title":"startorch.sequence.Exp","text":"<p>               Bases: <code>BaseWrapperSequenceGenerator</code></p> <p>Implement a sequence generator that computes the exponential of a batch of sequences.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; from startorch.sequence import Exp, RandUniform, RandNormal\n&gt;&gt;&gt; generator = Exp(RandUniform())\n&gt;&gt;&gt; generator\nExpSequenceGenerator(\n  (sequence): RandUniformSequenceGenerator(low=0.0, high=1.0, feature_size=(1,))\n)\n&gt;&gt;&gt; generator.generate(seq_len=12, batch_size=4)\ntensor([[...]])\n</code></pre>"},{"location":"refs/sequence/#startorch.sequence.ExpSequenceGenerator","title":"startorch.sequence.ExpSequenceGenerator","text":"<p>               Bases: <code>BaseWrapperSequenceGenerator</code></p> <p>Implement a sequence generator that computes the exponential of a batch of sequences.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; from startorch.sequence import Exp, RandUniform, RandNormal\n&gt;&gt;&gt; generator = Exp(RandUniform())\n&gt;&gt;&gt; generator\nExpSequenceGenerator(\n  (sequence): RandUniformSequenceGenerator(low=0.0, high=1.0, feature_size=(1,))\n)\n&gt;&gt;&gt; generator.generate(seq_len=12, batch_size=4)\ntensor([[...]])\n</code></pre>"},{"location":"refs/sequence/#startorch.sequence.Exponential","title":"startorch.sequence.Exponential","text":"<p>               Bases: <code>BaseSequenceGenerator</code></p> <p>Implement a class to generate sequence by sampling values from an Exponential distribution.</p> <p>The rates of the Exponential distribution are generated by the rate generator. The rate generator should return the rate for each value in the sequence.</p> <p>Parameters:</p> Name Type Description Default <code>rate</code> <code>BaseSequenceGenerator | dict</code> <p>The rate generator or its configuration. The rate generator should return valid rate values.</p> required <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.sequence import Exponential, RandUniform\n&gt;&gt;&gt; generator = Exponential(rate=RandUniform(low=1.0, high=10.0))\n&gt;&gt;&gt; generator\nExponentialSequenceGenerator(\n  (rate): RandUniformSequenceGenerator(low=1.0, high=10.0, feature_size=(1,))\n)\n&gt;&gt;&gt; generator.generate(seq_len=6, batch_size=2)\ntensor([[...]])\n</code></pre>"},{"location":"refs/sequence/#startorch.sequence.Exponential.create_fixed_rate","title":"startorch.sequence.Exponential.create_fixed_rate  <code>classmethod</code>","text":"<pre><code>create_fixed_rate(\n    rate: float = 1.0,\n    feature_size: tuple[int, ...] | list[int] | int = 1,\n) -&gt; ExponentialSequenceGenerator\n</code></pre> <p>Implement a sequence generator where the values are sampled from an Exponential distribution with a fixed rate.</p> <p>Parameters:</p> Name Type Description Default <code>rate</code> <code>float</code> <p>The rate of the Exponential distribution.</p> <code>1.0</code> <code>feature_size</code> <code>tuple[int, ...] | list[int] | int</code> <p>The feature size.</p> <code>1</code> <p>Returns:</p> Type Description <code>ExponentialSequenceGenerator</code> <p>A sequence generator where the rates of the Exponential distribution are a fixed given value.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.sequence import Exponential, RandUniform\n&gt;&gt;&gt; generator = Exponential.create_fixed_rate(rate=1.0)\n&gt;&gt;&gt; generator\nExponentialSequenceGenerator(\n  (rate): FullSequenceGenerator(value=1.0, feature_size=(1,))\n)\n&gt;&gt;&gt; generator.generate(seq_len=6, batch_size=2)\ntensor([[...]])\n</code></pre>"},{"location":"refs/sequence/#startorch.sequence.Exponential.create_uniform_rate","title":"startorch.sequence.Exponential.create_uniform_rate  <code>classmethod</code>","text":"<pre><code>create_uniform_rate(\n    min_rate: float = 0.01,\n    max_rate: float = 1.0,\n    feature_size: tuple[int, ...] | list[int] | int = 1,\n) -&gt; ExponentialSequenceGenerator\n</code></pre> <p>Implement a sequence generator where the rates of the Exponential distribution are sampled from a uniform distribution.</p> <p>One rate is sampled per sequence.</p> <p>Parameters:</p> Name Type Description Default <code>min_rate</code> <code>float</code> <p>The minimum rate value.</p> <code>0.01</code> <code>max_rate</code> <code>float</code> <p>The maximum rate value.</p> <code>1.0</code> <code>feature_size</code> <code>tuple[int, ...] | list[int] | int</code> <p>The feature size.</p> <code>1</code> <p>Returns:</p> Type Description <code>ExponentialSequenceGenerator</code> <p>A sequence generator where the rates for each sequence are sampled from a uniform distribution.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.sequence import Exponential, RandUniform\n&gt;&gt;&gt; generator = Exponential.create_uniform_rate(min_rate=0.1, max_rate=1.0)\n&gt;&gt;&gt; generator\nExponentialSequenceGenerator(\n  (rate): ConstantSequenceGenerator(\n      (sequence): RandUniformSequenceGenerator(low=0.1, high=1.0, feature_size=(1,))\n    )\n)\n&gt;&gt;&gt; generator.generate(seq_len=6, batch_size=2)\ntensor([[...]])\n</code></pre>"},{"location":"refs/sequence/#startorch.sequence.ExponentialSequenceGenerator","title":"startorch.sequence.ExponentialSequenceGenerator","text":"<p>               Bases: <code>BaseSequenceGenerator</code></p> <p>Implement a class to generate sequence by sampling values from an Exponential distribution.</p> <p>The rates of the Exponential distribution are generated by the rate generator. The rate generator should return the rate for each value in the sequence.</p> <p>Parameters:</p> Name Type Description Default <code>rate</code> <code>BaseSequenceGenerator | dict</code> <p>The rate generator or its configuration. The rate generator should return valid rate values.</p> required <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.sequence import Exponential, RandUniform\n&gt;&gt;&gt; generator = Exponential(rate=RandUniform(low=1.0, high=10.0))\n&gt;&gt;&gt; generator\nExponentialSequenceGenerator(\n  (rate): RandUniformSequenceGenerator(low=1.0, high=10.0, feature_size=(1,))\n)\n&gt;&gt;&gt; generator.generate(seq_len=6, batch_size=2)\ntensor([[...]])\n</code></pre>"},{"location":"refs/sequence/#startorch.sequence.ExponentialSequenceGenerator.create_fixed_rate","title":"startorch.sequence.ExponentialSequenceGenerator.create_fixed_rate  <code>classmethod</code>","text":"<pre><code>create_fixed_rate(\n    rate: float = 1.0,\n    feature_size: tuple[int, ...] | list[int] | int = 1,\n) -&gt; ExponentialSequenceGenerator\n</code></pre> <p>Implement a sequence generator where the values are sampled from an Exponential distribution with a fixed rate.</p> <p>Parameters:</p> Name Type Description Default <code>rate</code> <code>float</code> <p>The rate of the Exponential distribution.</p> <code>1.0</code> <code>feature_size</code> <code>tuple[int, ...] | list[int] | int</code> <p>The feature size.</p> <code>1</code> <p>Returns:</p> Type Description <code>ExponentialSequenceGenerator</code> <p>A sequence generator where the rates of the Exponential distribution are a fixed given value.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.sequence import Exponential, RandUniform\n&gt;&gt;&gt; generator = Exponential.create_fixed_rate(rate=1.0)\n&gt;&gt;&gt; generator\nExponentialSequenceGenerator(\n  (rate): FullSequenceGenerator(value=1.0, feature_size=(1,))\n)\n&gt;&gt;&gt; generator.generate(seq_len=6, batch_size=2)\ntensor([[...]])\n</code></pre>"},{"location":"refs/sequence/#startorch.sequence.ExponentialSequenceGenerator.create_uniform_rate","title":"startorch.sequence.ExponentialSequenceGenerator.create_uniform_rate  <code>classmethod</code>","text":"<pre><code>create_uniform_rate(\n    min_rate: float = 0.01,\n    max_rate: float = 1.0,\n    feature_size: tuple[int, ...] | list[int] | int = 1,\n) -&gt; ExponentialSequenceGenerator\n</code></pre> <p>Implement a sequence generator where the rates of the Exponential distribution are sampled from a uniform distribution.</p> <p>One rate is sampled per sequence.</p> <p>Parameters:</p> Name Type Description Default <code>min_rate</code> <code>float</code> <p>The minimum rate value.</p> <code>0.01</code> <code>max_rate</code> <code>float</code> <p>The maximum rate value.</p> <code>1.0</code> <code>feature_size</code> <code>tuple[int, ...] | list[int] | int</code> <p>The feature size.</p> <code>1</code> <p>Returns:</p> Type Description <code>ExponentialSequenceGenerator</code> <p>A sequence generator where the rates for each sequence are sampled from a uniform distribution.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.sequence import Exponential, RandUniform\n&gt;&gt;&gt; generator = Exponential.create_uniform_rate(min_rate=0.1, max_rate=1.0)\n&gt;&gt;&gt; generator\nExponentialSequenceGenerator(\n  (rate): ConstantSequenceGenerator(\n      (sequence): RandUniformSequenceGenerator(low=0.1, high=1.0, feature_size=(1,))\n    )\n)\n&gt;&gt;&gt; generator.generate(seq_len=6, batch_size=2)\ntensor([[...]])\n</code></pre>"},{"location":"refs/sequence/#startorch.sequence.Float","title":"startorch.sequence.Float","text":"<p>               Bases: <code>BaseWrapperSequenceGenerator</code></p> <p>Implement a sequence generator that converts a batch of sequences to float type.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.sequence import Float, RandInt\n&gt;&gt;&gt; generator = Float(RandInt(low=0, high=10))\n&gt;&gt;&gt; generator\nFloatSequenceGenerator(\n  (sequence): RandIntSequenceGenerator(low=0, high=10, feature_size=())\n)\n&gt;&gt;&gt; generator.generate(seq_len=6, batch_size=2)\ntensor([[...]])\n</code></pre>"},{"location":"refs/sequence/#startorch.sequence.FloatSequenceGenerator","title":"startorch.sequence.FloatSequenceGenerator","text":"<p>               Bases: <code>BaseWrapperSequenceGenerator</code></p> <p>Implement a sequence generator that converts a batch of sequences to float type.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.sequence import Float, RandInt\n&gt;&gt;&gt; generator = Float(RandInt(low=0, high=10))\n&gt;&gt;&gt; generator\nFloatSequenceGenerator(\n  (sequence): RandIntSequenceGenerator(low=0, high=10, feature_size=())\n)\n&gt;&gt;&gt; generator.generate(seq_len=6, batch_size=2)\ntensor([[...]])\n</code></pre>"},{"location":"refs/sequence/#startorch.sequence.Fmod","title":"startorch.sequence.Fmod","text":"<p>               Bases: <code>BaseSequenceGenerator</code></p> <p>Implement a tensor generator that computes the element-wise remainder of division.</p> <p>Parameters:</p> Name Type Description Default <code>dividend</code> <code>BaseSequenceGenerator | dict</code> <p>The sequence generator (or its configuration) that generates the dividend values.</p> required <code>divisor</code> <code>BaseSequenceGenerator | dict | float</code> <p>The divisor.</p> required <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.sequence import Fmod, RandUniform\n&gt;&gt;&gt; generator = Fmod(dividend=RandUniform(low=-100, high=100), divisor=10.0)\n&gt;&gt;&gt; generator\nFmodSequenceGenerator(\n  (dividend): RandUniformSequenceGenerator(low=-100.0, high=100.0, feature_size=(1,))\n  (divisor): 10.0\n)\n&gt;&gt;&gt; generator.generate(seq_len=6, batch_size=2)\ntensor([[...]])\n&gt;&gt;&gt; generator = Fmod(\n...     dividend=RandUniform(low=-100, high=100), divisor=RandUniform(low=1, high=10)\n... )\n&gt;&gt;&gt; generator\nFmodSequenceGenerator(\n  (dividend): RandUniformSequenceGenerator(low=-100.0, high=100.0, feature_size=(1,))\n  (divisor): RandUniformSequenceGenerator(low=1.0, high=10.0, feature_size=(1,))\n)\n&gt;&gt;&gt; generator.generate(seq_len=6, batch_size=2)\ntensor([[...]])\n</code></pre>"},{"location":"refs/sequence/#startorch.sequence.FmodSequenceGenerator","title":"startorch.sequence.FmodSequenceGenerator","text":"<p>               Bases: <code>BaseSequenceGenerator</code></p> <p>Implement a tensor generator that computes the element-wise remainder of division.</p> <p>Parameters:</p> Name Type Description Default <code>dividend</code> <code>BaseSequenceGenerator | dict</code> <p>The sequence generator (or its configuration) that generates the dividend values.</p> required <code>divisor</code> <code>BaseSequenceGenerator | dict | float</code> <p>The divisor.</p> required <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.sequence import Fmod, RandUniform\n&gt;&gt;&gt; generator = Fmod(dividend=RandUniform(low=-100, high=100), divisor=10.0)\n&gt;&gt;&gt; generator\nFmodSequenceGenerator(\n  (dividend): RandUniformSequenceGenerator(low=-100.0, high=100.0, feature_size=(1,))\n  (divisor): 10.0\n)\n&gt;&gt;&gt; generator.generate(seq_len=6, batch_size=2)\ntensor([[...]])\n&gt;&gt;&gt; generator = Fmod(\n...     dividend=RandUniform(low=-100, high=100), divisor=RandUniform(low=1, high=10)\n... )\n&gt;&gt;&gt; generator\nFmodSequenceGenerator(\n  (dividend): RandUniformSequenceGenerator(low=-100.0, high=100.0, feature_size=(1,))\n  (divisor): RandUniformSequenceGenerator(low=1.0, high=10.0, feature_size=(1,))\n)\n&gt;&gt;&gt; generator.generate(seq_len=6, batch_size=2)\ntensor([[...]])\n</code></pre>"},{"location":"refs/sequence/#startorch.sequence.Full","title":"startorch.sequence.Full","text":"<p>               Bases: <code>BaseSequenceGenerator</code></p> <p>Implement a sequence generator to generate sequences filled with a given value.</p> <p>This sequence generator is fully deterministic and the random seed has no effect.</p> <p>Parameters:</p> Name Type Description Default <code>value</code> <code>float</code> <p>The value.</p> required <code>feature_size</code> <code>tuple[int, ...] | list[int] | int</code> <p>The feature size.</p> <code>1</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.sequence import Full\n&gt;&gt;&gt; generator = Full(42.0)\n&gt;&gt;&gt; generator\nFullSequenceGenerator(value=42.0, feature_size=(1,))\n&gt;&gt;&gt; generator.generate(seq_len=6, batch_size=2)\ntensor([[[42.],\n         [42.],\n         [42.],\n         [42.],\n         [42.],\n         [42.]],\n        [[42.],\n         [42.],\n         [42.],\n         [42.],\n         [42.],\n         [42.]]])\n</code></pre>"},{"location":"refs/sequence/#startorch.sequence.FullSequenceGenerator","title":"startorch.sequence.FullSequenceGenerator","text":"<p>               Bases: <code>BaseSequenceGenerator</code></p> <p>Implement a sequence generator to generate sequences filled with a given value.</p> <p>This sequence generator is fully deterministic and the random seed has no effect.</p> <p>Parameters:</p> Name Type Description Default <code>value</code> <code>float</code> <p>The value.</p> required <code>feature_size</code> <code>tuple[int, ...] | list[int] | int</code> <p>The feature size.</p> <code>1</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.sequence import Full\n&gt;&gt;&gt; generator = Full(42.0)\n&gt;&gt;&gt; generator\nFullSequenceGenerator(value=42.0, feature_size=(1,))\n&gt;&gt;&gt; generator.generate(seq_len=6, batch_size=2)\ntensor([[[42.],\n         [42.],\n         [42.],\n         [42.],\n         [42.],\n         [42.]],\n        [[42.],\n         [42.],\n         [42.],\n         [42.],\n         [42.],\n         [42.]]])\n</code></pre>"},{"location":"refs/sequence/#startorch.sequence.HalfCauchy","title":"startorch.sequence.HalfCauchy","text":"<p>               Bases: <code>BaseSequenceGenerator</code></p> <p>Implement a class to generate sequence by sampling values from a half-Cauchy distribution.</p> <p>Parameters:</p> Name Type Description Default <code>scale</code> <code>BaseSequenceGenerator | dict</code> <p>A sequence generator (or its configuration) to generate the scale.</p> required <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.sequence import HalfCauchy, RandUniform\n&gt;&gt;&gt; generator = HalfCauchy(scale=RandUniform(low=1.0, high=2.0))\n&gt;&gt;&gt; generator\nHalfCauchySequenceGenerator(\n  (scale): RandUniformSequenceGenerator(low=1.0, high=2.0, feature_size=(1,))\n)\n&gt;&gt;&gt; generator.generate(seq_len=6, batch_size=2)\ntensor([[...]])\n</code></pre>"},{"location":"refs/sequence/#startorch.sequence.HalfCauchySequenceGenerator","title":"startorch.sequence.HalfCauchySequenceGenerator","text":"<p>               Bases: <code>BaseSequenceGenerator</code></p> <p>Implement a class to generate sequence by sampling values from a half-Cauchy distribution.</p> <p>Parameters:</p> Name Type Description Default <code>scale</code> <code>BaseSequenceGenerator | dict</code> <p>A sequence generator (or its configuration) to generate the scale.</p> required <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.sequence import HalfCauchy, RandUniform\n&gt;&gt;&gt; generator = HalfCauchy(scale=RandUniform(low=1.0, high=2.0))\n&gt;&gt;&gt; generator\nHalfCauchySequenceGenerator(\n  (scale): RandUniformSequenceGenerator(low=1.0, high=2.0, feature_size=(1,))\n)\n&gt;&gt;&gt; generator.generate(seq_len=6, batch_size=2)\ntensor([[...]])\n</code></pre>"},{"location":"refs/sequence/#startorch.sequence.HalfNormal","title":"startorch.sequence.HalfNormal","text":"<p>               Bases: <code>BaseSequenceGenerator</code></p> <p>Implement a class to generate sequence by sampling values from a half-Normal distribution.</p> <p>Parameters:</p> Name Type Description Default <code>std</code> <code>BaseSequenceGenerator | dict</code> <p>A sequence generator (or its configuration) to generate the standard deviation.</p> required <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.sequence import HalfNormal, RandUniform\n&gt;&gt;&gt; generator = HalfNormal(std=RandUniform(low=1.0, high=2.0))\n&gt;&gt;&gt; generator\nHalfNormalSequenceGenerator(\n  (std): RandUniformSequenceGenerator(low=1.0, high=2.0, feature_size=(1,))\n)\n&gt;&gt;&gt; generator.generate(seq_len=6, batch_size=2)\ntensor([[...]])\n</code></pre>"},{"location":"refs/sequence/#startorch.sequence.HalfNormalSequenceGenerator","title":"startorch.sequence.HalfNormalSequenceGenerator","text":"<p>               Bases: <code>BaseSequenceGenerator</code></p> <p>Implement a class to generate sequence by sampling values from a half-Normal distribution.</p> <p>Parameters:</p> Name Type Description Default <code>std</code> <code>BaseSequenceGenerator | dict</code> <p>A sequence generator (or its configuration) to generate the standard deviation.</p> required <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.sequence import HalfNormal, RandUniform\n&gt;&gt;&gt; generator = HalfNormal(std=RandUniform(low=1.0, high=2.0))\n&gt;&gt;&gt; generator\nHalfNormalSequenceGenerator(\n  (std): RandUniformSequenceGenerator(low=1.0, high=2.0, feature_size=(1,))\n)\n&gt;&gt;&gt; generator.generate(seq_len=6, batch_size=2)\ntensor([[...]])\n</code></pre>"},{"location":"refs/sequence/#startorch.sequence.Linear","title":"startorch.sequence.Linear","text":"<p>               Bases: <code>BaseSequenceGenerator</code></p> <p>Implement a class to generate sequence by sampling values with a linear pattern.</p> <p>The sequences are generated by using the following formula:</p> <p><code>output = slope * value + intercept</code></p> <p>Parameters:</p> Name Type Description Default <code>value</code> <code>BaseSequenceGenerator | dict</code> <p>A sequence generator (or its configuration) to generate the sequence values. The linear transformation is applied on these values.</p> required <code>slope</code> <code>BaseSequenceGenerator | dict</code> <p>A sequence generator (or its configuration) to generate the slope values.</p> required <code>intercept</code> <code>BaseSequenceGenerator | dict</code> <p>A sequence generator (or its configuration) to generate the intercept values.</p> required <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.sequence import Linear, RandUniform\n&gt;&gt;&gt; generator = Linear(\n...     value=RandUniform(low=-1.0, high=1.0),\n...     slope=RandUniform(low=1.0, high=2.0),\n...     intercept=RandUniform(low=-10.0, high=-5.0),\n... )\n&gt;&gt;&gt; generator\nLinearSequenceGenerator(\n  (value): RandUniformSequenceGenerator(low=-1.0, high=1.0, feature_size=(1,))\n  (slope): RandUniformSequenceGenerator(low=1.0, high=2.0, feature_size=(1,))\n  (intercept): RandUniformSequenceGenerator(low=-10.0, high=-5.0, feature_size=(1,))\n)\n&gt;&gt;&gt; generator.generate(seq_len=6, batch_size=2)\ntensor([[...]])\n</code></pre>"},{"location":"refs/sequence/#startorch.sequence.LinearSequenceGenerator","title":"startorch.sequence.LinearSequenceGenerator","text":"<p>               Bases: <code>BaseSequenceGenerator</code></p> <p>Implement a class to generate sequence by sampling values with a linear pattern.</p> <p>The sequences are generated by using the following formula:</p> <p><code>output = slope * value + intercept</code></p> <p>Parameters:</p> Name Type Description Default <code>value</code> <code>BaseSequenceGenerator | dict</code> <p>A sequence generator (or its configuration) to generate the sequence values. The linear transformation is applied on these values.</p> required <code>slope</code> <code>BaseSequenceGenerator | dict</code> <p>A sequence generator (or its configuration) to generate the slope values.</p> required <code>intercept</code> <code>BaseSequenceGenerator | dict</code> <p>A sequence generator (or its configuration) to generate the intercept values.</p> required <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.sequence import Linear, RandUniform\n&gt;&gt;&gt; generator = Linear(\n...     value=RandUniform(low=-1.0, high=1.0),\n...     slope=RandUniform(low=1.0, high=2.0),\n...     intercept=RandUniform(low=-10.0, high=-5.0),\n... )\n&gt;&gt;&gt; generator\nLinearSequenceGenerator(\n  (value): RandUniformSequenceGenerator(low=-1.0, high=1.0, feature_size=(1,))\n  (slope): RandUniformSequenceGenerator(low=1.0, high=2.0, feature_size=(1,))\n  (intercept): RandUniformSequenceGenerator(low=-10.0, high=-5.0, feature_size=(1,))\n)\n&gt;&gt;&gt; generator.generate(seq_len=6, batch_size=2)\ntensor([[...]])\n</code></pre>"},{"location":"refs/sequence/#startorch.sequence.Log","title":"startorch.sequence.Log","text":"<p>               Bases: <code>BaseWrapperSequenceGenerator</code></p> <p>Implement a sequence generator that computes the logarithm of a batch of sequences.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; from startorch.sequence import Log, RandUniform, RandNormal\n&gt;&gt;&gt; generator = Log(RandUniform(1.0, 10.0))\n&gt;&gt;&gt; generator\nLogSequenceGenerator(\n  (sequence): RandUniformSequenceGenerator(low=1.0, high=10.0, feature_size=(1,))\n)\n&gt;&gt;&gt; generator.generate(seq_len=12, batch_size=4)\ntensor([[...]])\n</code></pre>"},{"location":"refs/sequence/#startorch.sequence.LogNormal","title":"startorch.sequence.LogNormal","text":"<p>               Bases: <code>BaseSequenceGenerator</code></p> <p>Implement a class to generate sequence by sampling values from a log-Normal distribution.</p> <p>Parameters:</p> Name Type Description Default <code>mean</code> <code>BaseSequenceGenerator | dict</code> <p>A sequence generator (or its configuration) to generate the mean of the underlying Normal distribution.</p> required <code>std</code> <code>BaseSequenceGenerator | dict</code> <p>A sequence generator (or its configuration) to generate the standard deviation of the underlying Normal distribution.</p> required <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.sequence import LogNormal, RandUniform\n&gt;&gt;&gt; generator = LogNormal(\n...     mean=RandUniform(low=-1.0, high=1.0), std=RandUniform(low=1.0, high=2.0)\n... )\n&gt;&gt;&gt; generator\nLogNormalSequenceGenerator(\n  (mean): RandUniformSequenceGenerator(low=-1.0, high=1.0, feature_size=(1,))\n  (std): RandUniformSequenceGenerator(low=1.0, high=2.0, feature_size=(1,))\n)\n&gt;&gt;&gt; generator.generate(seq_len=6, batch_size=2)\ntensor([[...]])\n</code></pre>"},{"location":"refs/sequence/#startorch.sequence.LogNormalSequenceGenerator","title":"startorch.sequence.LogNormalSequenceGenerator","text":"<p>               Bases: <code>BaseSequenceGenerator</code></p> <p>Implement a class to generate sequence by sampling values from a log-Normal distribution.</p> <p>Parameters:</p> Name Type Description Default <code>mean</code> <code>BaseSequenceGenerator | dict</code> <p>A sequence generator (or its configuration) to generate the mean of the underlying Normal distribution.</p> required <code>std</code> <code>BaseSequenceGenerator | dict</code> <p>A sequence generator (or its configuration) to generate the standard deviation of the underlying Normal distribution.</p> required <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.sequence import LogNormal, RandUniform\n&gt;&gt;&gt; generator = LogNormal(\n...     mean=RandUniform(low=-1.0, high=1.0), std=RandUniform(low=1.0, high=2.0)\n... )\n&gt;&gt;&gt; generator\nLogNormalSequenceGenerator(\n  (mean): RandUniformSequenceGenerator(low=-1.0, high=1.0, feature_size=(1,))\n  (std): RandUniformSequenceGenerator(low=1.0, high=2.0, feature_size=(1,))\n)\n&gt;&gt;&gt; generator.generate(seq_len=6, batch_size=2)\ntensor([[...]])\n</code></pre>"},{"location":"refs/sequence/#startorch.sequence.LogSequenceGenerator","title":"startorch.sequence.LogSequenceGenerator","text":"<p>               Bases: <code>BaseWrapperSequenceGenerator</code></p> <p>Implement a sequence generator that computes the logarithm of a batch of sequences.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; from startorch.sequence import Log, RandUniform, RandNormal\n&gt;&gt;&gt; generator = Log(RandUniform(1.0, 10.0))\n&gt;&gt;&gt; generator\nLogSequenceGenerator(\n  (sequence): RandUniformSequenceGenerator(low=1.0, high=10.0, feature_size=(1,))\n)\n&gt;&gt;&gt; generator.generate(seq_len=12, batch_size=4)\ntensor([[...]])\n</code></pre>"},{"location":"refs/sequence/#startorch.sequence.LogUniform","title":"startorch.sequence.LogUniform","text":"<p>               Bases: <code>BaseSequenceGenerator</code></p> <p>Implement a sequence generator to generate sequences by sampling values from a log-uniform distribution.</p> <p>Parameters:</p> Name Type Description Default <code>low</code> <code>BaseSequenceGenerator | dict</code> <p>A sequence generator (or its configuration) to generate the minimum value (inclusive).</p> required <code>high</code> <code>BaseSequenceGenerator | dict</code> <p>A sequence generator (or its configuration) to generate the maximum value (exclusive).</p> required <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; from startorch.sequence import LogUniform, RandUniform\n&gt;&gt;&gt; generator = LogUniform(low=RandUniform(0.0, 1.0), high=RandUniform(5.0, 10.0))\n&gt;&gt;&gt; generator\nLogUniformSequenceGenerator(\n  (low): RandUniformSequenceGenerator(low=0.0, high=1.0, feature_size=(1,))\n  (high): RandUniformSequenceGenerator(low=5.0, high=10.0, feature_size=(1,))\n)\n&gt;&gt;&gt; generator.generate(seq_len=12, batch_size=4)\ntensor([[...]])\n</code></pre>"},{"location":"refs/sequence/#startorch.sequence.LogUniformSequenceGenerator","title":"startorch.sequence.LogUniformSequenceGenerator","text":"<p>               Bases: <code>BaseSequenceGenerator</code></p> <p>Implement a sequence generator to generate sequences by sampling values from a log-uniform distribution.</p> <p>Parameters:</p> Name Type Description Default <code>low</code> <code>BaseSequenceGenerator | dict</code> <p>A sequence generator (or its configuration) to generate the minimum value (inclusive).</p> required <code>high</code> <code>BaseSequenceGenerator | dict</code> <p>A sequence generator (or its configuration) to generate the maximum value (exclusive).</p> required <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; from startorch.sequence import LogUniform, RandUniform\n&gt;&gt;&gt; generator = LogUniform(low=RandUniform(0.0, 1.0), high=RandUniform(5.0, 10.0))\n&gt;&gt;&gt; generator\nLogUniformSequenceGenerator(\n  (low): RandUniformSequenceGenerator(low=0.0, high=1.0, feature_size=(1,))\n  (high): RandUniformSequenceGenerator(low=5.0, high=10.0, feature_size=(1,))\n)\n&gt;&gt;&gt; generator.generate(seq_len=12, batch_size=4)\ntensor([[...]])\n</code></pre>"},{"location":"refs/sequence/#startorch.sequence.Long","title":"startorch.sequence.Long","text":"<p>               Bases: <code>BaseWrapperSequenceGenerator</code></p> <p>Implement a sequence generator that converts a batch of sequences to long type.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.sequence import Long, RandUniform\n&gt;&gt;&gt; generator = Long(RandUniform(low=0, high=10))\n&gt;&gt;&gt; generator\nLongSequenceGenerator(\n  (sequence): RandUniformSequenceGenerator(low=0.0, high=10.0, feature_size=(1,))\n)\n&gt;&gt;&gt; generator.generate(seq_len=6, batch_size=2)\ntensor([[...]])\n</code></pre>"},{"location":"refs/sequence/#startorch.sequence.LongSequenceGenerator","title":"startorch.sequence.LongSequenceGenerator","text":"<p>               Bases: <code>BaseWrapperSequenceGenerator</code></p> <p>Implement a sequence generator that converts a batch of sequences to long type.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.sequence import Long, RandUniform\n&gt;&gt;&gt; generator = Long(RandUniform(low=0, high=10))\n&gt;&gt;&gt; generator\nLongSequenceGenerator(\n  (sequence): RandUniformSequenceGenerator(low=0.0, high=10.0, feature_size=(1,))\n)\n&gt;&gt;&gt; generator.generate(seq_len=6, batch_size=2)\ntensor([[...]])\n</code></pre>"},{"location":"refs/sequence/#startorch.sequence.Mul","title":"startorch.sequence.Mul","text":"<p>               Bases: <code>BaseSequenceGenerator</code></p> <p>Implement a sequence generator that multiplies multiple sequences.</p> <p><code>sequence = sequence_1 * sequence_2 * ... * sequence_n</code></p> <p>Parameters:</p> Name Type Description Default <code>sequences</code> <code>Sequence[BaseSequenceGenerator | dict]</code> <p>The sequence generators.</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>if no sequence generator is provided.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; from startorch.sequence import Mul, RandUniform, RandNormal\n&gt;&gt;&gt; generator = Mul([RandUniform(), RandNormal()])\n&gt;&gt;&gt; generator\nMulSequenceGenerator(\n  (0): RandUniformSequenceGenerator(low=0.0, high=1.0, feature_size=(1,))\n  (1): RandNormalSequenceGenerator(mean=0.0, std=1.0, feature_size=(1,))\n)\n&gt;&gt;&gt; generator.generate(seq_len=12, batch_size=4)\ntensor([[...]])\n</code></pre>"},{"location":"refs/sequence/#startorch.sequence.MulScalar","title":"startorch.sequence.MulScalar","text":"<p>               Bases: <code>BaseWrapperSequenceGenerator</code></p> <p>Implement a sequence generator that multiplies a scalar value to a generated batch of sequences.</p> <p>Parameters:</p> Name Type Description Default <code>generator</code> <code>BaseSequenceGenerator | dict</code> <p>The sequence generator or its configuration.</p> required <code>value</code> <code>float</code> <p>The scalar value to multiply.</p> required <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; from startorch.sequence import MulScalar, RandUniform, RandNormal\n&gt;&gt;&gt; generator = MulScalar(RandUniform(), 2.0)\n&gt;&gt;&gt; generator\nMulScalarSequenceGenerator(\n  (sequence): RandUniformSequenceGenerator(low=0.0, high=1.0, feature_size=(1,))\n  (value): 2.0\n)\n&gt;&gt;&gt; generator.generate(seq_len=12, batch_size=4)\ntensor([[...]])\n</code></pre>"},{"location":"refs/sequence/#startorch.sequence.MulScalarSequenceGenerator","title":"startorch.sequence.MulScalarSequenceGenerator","text":"<p>               Bases: <code>BaseWrapperSequenceGenerator</code></p> <p>Implement a sequence generator that multiplies a scalar value to a generated batch of sequences.</p> <p>Parameters:</p> Name Type Description Default <code>generator</code> <code>BaseSequenceGenerator | dict</code> <p>The sequence generator or its configuration.</p> required <code>value</code> <code>float</code> <p>The scalar value to multiply.</p> required <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; from startorch.sequence import MulScalar, RandUniform, RandNormal\n&gt;&gt;&gt; generator = MulScalar(RandUniform(), 2.0)\n&gt;&gt;&gt; generator\nMulScalarSequenceGenerator(\n  (sequence): RandUniformSequenceGenerator(low=0.0, high=1.0, feature_size=(1,))\n  (value): 2.0\n)\n&gt;&gt;&gt; generator.generate(seq_len=12, batch_size=4)\ntensor([[...]])\n</code></pre>"},{"location":"refs/sequence/#startorch.sequence.MulSequenceGenerator","title":"startorch.sequence.MulSequenceGenerator","text":"<p>               Bases: <code>BaseSequenceGenerator</code></p> <p>Implement a sequence generator that multiplies multiple sequences.</p> <p><code>sequence = sequence_1 * sequence_2 * ... * sequence_n</code></p> <p>Parameters:</p> Name Type Description Default <code>sequences</code> <code>Sequence[BaseSequenceGenerator | dict]</code> <p>The sequence generators.</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>if no sequence generator is provided.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; from startorch.sequence import Mul, RandUniform, RandNormal\n&gt;&gt;&gt; generator = Mul([RandUniform(), RandNormal()])\n&gt;&gt;&gt; generator\nMulSequenceGenerator(\n  (0): RandUniformSequenceGenerator(low=0.0, high=1.0, feature_size=(1,))\n  (1): RandNormalSequenceGenerator(mean=0.0, std=1.0, feature_size=(1,))\n)\n&gt;&gt;&gt; generator.generate(seq_len=12, batch_size=4)\ntensor([[...]])\n</code></pre>"},{"location":"refs/sequence/#startorch.sequence.Multinomial","title":"startorch.sequence.Multinomial","text":"<p>               Bases: <code>BaseSequenceGenerator</code></p> <p>Implement a class to generate sequences of categorical variables where each value is sampled from a multinomial distribution.</p> <p>Parameters:</p> Name Type Description Default <code>weights</code> <code>Tensor | Sequence[float]</code> <p>The vector of weights associated at each category. The weights have to be positive but do not need to sum to 1. The input is expected to be a <code>torch.Tensor</code> of shape <code>(num_categories,)</code> and type float.</p> required <code>feature_size</code> <code>tuple[int, ...] | list[int] | int</code> <p>The feature size.</p> <code>1</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; from startorch.sequence import Multinomial\n&gt;&gt;&gt; generator = Multinomial(weights=torch.ones(5))\n&gt;&gt;&gt; generator\nMultinomialSequenceGenerator(num_categories=5, feature_size=(1,))\n&gt;&gt;&gt; generator.generate(seq_len=12, batch_size=4)\ntensor([[...]])\n</code></pre>"},{"location":"refs/sequence/#startorch.sequence.Multinomial.create_exp_weights","title":"startorch.sequence.Multinomial.create_exp_weights  <code>classmethod</code>","text":"<pre><code>create_exp_weights(\n    num_categories: int, scale: float = 0.1\n) -&gt; MultinomialSequenceGenerator\n</code></pre> <p>Instantiate the weights with an exponential pattern.</p> <p>The weight of the <code>i</code>-th category (<code>w_i</code>) is generated with the rule: <code>w_i = exp(-scale * i)</code></p> <p>Parameters:</p> Name Type Description Default <code>num_categories</code> <code>int</code> <p>The number of categories.</p> required <code>scale</code> <code>float</code> <p>The scale parameter that controls the exponential function.</p> <code>0.1</code> <p>Returns:</p> Type Description <code>MultinomialSequenceGenerator</code> <p>A sequence generator where the weights of the multinomial distribution follow an exponential pattern.</p>"},{"location":"refs/sequence/#startorch.sequence.Multinomial.create_linear_weights","title":"startorch.sequence.Multinomial.create_linear_weights  <code>classmethod</code>","text":"<pre><code>create_linear_weights(\n    num_categories: int,\n) -&gt; MultinomialSequenceGenerator\n</code></pre> <p>Instantiate the weights with a linear pattern.</p> <p>The weight of the <code>i</code>-th category (<code>w_i</code>) is generated with the rule: <code>w_i = num_categories - i</code></p> <p>Parameters:</p> Name Type Description Default <code>num_categories</code> <code>int</code> <p>The number of categories.</p> required <p>Returns:</p> Type Description <code>MultinomialSequenceGenerator</code> <p>A sequence generator where the weights of the multinomial distribution follow a linear pattern.</p>"},{"location":"refs/sequence/#startorch.sequence.Multinomial.create_uniform_weights","title":"startorch.sequence.Multinomial.create_uniform_weights  <code>classmethod</code>","text":"<pre><code>create_uniform_weights(\n    num_categories: int,\n) -&gt; MultinomialSequenceGenerator\n</code></pre> <p>Instantiate the weights with a uniform pattern.</p> <p>All the categories have the same probability. The weight of the <code>i</code>-th category (<code>w_i</code>) is generated with the rule: <code>w_i = 1</code></p> <p>Parameters:</p> Name Type Description Default <code>num_categories</code> <code>int</code> <p>The number of categories.</p> required <p>Returns:</p> Type Description <code>MultinomialSequenceGenerator</code> <p>A sequence generator where the weights of the multinomial distribution follow a uniform pattern.</p>"},{"location":"refs/sequence/#startorch.sequence.MultinomialChoice","title":"startorch.sequence.MultinomialChoice","text":"<p>               Bases: <code>BaseSequenceGenerator</code></p> <p>Implement a sequence generator that select a sequence generator at each batch.</p> <p>This sequence generator is used to generate sequences with different generation processes. The user can specify a list of sequence generators with an associated weight. The weight is used to sample the sequence generator with a multinomial distribution. Higher weight means that the sequence generator has a higher probability to be selected at each batch. Each dictionary in the <code>generators</code> input should have the following items:</p> <pre><code>- a key ``'generator'`` which indicates the sequence generator\n    or its configuration.\n- an optional key ``'weight'`` with a float value which\n    indicates the weight of the sequence generator.\n    If this key is absent, the weight is set to ``1.0``.\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>sequences</code> <code>Sequence[dict[str, BaseSequenceGenerator | dict]]</code> <p>The sequence generators and their weights. See above to learn about the expected format.</p> required <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.sequence import MultinomialChoice, RandUniform, RandNormal\n&gt;&gt;&gt; generator = MultinomialChoice(\n...     (\n...         {\"weight\": 2.0, \"generator\": RandUniform()},\n...         {\"weight\": 1.0, \"generator\": RandNormal()},\n...     )\n... )\n&gt;&gt;&gt; generator.generate(seq_len=10, batch_size=2)\ntensor([[...]])\n</code></pre>"},{"location":"refs/sequence/#startorch.sequence.MultinomialChoiceSequenceGenerator","title":"startorch.sequence.MultinomialChoiceSequenceGenerator","text":"<p>               Bases: <code>BaseSequenceGenerator</code></p> <p>Implement a sequence generator that select a sequence generator at each batch.</p> <p>This sequence generator is used to generate sequences with different generation processes. The user can specify a list of sequence generators with an associated weight. The weight is used to sample the sequence generator with a multinomial distribution. Higher weight means that the sequence generator has a higher probability to be selected at each batch. Each dictionary in the <code>generators</code> input should have the following items:</p> <pre><code>- a key ``'generator'`` which indicates the sequence generator\n    or its configuration.\n- an optional key ``'weight'`` with a float value which\n    indicates the weight of the sequence generator.\n    If this key is absent, the weight is set to ``1.0``.\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>sequences</code> <code>Sequence[dict[str, BaseSequenceGenerator | dict]]</code> <p>The sequence generators and their weights. See above to learn about the expected format.</p> required <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.sequence import MultinomialChoice, RandUniform, RandNormal\n&gt;&gt;&gt; generator = MultinomialChoice(\n...     (\n...         {\"weight\": 2.0, \"generator\": RandUniform()},\n...         {\"weight\": 1.0, \"generator\": RandNormal()},\n...     )\n... )\n&gt;&gt;&gt; generator.generate(seq_len=10, batch_size=2)\ntensor([[...]])\n</code></pre>"},{"location":"refs/sequence/#startorch.sequence.MultinomialSequenceGenerator","title":"startorch.sequence.MultinomialSequenceGenerator","text":"<p>               Bases: <code>BaseSequenceGenerator</code></p> <p>Implement a class to generate sequences of categorical variables where each value is sampled from a multinomial distribution.</p> <p>Parameters:</p> Name Type Description Default <code>weights</code> <code>Tensor | Sequence[float]</code> <p>The vector of weights associated at each category. The weights have to be positive but do not need to sum to 1. The input is expected to be a <code>torch.Tensor</code> of shape <code>(num_categories,)</code> and type float.</p> required <code>feature_size</code> <code>tuple[int, ...] | list[int] | int</code> <p>The feature size.</p> <code>1</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; from startorch.sequence import Multinomial\n&gt;&gt;&gt; generator = Multinomial(weights=torch.ones(5))\n&gt;&gt;&gt; generator\nMultinomialSequenceGenerator(num_categories=5, feature_size=(1,))\n&gt;&gt;&gt; generator.generate(seq_len=12, batch_size=4)\ntensor([[...]])\n</code></pre>"},{"location":"refs/sequence/#startorch.sequence.MultinomialSequenceGenerator.create_exp_weights","title":"startorch.sequence.MultinomialSequenceGenerator.create_exp_weights  <code>classmethod</code>","text":"<pre><code>create_exp_weights(\n    num_categories: int, scale: float = 0.1\n) -&gt; MultinomialSequenceGenerator\n</code></pre> <p>Instantiate the weights with an exponential pattern.</p> <p>The weight of the <code>i</code>-th category (<code>w_i</code>) is generated with the rule: <code>w_i = exp(-scale * i)</code></p> <p>Parameters:</p> Name Type Description Default <code>num_categories</code> <code>int</code> <p>The number of categories.</p> required <code>scale</code> <code>float</code> <p>The scale parameter that controls the exponential function.</p> <code>0.1</code> <p>Returns:</p> Type Description <code>MultinomialSequenceGenerator</code> <p>A sequence generator where the weights of the multinomial distribution follow an exponential pattern.</p>"},{"location":"refs/sequence/#startorch.sequence.MultinomialSequenceGenerator.create_linear_weights","title":"startorch.sequence.MultinomialSequenceGenerator.create_linear_weights  <code>classmethod</code>","text":"<pre><code>create_linear_weights(\n    num_categories: int,\n) -&gt; MultinomialSequenceGenerator\n</code></pre> <p>Instantiate the weights with a linear pattern.</p> <p>The weight of the <code>i</code>-th category (<code>w_i</code>) is generated with the rule: <code>w_i = num_categories - i</code></p> <p>Parameters:</p> Name Type Description Default <code>num_categories</code> <code>int</code> <p>The number of categories.</p> required <p>Returns:</p> Type Description <code>MultinomialSequenceGenerator</code> <p>A sequence generator where the weights of the multinomial distribution follow a linear pattern.</p>"},{"location":"refs/sequence/#startorch.sequence.MultinomialSequenceGenerator.create_uniform_weights","title":"startorch.sequence.MultinomialSequenceGenerator.create_uniform_weights  <code>classmethod</code>","text":"<pre><code>create_uniform_weights(\n    num_categories: int,\n) -&gt; MultinomialSequenceGenerator\n</code></pre> <p>Instantiate the weights with a uniform pattern.</p> <p>All the categories have the same probability. The weight of the <code>i</code>-th category (<code>w_i</code>) is generated with the rule: <code>w_i = 1</code></p> <p>Parameters:</p> Name Type Description Default <code>num_categories</code> <code>int</code> <p>The number of categories.</p> required <p>Returns:</p> Type Description <code>MultinomialSequenceGenerator</code> <p>A sequence generator where the weights of the multinomial distribution follow a uniform pattern.</p>"},{"location":"refs/sequence/#startorch.sequence.Neg","title":"startorch.sequence.Neg","text":"<p>               Bases: <code>BaseWrapperSequenceGenerator</code></p> <p>Implement a sequence generator that computes the negation of a generated sequence.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; from startorch.sequence import Neg, RandUniform, RandNormal\n&gt;&gt;&gt; generator = Neg(RandUniform())\n&gt;&gt;&gt; generator\nNegSequenceGenerator(\n  (sequence): RandUniformSequenceGenerator(low=0.0, high=1.0, feature_size=(1,))\n)\n&gt;&gt;&gt; generator.generate(seq_len=12, batch_size=4)\ntensor([[...]])\n</code></pre>"},{"location":"refs/sequence/#startorch.sequence.NegSequenceGenerator","title":"startorch.sequence.NegSequenceGenerator","text":"<p>               Bases: <code>BaseWrapperSequenceGenerator</code></p> <p>Implement a sequence generator that computes the negation of a generated sequence.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; from startorch.sequence import Neg, RandUniform, RandNormal\n&gt;&gt;&gt; generator = Neg(RandUniform())\n&gt;&gt;&gt; generator\nNegSequenceGenerator(\n  (sequence): RandUniformSequenceGenerator(low=0.0, high=1.0, feature_size=(1,))\n)\n&gt;&gt;&gt; generator.generate(seq_len=12, batch_size=4)\ntensor([[...]])\n</code></pre>"},{"location":"refs/sequence/#startorch.sequence.Normal","title":"startorch.sequence.Normal","text":"<p>               Bases: <code>BaseSequenceGenerator</code></p> <p>Implement a class to generate sequence by sampling values from a Normal distribution.</p> <p>Parameters:</p> Name Type Description Default <code>mean</code> <code>BaseSequenceGenerator | dict</code> <p>A sequence generator (or its configuration) to generate the mean.</p> required <code>std</code> <code>BaseSequenceGenerator | dict</code> <p>A sequence generator (or its configuration) to generate the standard deviation.</p> required <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.sequence import Normal, RandUniform\n&gt;&gt;&gt; generator = Normal(\n...     mean=RandUniform(low=-1.0, high=1.0), std=RandUniform(low=1.0, high=2.0)\n... )\n&gt;&gt;&gt; generator\nNormalSequenceGenerator(\n  (mean): RandUniformSequenceGenerator(low=-1.0, high=1.0, feature_size=(1,))\n  (std): RandUniformSequenceGenerator(low=1.0, high=2.0, feature_size=(1,))\n)\n&gt;&gt;&gt; generator.generate(seq_len=6, batch_size=2)\ntensor([[...]])\n</code></pre>"},{"location":"refs/sequence/#startorch.sequence.NormalSequenceGenerator","title":"startorch.sequence.NormalSequenceGenerator","text":"<p>               Bases: <code>BaseSequenceGenerator</code></p> <p>Implement a class to generate sequence by sampling values from a Normal distribution.</p> <p>Parameters:</p> Name Type Description Default <code>mean</code> <code>BaseSequenceGenerator | dict</code> <p>A sequence generator (or its configuration) to generate the mean.</p> required <code>std</code> <code>BaseSequenceGenerator | dict</code> <p>A sequence generator (or its configuration) to generate the standard deviation.</p> required <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.sequence import Normal, RandUniform\n&gt;&gt;&gt; generator = Normal(\n...     mean=RandUniform(low=-1.0, high=1.0), std=RandUniform(low=1.0, high=2.0)\n... )\n&gt;&gt;&gt; generator\nNormalSequenceGenerator(\n  (mean): RandUniformSequenceGenerator(low=-1.0, high=1.0, feature_size=(1,))\n  (std): RandUniformSequenceGenerator(low=1.0, high=2.0, feature_size=(1,))\n)\n&gt;&gt;&gt; generator.generate(seq_len=6, batch_size=2)\ntensor([[...]])\n</code></pre>"},{"location":"refs/sequence/#startorch.sequence.Periodic","title":"startorch.sequence.Periodic","text":"<p>               Bases: <code>BaseSequenceGenerator</code></p> <p>Implement a sequence generator to generate periodic sequence from a regular sequence generator.</p> <p>Parameters:</p> Name Type Description Default <code>sequence</code> <code>BaseSequenceGenerator | BasePeriodicSequenceGenerator | dict</code> <p>A sequence generator or its configuration that is used to generate the periodic pattern.</p> required <code>period</code> <code>BaseTensorGenerator | dict</code> <p>The period length sampler or its configuration. This sampler is used to sample the period length at each batch.</p> required <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.sequence import Periodic, RandUniform\n&gt;&gt;&gt; from startorch.tensor import RandInt\n&gt;&gt;&gt; generator = Periodic(sequence=RandUniform(), period=RandInt(2, 5))\n&gt;&gt;&gt; generator\nPeriodicSequenceGenerator(\n  (sequence): RandUniformSequenceGenerator(low=0.0, high=1.0, feature_size=(1,))\n  (period): RandIntTensorGenerator(low=2, high=5)\n)\n&gt;&gt;&gt; generator.generate(seq_len=10, batch_size=2)\ntensor([[...]])\n</code></pre>"},{"location":"refs/sequence/#startorch.sequence.PeriodicSequenceGenerator","title":"startorch.sequence.PeriodicSequenceGenerator","text":"<p>               Bases: <code>BaseSequenceGenerator</code></p> <p>Implement a sequence generator to generate periodic sequence from a regular sequence generator.</p> <p>Parameters:</p> Name Type Description Default <code>sequence</code> <code>BaseSequenceGenerator | BasePeriodicSequenceGenerator | dict</code> <p>A sequence generator or its configuration that is used to generate the periodic pattern.</p> required <code>period</code> <code>BaseTensorGenerator | dict</code> <p>The period length sampler or its configuration. This sampler is used to sample the period length at each batch.</p> required <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.sequence import Periodic, RandUniform\n&gt;&gt;&gt; from startorch.tensor import RandInt\n&gt;&gt;&gt; generator = Periodic(sequence=RandUniform(), period=RandInt(2, 5))\n&gt;&gt;&gt; generator\nPeriodicSequenceGenerator(\n  (sequence): RandUniformSequenceGenerator(low=0.0, high=1.0, feature_size=(1,))\n  (period): RandIntTensorGenerator(low=2, high=5)\n)\n&gt;&gt;&gt; generator.generate(seq_len=10, batch_size=2)\ntensor([[...]])\n</code></pre>"},{"location":"refs/sequence/#startorch.sequence.Poisson","title":"startorch.sequence.Poisson","text":"<p>               Bases: <code>BaseSequenceGenerator</code></p> <p>Implement a class to generate sequence by sampling values from a Poisson distribution.</p> <p>The rates of the Poisson distribution are generated by the rate generator. The rate generator should return the rate for each value in the sequence. The rate values should be greater than 0.</p> <p>Parameters:</p> Name Type Description Default <code>rate</code> <code>BaseSequenceGenerator | dict</code> <p>The rate generator or its configuration. The rate generator should return valid rate values.</p> required <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.sequence import RandUniform, Poisson\n&gt;&gt;&gt; generator = Poisson(rate=RandUniform(low=1.0, high=2.0))\n&gt;&gt;&gt; generator\nPoissonSequenceGenerator(\n  (rate): RandUniformSequenceGenerator(low=1.0, high=2.0, feature_size=(1,))\n)\n&gt;&gt;&gt; generator.generate(seq_len=6, batch_size=2)\ntensor([[...]])\n</code></pre>"},{"location":"refs/sequence/#startorch.sequence.Poisson.generate_uniform_rate","title":"startorch.sequence.Poisson.generate_uniform_rate  <code>classmethod</code>","text":"<pre><code>generate_uniform_rate(\n    min_rate: float = 0.01,\n    max_rate: float = 1.0,\n    feature_size: tuple[int, ...] | list[int] | int = 1,\n) -&gt; PoissonSequenceGenerator\n</code></pre> <p>Implement a sequence generator where the rates of the Poisson distribution are sampled from a uniform distribution.</p> <p>Parameters:</p> Name Type Description Default <code>min_rate</code> <code>float</code> <p>The minimum rate value.</p> <code>0.01</code> <code>max_rate</code> <code>float</code> <p>The maximum rate value.</p> <code>1.0</code> <code>feature_size</code> <code>tuple[int, ...] | list[int] | int</code> <p>The feature size.</p> <code>1</code> <p>Returns:</p> Type Description <code>PoissonSequenceGenerator</code> <p>A sequence generator where the rates of the Poisson distribution are sampled from a uniform distribution (<code>UniformConstantSequenceGenerator</code>).</p>"},{"location":"refs/sequence/#startorch.sequence.PoissonSequenceGenerator","title":"startorch.sequence.PoissonSequenceGenerator","text":"<p>               Bases: <code>BaseSequenceGenerator</code></p> <p>Implement a class to generate sequence by sampling values from a Poisson distribution.</p> <p>The rates of the Poisson distribution are generated by the rate generator. The rate generator should return the rate for each value in the sequence. The rate values should be greater than 0.</p> <p>Parameters:</p> Name Type Description Default <code>rate</code> <code>BaseSequenceGenerator | dict</code> <p>The rate generator or its configuration. The rate generator should return valid rate values.</p> required <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.sequence import RandUniform, Poisson\n&gt;&gt;&gt; generator = Poisson(rate=RandUniform(low=1.0, high=2.0))\n&gt;&gt;&gt; generator\nPoissonSequenceGenerator(\n  (rate): RandUniformSequenceGenerator(low=1.0, high=2.0, feature_size=(1,))\n)\n&gt;&gt;&gt; generator.generate(seq_len=6, batch_size=2)\ntensor([[...]])\n</code></pre>"},{"location":"refs/sequence/#startorch.sequence.PoissonSequenceGenerator.generate_uniform_rate","title":"startorch.sequence.PoissonSequenceGenerator.generate_uniform_rate  <code>classmethod</code>","text":"<pre><code>generate_uniform_rate(\n    min_rate: float = 0.01,\n    max_rate: float = 1.0,\n    feature_size: tuple[int, ...] | list[int] | int = 1,\n) -&gt; PoissonSequenceGenerator\n</code></pre> <p>Implement a sequence generator where the rates of the Poisson distribution are sampled from a uniform distribution.</p> <p>Parameters:</p> Name Type Description Default <code>min_rate</code> <code>float</code> <p>The minimum rate value.</p> <code>0.01</code> <code>max_rate</code> <code>float</code> <p>The maximum rate value.</p> <code>1.0</code> <code>feature_size</code> <code>tuple[int, ...] | list[int] | int</code> <p>The feature size.</p> <code>1</code> <p>Returns:</p> Type Description <code>PoissonSequenceGenerator</code> <p>A sequence generator where the rates of the Poisson distribution are sampled from a uniform distribution (<code>UniformConstantSequenceGenerator</code>).</p>"},{"location":"refs/sequence/#startorch.sequence.RandAsinhUniform","title":"startorch.sequence.RandAsinhUniform","text":"<p>               Bases: <code>BaseSequenceGenerator</code></p> <p>Implement a sequence generator to generate sequences by sampling values from an asinh-uniform distribution.</p> <p>Parameters:</p> Name Type Description Default <code>low</code> <code>float</code> <p>The minimum value (inclusive).</p> required <code>high</code> <code>float</code> <p>The maximum value (exclusive).</p> required <code>feature_size</code> <code>tuple[int, ...] | list[int] | int</code> <p>The feature size.</p> <code>1</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>if <code>high</code> is lower than <code>low</code>.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; from startorch.sequence import RandAsinhUniform\n&gt;&gt;&gt; generator = RandAsinhUniform(low=1.0, high=10.0)\n&gt;&gt;&gt; generator\nRandAsinhUniformSequenceGenerator(low=1.0, high=10.0, feature_size=(1,))\n&gt;&gt;&gt; generator.generate(seq_len=12, batch_size=4)\ntensor([[...]])\n</code></pre>"},{"location":"refs/sequence/#startorch.sequence.RandAsinhUniformSequenceGenerator","title":"startorch.sequence.RandAsinhUniformSequenceGenerator","text":"<p>               Bases: <code>BaseSequenceGenerator</code></p> <p>Implement a sequence generator to generate sequences by sampling values from an asinh-uniform distribution.</p> <p>Parameters:</p> Name Type Description Default <code>low</code> <code>float</code> <p>The minimum value (inclusive).</p> required <code>high</code> <code>float</code> <p>The maximum value (exclusive).</p> required <code>feature_size</code> <code>tuple[int, ...] | list[int] | int</code> <p>The feature size.</p> <code>1</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>if <code>high</code> is lower than <code>low</code>.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; from startorch.sequence import RandAsinhUniform\n&gt;&gt;&gt; generator = RandAsinhUniform(low=1.0, high=10.0)\n&gt;&gt;&gt; generator\nRandAsinhUniformSequenceGenerator(low=1.0, high=10.0, feature_size=(1,))\n&gt;&gt;&gt; generator.generate(seq_len=12, batch_size=4)\ntensor([[...]])\n</code></pre>"},{"location":"refs/sequence/#startorch.sequence.RandCauchy","title":"startorch.sequence.RandCauchy","text":"<p>               Bases: <code>BaseSequenceGenerator</code></p> <p>Implement a class to generate sequence by sampling values from a Cauchy distribution.</p> <p>Parameters:</p> Name Type Description Default <code>loc</code> <code>float</code> <p>The location/median of the Cauchy distribution.</p> <code>0.0</code> <code>scale</code> <code>float</code> <p>The scale of the distribution.</p> <code>1.0</code> <code>feature_size</code> <code>tuple[int, ...] | list[int] | int</code> <p>The feature size.</p> <code>1</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>if <code>scale</code> is not a positive number.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.sequence import RandCauchy\n&gt;&gt;&gt; generator = RandCauchy(loc=0.0, scale=1.0)\n&gt;&gt;&gt; generator\nRandCauchySequenceGenerator(loc=0.0, scale=1.0, feature_size=(1,))\n&gt;&gt;&gt; generator.generate(seq_len=6, batch_size=2)\ntensor([[...]])\n</code></pre>"},{"location":"refs/sequence/#startorch.sequence.RandCauchySequenceGenerator","title":"startorch.sequence.RandCauchySequenceGenerator","text":"<p>               Bases: <code>BaseSequenceGenerator</code></p> <p>Implement a class to generate sequence by sampling values from a Cauchy distribution.</p> <p>Parameters:</p> Name Type Description Default <code>loc</code> <code>float</code> <p>The location/median of the Cauchy distribution.</p> <code>0.0</code> <code>scale</code> <code>float</code> <p>The scale of the distribution.</p> <code>1.0</code> <code>feature_size</code> <code>tuple[int, ...] | list[int] | int</code> <p>The feature size.</p> <code>1</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>if <code>scale</code> is not a positive number.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.sequence import RandCauchy\n&gt;&gt;&gt; generator = RandCauchy(loc=0.0, scale=1.0)\n&gt;&gt;&gt; generator\nRandCauchySequenceGenerator(loc=0.0, scale=1.0, feature_size=(1,))\n&gt;&gt;&gt; generator.generate(seq_len=6, batch_size=2)\ntensor([[...]])\n</code></pre>"},{"location":"refs/sequence/#startorch.sequence.RandExponential","title":"startorch.sequence.RandExponential","text":"<p>               Bases: <code>BaseSequenceGenerator</code></p> <p>Implement a class to generate sequences by sampling values from an Exponential distribution.</p> <p>Parameters:</p> Name Type Description Default <code>rate</code> <code>float</code> <p>The rate of the Exponential distribution.</p> <code>1.0</code> <code>feature_size</code> <code>tuple[int, ...] | list[int] | int</code> <p>The feature size.</p> <code>1</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>if <code>rate</code> is not a positive number.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.sequence import RandExponential\n&gt;&gt;&gt; generator = RandExponential(rate=1.0)\n&gt;&gt;&gt; generator\nRandExponentialSequenceGenerator(rate=1.0, feature_size=(1,))\n&gt;&gt;&gt; generator.generate(seq_len=6, batch_size=2)\ntensor([[...]])\n</code></pre>"},{"location":"refs/sequence/#startorch.sequence.RandExponentialSequenceGenerator","title":"startorch.sequence.RandExponentialSequenceGenerator","text":"<p>               Bases: <code>BaseSequenceGenerator</code></p> <p>Implement a class to generate sequences by sampling values from an Exponential distribution.</p> <p>Parameters:</p> Name Type Description Default <code>rate</code> <code>float</code> <p>The rate of the Exponential distribution.</p> <code>1.0</code> <code>feature_size</code> <code>tuple[int, ...] | list[int] | int</code> <p>The feature size.</p> <code>1</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>if <code>rate</code> is not a positive number.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.sequence import RandExponential\n&gt;&gt;&gt; generator = RandExponential(rate=1.0)\n&gt;&gt;&gt; generator\nRandExponentialSequenceGenerator(rate=1.0, feature_size=(1,))\n&gt;&gt;&gt; generator.generate(seq_len=6, batch_size=2)\ntensor([[...]])\n</code></pre>"},{"location":"refs/sequence/#startorch.sequence.RandHalfCauchy","title":"startorch.sequence.RandHalfCauchy","text":"<p>               Bases: <code>BaseSequenceGenerator</code></p> <p>Implement a class to generate sequence by sampling values from a half-Cauchy distribution.</p> <p>Parameters:</p> Name Type Description Default <code>scale</code> <code>float</code> <p>The scale of the distribution.</p> <code>1.0</code> <code>feature_size</code> <code>tuple[int, ...] | list[int] | int</code> <p>The feature size.</p> <code>1</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>if <code>scale</code> is not a positive number.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.sequence import RandHalfCauchy\n&gt;&gt;&gt; generator = RandHalfCauchy(scale=1.0)\n&gt;&gt;&gt; generator\nRandHalfCauchySequenceGenerator(scale=1.0, feature_size=(1,))\n&gt;&gt;&gt; generator.generate(seq_len=6, batch_size=2)\ntensor([[...]])\n</code></pre>"},{"location":"refs/sequence/#startorch.sequence.RandHalfCauchySequenceGenerator","title":"startorch.sequence.RandHalfCauchySequenceGenerator","text":"<p>               Bases: <code>BaseSequenceGenerator</code></p> <p>Implement a class to generate sequence by sampling values from a half-Cauchy distribution.</p> <p>Parameters:</p> Name Type Description Default <code>scale</code> <code>float</code> <p>The scale of the distribution.</p> <code>1.0</code> <code>feature_size</code> <code>tuple[int, ...] | list[int] | int</code> <p>The feature size.</p> <code>1</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>if <code>scale</code> is not a positive number.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.sequence import RandHalfCauchy\n&gt;&gt;&gt; generator = RandHalfCauchy(scale=1.0)\n&gt;&gt;&gt; generator\nRandHalfCauchySequenceGenerator(scale=1.0, feature_size=(1,))\n&gt;&gt;&gt; generator.generate(seq_len=6, batch_size=2)\ntensor([[...]])\n</code></pre>"},{"location":"refs/sequence/#startorch.sequence.RandHalfNormal","title":"startorch.sequence.RandHalfNormal","text":"<p>               Bases: <code>BaseSequenceGenerator</code></p> <p>Implement a class to generate sequence by sampling values from a half-Normal distribution.</p> <p>Parameters:</p> Name Type Description Default <code>std</code> <code>float</code> <p>The std of the distribution.</p> <code>1.0</code> <code>feature_size</code> <code>tuple[int, ...] | list[int] | int</code> <p>The feature size.</p> <code>1</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>if <code>std</code> is not a positive number.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.sequence import RandHalfNormal\n&gt;&gt;&gt; generator = RandHalfNormal(std=1.0)\n&gt;&gt;&gt; generator\nRandHalfNormalSequenceGenerator(std=1.0, feature_size=(1,))\n&gt;&gt;&gt; generator.generate(seq_len=6, batch_size=2)\ntensor([[...]])\n</code></pre>"},{"location":"refs/sequence/#startorch.sequence.RandHalfNormalSequenceGenerator","title":"startorch.sequence.RandHalfNormalSequenceGenerator","text":"<p>               Bases: <code>BaseSequenceGenerator</code></p> <p>Implement a class to generate sequence by sampling values from a half-Normal distribution.</p> <p>Parameters:</p> Name Type Description Default <code>std</code> <code>float</code> <p>The std of the distribution.</p> <code>1.0</code> <code>feature_size</code> <code>tuple[int, ...] | list[int] | int</code> <p>The feature size.</p> <code>1</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>if <code>std</code> is not a positive number.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.sequence import RandHalfNormal\n&gt;&gt;&gt; generator = RandHalfNormal(std=1.0)\n&gt;&gt;&gt; generator\nRandHalfNormalSequenceGenerator(std=1.0, feature_size=(1,))\n&gt;&gt;&gt; generator.generate(seq_len=6, batch_size=2)\ntensor([[...]])\n</code></pre>"},{"location":"refs/sequence/#startorch.sequence.RandInt","title":"startorch.sequence.RandInt","text":"<p>               Bases: <code>BaseSequenceGenerator</code></p> <p>Implement a class to generate sequences of uniformly distributed integers.</p> <p>Parameters:</p> Name Type Description Default <code>low</code> <code>int</code> <p>The minimum value (included).</p> required <code>high</code> <code>int</code> <p>The maximum value (excluded).</p> required <code>feature_size</code> <code>tuple[int, ...] | list[int] | int</code> <p>The feature size.</p> <code>()</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>if <code>high</code> is lower than <code>low</code>.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; from startorch.sequence import RandInt\n&gt;&gt;&gt; generator = RandInt(0, 100)\n&gt;&gt;&gt; generator\nRandIntSequenceGenerator(low=0, high=100, feature_size=())\n&gt;&gt;&gt; generator.generate(seq_len=12, batch_size=4)\ntensor([[...]])\n</code></pre>"},{"location":"refs/sequence/#startorch.sequence.RandIntSequenceGenerator","title":"startorch.sequence.RandIntSequenceGenerator","text":"<p>               Bases: <code>BaseSequenceGenerator</code></p> <p>Implement a class to generate sequences of uniformly distributed integers.</p> <p>Parameters:</p> Name Type Description Default <code>low</code> <code>int</code> <p>The minimum value (included).</p> required <code>high</code> <code>int</code> <p>The maximum value (excluded).</p> required <code>feature_size</code> <code>tuple[int, ...] | list[int] | int</code> <p>The feature size.</p> <code>()</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>if <code>high</code> is lower than <code>low</code>.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; from startorch.sequence import RandInt\n&gt;&gt;&gt; generator = RandInt(0, 100)\n&gt;&gt;&gt; generator\nRandIntSequenceGenerator(low=0, high=100, feature_size=())\n&gt;&gt;&gt; generator.generate(seq_len=12, batch_size=4)\ntensor([[...]])\n</code></pre>"},{"location":"refs/sequence/#startorch.sequence.RandLogNormal","title":"startorch.sequence.RandLogNormal","text":"<p>               Bases: <code>BaseSequenceGenerator</code></p> <p>Implement a class to generate sequence by sampling values from a log-Normal distribution.</p> <p>Parameters:</p> Name Type Description Default <code>mean</code> <code>float</code> <p>The mean of the underlying Normal distribution.</p> <code>0.0</code> <code>std</code> <code>float</code> <p>The standard deviation of the underlying Normal distribution.</p> <code>1.0</code> <code>feature_size</code> <code>tuple[int, ...] | list[int] | int</code> <p>The feature size.</p> <code>1</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>if <code>std</code> is not a positive number.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.sequence import RandLogNormal\n&gt;&gt;&gt; generator = RandLogNormal(mean=0.0, std=1.0)\n&gt;&gt;&gt; generator\nRandLogNormalSequenceGenerator(mean=0.0, std=1.0, feature_size=(1,))\n&gt;&gt;&gt; generator.generate(seq_len=6, batch_size=2)\ntensor([[...]])\n</code></pre>"},{"location":"refs/sequence/#startorch.sequence.RandLogNormalSequenceGenerator","title":"startorch.sequence.RandLogNormalSequenceGenerator","text":"<p>               Bases: <code>BaseSequenceGenerator</code></p> <p>Implement a class to generate sequence by sampling values from a log-Normal distribution.</p> <p>Parameters:</p> Name Type Description Default <code>mean</code> <code>float</code> <p>The mean of the underlying Normal distribution.</p> <code>0.0</code> <code>std</code> <code>float</code> <p>The standard deviation of the underlying Normal distribution.</p> <code>1.0</code> <code>feature_size</code> <code>tuple[int, ...] | list[int] | int</code> <p>The feature size.</p> <code>1</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>if <code>std</code> is not a positive number.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.sequence import RandLogNormal\n&gt;&gt;&gt; generator = RandLogNormal(mean=0.0, std=1.0)\n&gt;&gt;&gt; generator\nRandLogNormalSequenceGenerator(mean=0.0, std=1.0, feature_size=(1,))\n&gt;&gt;&gt; generator.generate(seq_len=6, batch_size=2)\ntensor([[...]])\n</code></pre>"},{"location":"refs/sequence/#startorch.sequence.RandLogUniform","title":"startorch.sequence.RandLogUniform","text":"<p>               Bases: <code>BaseSequenceGenerator</code></p> <p>Implement a sequence generator to generate sequences by sampling values from a log-uniform distribution.</p> <p>Parameters:</p> Name Type Description Default <code>low</code> <code>float</code> <p>The minimum value (inclusive).</p> required <code>high</code> <code>float</code> <p>The maximum value (exclusive).</p> required <code>feature_size</code> <code>tuple[int, ...] | list[int] | int</code> <p>The feature size.</p> <code>1</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>if <code>high</code> is lower than <code>low</code>.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; from startorch.sequence import RandLogUniform\n&gt;&gt;&gt; generator = RandLogUniform(low=1.0, high=10.0)\n&gt;&gt;&gt; generator\nRandLogUniformSequenceGenerator(low=1.0, high=10.0, feature_size=(1,))\n&gt;&gt;&gt; generator.generate(seq_len=12, batch_size=4)\ntensor([[...]])\n</code></pre>"},{"location":"refs/sequence/#startorch.sequence.RandLogUniformSequenceGenerator","title":"startorch.sequence.RandLogUniformSequenceGenerator","text":"<p>               Bases: <code>BaseSequenceGenerator</code></p> <p>Implement a sequence generator to generate sequences by sampling values from a log-uniform distribution.</p> <p>Parameters:</p> Name Type Description Default <code>low</code> <code>float</code> <p>The minimum value (inclusive).</p> required <code>high</code> <code>float</code> <p>The maximum value (exclusive).</p> required <code>feature_size</code> <code>tuple[int, ...] | list[int] | int</code> <p>The feature size.</p> <code>1</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>if <code>high</code> is lower than <code>low</code>.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; from startorch.sequence import RandLogUniform\n&gt;&gt;&gt; generator = RandLogUniform(low=1.0, high=10.0)\n&gt;&gt;&gt; generator\nRandLogUniformSequenceGenerator(low=1.0, high=10.0, feature_size=(1,))\n&gt;&gt;&gt; generator.generate(seq_len=12, batch_size=4)\ntensor([[...]])\n</code></pre>"},{"location":"refs/sequence/#startorch.sequence.RandNormal","title":"startorch.sequence.RandNormal","text":"<p>               Bases: <code>BaseSequenceGenerator</code></p> <p>Implement a sequence generator to generate cyclic sequences by sampling values from a Normal distribution.</p> <p>Parameters:</p> Name Type Description Default <code>mean</code> <code>float</code> <p>The mean of the Normal distribution.</p> <code>0.0</code> <code>std</code> <code>float</code> <p>The standard deviation of the Normal distribution.</p> <code>1.0</code> <code>feature_size</code> <code>tuple[int, ...] | list[int] | int</code> <p>The feature size.</p> <code>1</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>if <code>std</code> is not a positive number.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.sequence import RandNormal\n&gt;&gt;&gt; generator = RandNormal(mean=0.0, std=1.0)\n&gt;&gt;&gt; generator\nRandNormalSequenceGenerator(mean=0.0, std=1.0, feature_size=(1,))\n&gt;&gt;&gt; generator.generate(seq_len=6, batch_size=2)\ntensor([[...]])\n</code></pre>"},{"location":"refs/sequence/#startorch.sequence.RandNormalSequenceGenerator","title":"startorch.sequence.RandNormalSequenceGenerator","text":"<p>               Bases: <code>BaseSequenceGenerator</code></p> <p>Implement a sequence generator to generate cyclic sequences by sampling values from a Normal distribution.</p> <p>Parameters:</p> Name Type Description Default <code>mean</code> <code>float</code> <p>The mean of the Normal distribution.</p> <code>0.0</code> <code>std</code> <code>float</code> <p>The standard deviation of the Normal distribution.</p> <code>1.0</code> <code>feature_size</code> <code>tuple[int, ...] | list[int] | int</code> <p>The feature size.</p> <code>1</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>if <code>std</code> is not a positive number.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.sequence import RandNormal\n&gt;&gt;&gt; generator = RandNormal(mean=0.0, std=1.0)\n&gt;&gt;&gt; generator\nRandNormalSequenceGenerator(mean=0.0, std=1.0, feature_size=(1,))\n&gt;&gt;&gt; generator.generate(seq_len=6, batch_size=2)\ntensor([[...]])\n</code></pre>"},{"location":"refs/sequence/#startorch.sequence.RandPoisson","title":"startorch.sequence.RandPoisson","text":"<p>               Bases: <code>BaseSequenceGenerator</code></p> <p>Implement a class to generate sequence by sampling values from a Poisson distribution.</p> <p>Parameters:</p> Name Type Description Default <code>rate</code> <code>float</code> <p>The rate of the Poisson distribution. This value has to be greater than 0.</p> <code>1.0</code> <code>feature_size</code> <code>tuple[int, ...] | list[int] | int</code> <p>The feature size.</p> <code>1</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>if <code>rate</code> is not a positive number.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.sequence import RandPoisson\n&gt;&gt;&gt; generator = RandPoisson(rate=1.0)\n&gt;&gt;&gt; generator\nRandPoissonSequenceGenerator(rate=1.0, feature_size=(1,))\n&gt;&gt;&gt; generator.generate(seq_len=6, batch_size=2)\ntensor([[...]])\n</code></pre>"},{"location":"refs/sequence/#startorch.sequence.RandPoissonSequenceGenerator","title":"startorch.sequence.RandPoissonSequenceGenerator","text":"<p>               Bases: <code>BaseSequenceGenerator</code></p> <p>Implement a class to generate sequence by sampling values from a Poisson distribution.</p> <p>Parameters:</p> Name Type Description Default <code>rate</code> <code>float</code> <p>The rate of the Poisson distribution. This value has to be greater than 0.</p> <code>1.0</code> <code>feature_size</code> <code>tuple[int, ...] | list[int] | int</code> <p>The feature size.</p> <code>1</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>if <code>rate</code> is not a positive number.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.sequence import RandPoisson\n&gt;&gt;&gt; generator = RandPoisson(rate=1.0)\n&gt;&gt;&gt; generator\nRandPoissonSequenceGenerator(rate=1.0, feature_size=(1,))\n&gt;&gt;&gt; generator.generate(seq_len=6, batch_size=2)\ntensor([[...]])\n</code></pre>"},{"location":"refs/sequence/#startorch.sequence.RandTruncCauchy","title":"startorch.sequence.RandTruncCauchy","text":"<p>               Bases: <code>BaseSequenceGenerator</code></p> <p>Implement a class to generate sequence by sampling values from a truncated Cauchy distribution.</p> <p>Parameters:</p> Name Type Description Default <code>loc</code> <code>float</code> <p>The location/median of the Cauchy distribution.</p> <code>0.0</code> <code>scale</code> <code>float</code> <p>The scale of the distribution.</p> <code>1.0</code> <code>min_value</code> <code>float</code> <p>The minimum value (included).</p> <code>-2.0</code> <code>max_value</code> <code>float</code> <p>The maximum value (excluded).</p> <code>2.0</code> <code>feature_size</code> <code>tuple[int, ...] | list[int] | int</code> <p>The feature size.</p> <code>1</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>if <code>std</code> is not a positive number.</p> <code>ValueError</code> <p>if <code>max_value</code> is lower than <code>min_value</code>.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.sequence import RandTruncCauchy\n&gt;&gt;&gt; generator = RandTruncCauchy(loc=0.0, scale=1.0, min_value=-5.0, max_value=5.0)\n&gt;&gt;&gt; generator\nRandTruncCauchySequenceGenerator(loc=0.0, scale=1.0, min_value=-5.0, max_value=5.0, feature_size=(1,))\n&gt;&gt;&gt; generator.generate(seq_len=6, batch_size=2)\ntensor([[...]])\n</code></pre>"},{"location":"refs/sequence/#startorch.sequence.RandTruncCauchySequenceGenerator","title":"startorch.sequence.RandTruncCauchySequenceGenerator","text":"<p>               Bases: <code>BaseSequenceGenerator</code></p> <p>Implement a class to generate sequence by sampling values from a truncated Cauchy distribution.</p> <p>Parameters:</p> Name Type Description Default <code>loc</code> <code>float</code> <p>The location/median of the Cauchy distribution.</p> <code>0.0</code> <code>scale</code> <code>float</code> <p>The scale of the distribution.</p> <code>1.0</code> <code>min_value</code> <code>float</code> <p>The minimum value (included).</p> <code>-2.0</code> <code>max_value</code> <code>float</code> <p>The maximum value (excluded).</p> <code>2.0</code> <code>feature_size</code> <code>tuple[int, ...] | list[int] | int</code> <p>The feature size.</p> <code>1</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>if <code>std</code> is not a positive number.</p> <code>ValueError</code> <p>if <code>max_value</code> is lower than <code>min_value</code>.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.sequence import RandTruncCauchy\n&gt;&gt;&gt; generator = RandTruncCauchy(loc=0.0, scale=1.0, min_value=-5.0, max_value=5.0)\n&gt;&gt;&gt; generator\nRandTruncCauchySequenceGenerator(loc=0.0, scale=1.0, min_value=-5.0, max_value=5.0, feature_size=(1,))\n&gt;&gt;&gt; generator.generate(seq_len=6, batch_size=2)\ntensor([[...]])\n</code></pre>"},{"location":"refs/sequence/#startorch.sequence.RandTruncExponential","title":"startorch.sequence.RandTruncExponential","text":"<p>               Bases: <code>BaseSequenceGenerator</code></p> <p>Implement a class to generate sequences by sampling values from a truncated Exponential distribution.</p> <p>Parameters:</p> Name Type Description Default <code>rate</code> <code>float</code> <p>The rate of the Exponential distribution.</p> <code>1.0</code> <code>max_value</code> <code>float</code> <p>The maximum value.</p> <code>5.0</code> <code>feature_size</code> <code>tuple[int, ...] | list[int] | int</code> <p>The feature size.</p> <code>1</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>if <code>rate</code> is not a positive number.</p> <code>ValueError</code> <p>if <code>max_value</code> is not a positive number.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.sequence import RandTruncExponential\n&gt;&gt;&gt; generator = RandTruncExponential(rate=1.0, max_value=3.0)\n&gt;&gt;&gt; generator\nRandTruncExponentialSequenceGenerator(rate=1.0, max_value=3.0, feature_size=(1,))\n&gt;&gt;&gt; generator.generate(seq_len=6, batch_size=2)\ntensor([[...]])\n</code></pre>"},{"location":"refs/sequence/#startorch.sequence.RandTruncExponentialSequenceGenerator","title":"startorch.sequence.RandTruncExponentialSequenceGenerator","text":"<p>               Bases: <code>BaseSequenceGenerator</code></p> <p>Implement a class to generate sequences by sampling values from a truncated Exponential distribution.</p> <p>Parameters:</p> Name Type Description Default <code>rate</code> <code>float</code> <p>The rate of the Exponential distribution.</p> <code>1.0</code> <code>max_value</code> <code>float</code> <p>The maximum value.</p> <code>5.0</code> <code>feature_size</code> <code>tuple[int, ...] | list[int] | int</code> <p>The feature size.</p> <code>1</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>if <code>rate</code> is not a positive number.</p> <code>ValueError</code> <p>if <code>max_value</code> is not a positive number.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.sequence import RandTruncExponential\n&gt;&gt;&gt; generator = RandTruncExponential(rate=1.0, max_value=3.0)\n&gt;&gt;&gt; generator\nRandTruncExponentialSequenceGenerator(rate=1.0, max_value=3.0, feature_size=(1,))\n&gt;&gt;&gt; generator.generate(seq_len=6, batch_size=2)\ntensor([[...]])\n</code></pre>"},{"location":"refs/sequence/#startorch.sequence.RandTruncHalfCauchy","title":"startorch.sequence.RandTruncHalfCauchy","text":"<p>               Bases: <code>BaseSequenceGenerator</code></p> <p>Implement a class to generate sequence by sampling values from a truncated half-Cauchy distribution.</p> <p>Parameters:</p> Name Type Description Default <code>scale</code> <code>float</code> <p>The scale of the distribution.</p> <code>1.0</code> <code>max_value</code> <code>float</code> <p>The maximum value.</p> <code>4.0</code> <code>feature_size</code> <code>tuple[int, ...] | list[int] | int</code> <p>The feature size.</p> <code>1</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>if <code>scale</code> is not a positive number.</p> <code>ValueError</code> <p>if <code>max_value</code> is not a positive number.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.sequence import RandTruncHalfCauchy\n&gt;&gt;&gt; generator = RandTruncHalfCauchy(scale=1.0, max_value=5.0)\n&gt;&gt;&gt; generator\nRandTruncHalfCauchySequenceGenerator(scale=1.0, max_value=5.0, feature_size=(1,))\n&gt;&gt;&gt; generator.generate(seq_len=6, batch_size=2)\ntensor([[...]])\n</code></pre>"},{"location":"refs/sequence/#startorch.sequence.RandTruncHalfCauchySequenceGenerator","title":"startorch.sequence.RandTruncHalfCauchySequenceGenerator","text":"<p>               Bases: <code>BaseSequenceGenerator</code></p> <p>Implement a class to generate sequence by sampling values from a truncated half-Cauchy distribution.</p> <p>Parameters:</p> Name Type Description Default <code>scale</code> <code>float</code> <p>The scale of the distribution.</p> <code>1.0</code> <code>max_value</code> <code>float</code> <p>The maximum value.</p> <code>4.0</code> <code>feature_size</code> <code>tuple[int, ...] | list[int] | int</code> <p>The feature size.</p> <code>1</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>if <code>scale</code> is not a positive number.</p> <code>ValueError</code> <p>if <code>max_value</code> is not a positive number.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.sequence import RandTruncHalfCauchy\n&gt;&gt;&gt; generator = RandTruncHalfCauchy(scale=1.0, max_value=5.0)\n&gt;&gt;&gt; generator\nRandTruncHalfCauchySequenceGenerator(scale=1.0, max_value=5.0, feature_size=(1,))\n&gt;&gt;&gt; generator.generate(seq_len=6, batch_size=2)\ntensor([[...]])\n</code></pre>"},{"location":"refs/sequence/#startorch.sequence.RandTruncHalfNormal","title":"startorch.sequence.RandTruncHalfNormal","text":"<p>               Bases: <code>BaseSequenceGenerator</code></p> <p>Implement a class to generate sequence by sampling values from a truncated half-Normal distribution.</p> <p>Parameters:</p> Name Type Description Default <code>std</code> <code>float</code> <p>The std of the distribution.</p> <code>1.0</code> <code>max_value</code> <code>float</code> <p>The maximum value.</p> <code>3.0</code> <code>feature_size</code> <code>tuple[int, ...] | list[int] | int</code> <p>The feature size.</p> <code>1</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>if <code>std</code> is not a positive number.</p> <code>ValueError</code> <p>if <code>max_value</code> is not a positive number.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.sequence import RandTruncHalfNormal\n&gt;&gt;&gt; generator = RandTruncHalfNormal(std=1.0, max_value=1.0)\n&gt;&gt;&gt; generator\nRandTruncHalfNormalSequenceGenerator(std=1.0, max_value=1.0, feature_size=(1,))\n&gt;&gt;&gt; generator.generate(seq_len=6, batch_size=2)\ntensor([[...]])\n</code></pre>"},{"location":"refs/sequence/#startorch.sequence.RandTruncHalfNormalSequenceGenerator","title":"startorch.sequence.RandTruncHalfNormalSequenceGenerator","text":"<p>               Bases: <code>BaseSequenceGenerator</code></p> <p>Implement a class to generate sequence by sampling values from a truncated half-Normal distribution.</p> <p>Parameters:</p> Name Type Description Default <code>std</code> <code>float</code> <p>The std of the distribution.</p> <code>1.0</code> <code>max_value</code> <code>float</code> <p>The maximum value.</p> <code>3.0</code> <code>feature_size</code> <code>tuple[int, ...] | list[int] | int</code> <p>The feature size.</p> <code>1</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>if <code>std</code> is not a positive number.</p> <code>ValueError</code> <p>if <code>max_value</code> is not a positive number.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.sequence import RandTruncHalfNormal\n&gt;&gt;&gt; generator = RandTruncHalfNormal(std=1.0, max_value=1.0)\n&gt;&gt;&gt; generator\nRandTruncHalfNormalSequenceGenerator(std=1.0, max_value=1.0, feature_size=(1,))\n&gt;&gt;&gt; generator.generate(seq_len=6, batch_size=2)\ntensor([[...]])\n</code></pre>"},{"location":"refs/sequence/#startorch.sequence.RandTruncLogNormal","title":"startorch.sequence.RandTruncLogNormal","text":"<p>               Bases: <code>BaseSequenceGenerator</code></p> <p>Implement a sequence generator to generate cyclic sequences by sampling values from a truncated log-Normal distribution.</p> <p>Parameters:</p> Name Type Description Default <code>mean</code> <code>float</code> <p>The mean of the log-Normal distribution.</p> <code>0.0</code> <code>std</code> <code>float</code> <p>The standard deviation of the log-Normal distribution.</p> <code>1.0</code> <code>min_value</code> <code>float</code> <p>The minimum value.</p> <code>0.0</code> <code>max_value</code> <code>float</code> <p>The maximum value.</p> <code>5.0</code> <code>feature_size</code> <code>tuple[int, ...] | list[int] | int</code> <p>The feature size.</p> <code>1</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>if <code>std</code> is not a positive number.</p> <code>ValueError</code> <p>if <code>max_value</code> is lower than <code>min_value</code>.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.sequence import RandTruncLogNormal\n&gt;&gt;&gt; generator = RandTruncLogNormal(mean=0.0, std=1.0, min_value=0.0, max_value=1.0)\n&gt;&gt;&gt; generator\nRandTruncLogNormalSequenceGenerator(mean=0.0, std=1.0, min_value=0.0, max_value=1.0, feature_size=(1,))\n&gt;&gt;&gt; generator.generate(seq_len=6, batch_size=2)\ntensor([[...]])\n</code></pre>"},{"location":"refs/sequence/#startorch.sequence.RandTruncLogNormalSequenceGenerator","title":"startorch.sequence.RandTruncLogNormalSequenceGenerator","text":"<p>               Bases: <code>BaseSequenceGenerator</code></p> <p>Implement a sequence generator to generate cyclic sequences by sampling values from a truncated log-Normal distribution.</p> <p>Parameters:</p> Name Type Description Default <code>mean</code> <code>float</code> <p>The mean of the log-Normal distribution.</p> <code>0.0</code> <code>std</code> <code>float</code> <p>The standard deviation of the log-Normal distribution.</p> <code>1.0</code> <code>min_value</code> <code>float</code> <p>The minimum value.</p> <code>0.0</code> <code>max_value</code> <code>float</code> <p>The maximum value.</p> <code>5.0</code> <code>feature_size</code> <code>tuple[int, ...] | list[int] | int</code> <p>The feature size.</p> <code>1</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>if <code>std</code> is not a positive number.</p> <code>ValueError</code> <p>if <code>max_value</code> is lower than <code>min_value</code>.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.sequence import RandTruncLogNormal\n&gt;&gt;&gt; generator = RandTruncLogNormal(mean=0.0, std=1.0, min_value=0.0, max_value=1.0)\n&gt;&gt;&gt; generator\nRandTruncLogNormalSequenceGenerator(mean=0.0, std=1.0, min_value=0.0, max_value=1.0, feature_size=(1,))\n&gt;&gt;&gt; generator.generate(seq_len=6, batch_size=2)\ntensor([[...]])\n</code></pre>"},{"location":"refs/sequence/#startorch.sequence.RandTruncNormal","title":"startorch.sequence.RandTruncNormal","text":"<p>               Bases: <code>BaseSequenceGenerator</code></p> <p>Implement a sequence generator to generate cyclic sequences by sampling values from a truncated Normal distribution.</p> <p>Parameters:</p> Name Type Description Default <code>mean</code> <code>float</code> <p>The mean of the Normal distribution.</p> <code>0.0</code> <code>std</code> <code>float</code> <p>The standard deviation of the Normal distribution.</p> <code>1.0</code> <code>min_value</code> <code>float</code> <p>The minimum value.</p> <code>-3.0</code> <code>max_value</code> <code>float</code> <p>The maximum value.</p> <code>3.0</code> <code>feature_size</code> <code>tuple[int, ...] | list[int] | int</code> <p>The feature size.</p> <code>1</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>if <code>std</code> is not a positive number.</p> <code>ValueError</code> <p>if <code>max_value</code> is lower than <code>min_value</code>.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.sequence import RandTruncNormal\n&gt;&gt;&gt; generator = RandTruncNormal(mean=0.0, std=1.0, min_value=-1.0, max_value=1.0)\n&gt;&gt;&gt; generator\nRandTruncNormalSequenceGenerator(mean=0.0, std=1.0, min_value=-1.0, max_value=1.0, feature_size=(1,))\n&gt;&gt;&gt; generator.generate(seq_len=6, batch_size=2)\ntensor([[...]])\n</code></pre>"},{"location":"refs/sequence/#startorch.sequence.RandTruncNormalSequenceGenerator","title":"startorch.sequence.RandTruncNormalSequenceGenerator","text":"<p>               Bases: <code>BaseSequenceGenerator</code></p> <p>Implement a sequence generator to generate cyclic sequences by sampling values from a truncated Normal distribution.</p> <p>Parameters:</p> Name Type Description Default <code>mean</code> <code>float</code> <p>The mean of the Normal distribution.</p> <code>0.0</code> <code>std</code> <code>float</code> <p>The standard deviation of the Normal distribution.</p> <code>1.0</code> <code>min_value</code> <code>float</code> <p>The minimum value.</p> <code>-3.0</code> <code>max_value</code> <code>float</code> <p>The maximum value.</p> <code>3.0</code> <code>feature_size</code> <code>tuple[int, ...] | list[int] | int</code> <p>The feature size.</p> <code>1</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>if <code>std</code> is not a positive number.</p> <code>ValueError</code> <p>if <code>max_value</code> is lower than <code>min_value</code>.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.sequence import RandTruncNormal\n&gt;&gt;&gt; generator = RandTruncNormal(mean=0.0, std=1.0, min_value=-1.0, max_value=1.0)\n&gt;&gt;&gt; generator\nRandTruncNormalSequenceGenerator(mean=0.0, std=1.0, min_value=-1.0, max_value=1.0, feature_size=(1,))\n&gt;&gt;&gt; generator.generate(seq_len=6, batch_size=2)\ntensor([[...]])\n</code></pre>"},{"location":"refs/sequence/#startorch.sequence.RandUniform","title":"startorch.sequence.RandUniform","text":"<p>               Bases: <code>BaseSequenceGenerator</code></p> <p>Implement a sequence generator to generate sequences by sampling values from a uniform distribution.</p> <p>Parameters:</p> Name Type Description Default <code>low</code> <code>float</code> <p>The minimum value (inclusive).</p> <code>0.0</code> <code>high</code> <code>float</code> <p>The maximum value (exclusive).</p> <code>1.0</code> <code>feature_size</code> <code>tuple[int, ...] | list[int] | int</code> <p>The feature size.</p> <code>1</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>if <code>high</code> is lower than <code>low</code>.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; from startorch.sequence import RandUniform\n&gt;&gt;&gt; generator = RandUniform()\n&gt;&gt;&gt; generator\nRandUniformSequenceGenerator(low=0.0, high=1.0, feature_size=(1,))\n&gt;&gt;&gt; generator.generate(seq_len=12, batch_size=4)\ntensor([[...]])\n</code></pre>"},{"location":"refs/sequence/#startorch.sequence.RandUniformSequenceGenerator","title":"startorch.sequence.RandUniformSequenceGenerator","text":"<p>               Bases: <code>BaseSequenceGenerator</code></p> <p>Implement a sequence generator to generate sequences by sampling values from a uniform distribution.</p> <p>Parameters:</p> Name Type Description Default <code>low</code> <code>float</code> <p>The minimum value (inclusive).</p> <code>0.0</code> <code>high</code> <code>float</code> <p>The maximum value (exclusive).</p> <code>1.0</code> <code>feature_size</code> <code>tuple[int, ...] | list[int] | int</code> <p>The feature size.</p> <code>1</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>if <code>high</code> is lower than <code>low</code>.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; from startorch.sequence import RandUniform\n&gt;&gt;&gt; generator = RandUniform()\n&gt;&gt;&gt; generator\nRandUniformSequenceGenerator(low=0.0, high=1.0, feature_size=(1,))\n&gt;&gt;&gt; generator.generate(seq_len=12, batch_size=4)\ntensor([[...]])\n</code></pre>"},{"location":"refs/sequence/#startorch.sequence.RandWienerProcess","title":"startorch.sequence.RandWienerProcess","text":"<p>               Bases: <code>BaseSequenceGenerator</code></p> <p>Implement a sequence generator to generate sequences where the values are generated by a Wiener process.</p> <p>Useful link: https://en.wikipedia.org/wiki/Wiener_process</p> <p>Parameters:</p> Name Type Description Default <code>step_size</code> <code>float</code> <p>The time step size.</p> <code>1.0</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>if <code>step_size</code> is not a positive number.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.sequence import RandWienerProcess\n&gt;&gt;&gt; generator = RandWienerProcess()\n&gt;&gt;&gt; generator\nRandWienerProcessSequenceGenerator(step_size=1.0)\n&gt;&gt;&gt; generator.generate(seq_len=6, batch_size=2)\ntensor([[...]])\n</code></pre>"},{"location":"refs/sequence/#startorch.sequence.RandWienerProcessSequenceGenerator","title":"startorch.sequence.RandWienerProcessSequenceGenerator","text":"<p>               Bases: <code>BaseSequenceGenerator</code></p> <p>Implement a sequence generator to generate sequences where the values are generated by a Wiener process.</p> <p>Useful link: https://en.wikipedia.org/wiki/Wiener_process</p> <p>Parameters:</p> Name Type Description Default <code>step_size</code> <code>float</code> <p>The time step size.</p> <code>1.0</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>if <code>step_size</code> is not a positive number.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.sequence import RandWienerProcess\n&gt;&gt;&gt; generator = RandWienerProcess()\n&gt;&gt;&gt; generator\nRandWienerProcessSequenceGenerator(step_size=1.0)\n&gt;&gt;&gt; generator.generate(seq_len=6, batch_size=2)\ntensor([[...]])\n</code></pre>"},{"location":"refs/sequence/#startorch.sequence.SineWave","title":"startorch.sequence.SineWave","text":"<p>               Bases: <code>BaseSequenceGenerator</code></p> <p>Implement a class to generate sequence by sampling values with a sine wave pattern.</p> <p>The sequences are generated by using the following formula:</p> <p><code>output = amplitude * sin(2 * pi * frequency * value + phase)</code></p> <p>Parameters:</p> Name Type Description Default <code>value</code> <code>BaseSequenceGenerator | dict</code> <p>A sequence generator (or its configuration) to generate the sequence values.</p> required <code>frequency</code> <code>BaseSequenceGenerator | dict</code> <p>A sequence generator (or its configuration) to generate the frequency values.</p> required <code>phase</code> <code>BaseSequenceGenerator | dict</code> <p>A sequence generator (or its configuration) to generate the phase values.</p> required <code>amplitude</code> <code>BaseSequenceGenerator | dict</code> <p>A sequence generator (or its configuration) to generate the amplitude values.</p> required <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; from startorch.sequence import Arange, SineWave, RandUniform, Constant, RandLogUniform\n&gt;&gt;&gt; generator = SineWave(\n...     value=Arange(),\n...     frequency=Constant(RandLogUniform(low=0.01, high=0.1)),\n...     phase=Constant(RandUniform(low=-1.0, high=1.0)),\n...     amplitude=Constant(RandLogUniform(low=0.1, high=1.0)),\n... )\n&gt;&gt;&gt; generator\nSineWaveSequenceGenerator(\n  (value): ArangeSequenceGenerator(feature_size=(1,))\n  (frequency): ConstantSequenceGenerator(\n      (sequence): RandLogUniformSequenceGenerator(low=0.01, high=0.1, feature_size=(1,))\n    )\n  (phase): ConstantSequenceGenerator(\n      (sequence): RandUniformSequenceGenerator(low=-1.0, high=1.0, feature_size=(1,))\n    )\n  (amplitude): ConstantSequenceGenerator(\n      (sequence): RandLogUniformSequenceGenerator(low=0.1, high=1.0, feature_size=(1,))\n    )\n)\n&gt;&gt;&gt; generator.generate(seq_len=12, batch_size=4)\ntensor([[...]])\n</code></pre>"},{"location":"refs/sequence/#startorch.sequence.SineWaveSequenceGenerator","title":"startorch.sequence.SineWaveSequenceGenerator","text":"<p>               Bases: <code>BaseSequenceGenerator</code></p> <p>Implement a class to generate sequence by sampling values with a sine wave pattern.</p> <p>The sequences are generated by using the following formula:</p> <p><code>output = amplitude * sin(2 * pi * frequency * value + phase)</code></p> <p>Parameters:</p> Name Type Description Default <code>value</code> <code>BaseSequenceGenerator | dict</code> <p>A sequence generator (or its configuration) to generate the sequence values.</p> required <code>frequency</code> <code>BaseSequenceGenerator | dict</code> <p>A sequence generator (or its configuration) to generate the frequency values.</p> required <code>phase</code> <code>BaseSequenceGenerator | dict</code> <p>A sequence generator (or its configuration) to generate the phase values.</p> required <code>amplitude</code> <code>BaseSequenceGenerator | dict</code> <p>A sequence generator (or its configuration) to generate the amplitude values.</p> required <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; from startorch.sequence import Arange, SineWave, RandUniform, Constant, RandLogUniform\n&gt;&gt;&gt; generator = SineWave(\n...     value=Arange(),\n...     frequency=Constant(RandLogUniform(low=0.01, high=0.1)),\n...     phase=Constant(RandUniform(low=-1.0, high=1.0)),\n...     amplitude=Constant(RandLogUniform(low=0.1, high=1.0)),\n... )\n&gt;&gt;&gt; generator\nSineWaveSequenceGenerator(\n  (value): ArangeSequenceGenerator(feature_size=(1,))\n  (frequency): ConstantSequenceGenerator(\n      (sequence): RandLogUniformSequenceGenerator(low=0.01, high=0.1, feature_size=(1,))\n    )\n  (phase): ConstantSequenceGenerator(\n      (sequence): RandUniformSequenceGenerator(low=-1.0, high=1.0, feature_size=(1,))\n    )\n  (amplitude): ConstantSequenceGenerator(\n      (sequence): RandLogUniformSequenceGenerator(low=0.1, high=1.0, feature_size=(1,))\n    )\n)\n&gt;&gt;&gt; generator.generate(seq_len=12, batch_size=4)\ntensor([[...]])\n</code></pre>"},{"location":"refs/sequence/#startorch.sequence.Sinh","title":"startorch.sequence.Sinh","text":"<p>               Bases: <code>BaseWrapperSequenceGenerator</code></p> <p>Implement a sequence generator that computes the hyperbolic sine (sinh) of each value.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; from startorch.sequence import Sinh, RandUniform\n&gt;&gt;&gt; generator = Sinh(RandUniform())\n&gt;&gt;&gt; generator\nSinhSequenceGenerator(\n  (sequence): RandUniformSequenceGenerator(low=0.0, high=1.0, feature_size=(1,))\n)\n&gt;&gt;&gt; generator.generate(seq_len=12, batch_size=4)\ntensor([[...]])\n</code></pre>"},{"location":"refs/sequence/#startorch.sequence.SinhSequenceGenerator","title":"startorch.sequence.SinhSequenceGenerator","text":"<p>               Bases: <code>BaseWrapperSequenceGenerator</code></p> <p>Implement a sequence generator that computes the hyperbolic sine (sinh) of each value.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; from startorch.sequence import Sinh, RandUniform\n&gt;&gt;&gt; generator = Sinh(RandUniform())\n&gt;&gt;&gt; generator\nSinhSequenceGenerator(\n  (sequence): RandUniformSequenceGenerator(low=0.0, high=1.0, feature_size=(1,))\n)\n&gt;&gt;&gt; generator.generate(seq_len=12, batch_size=4)\ntensor([[...]])\n</code></pre>"},{"location":"refs/sequence/#startorch.sequence.Sort","title":"startorch.sequence.Sort","text":"<p>               Bases: <code>BaseWrapperSequenceGenerator</code></p> <p>Implement a sequence generator that sorts a generated sequence.</p> <p>Parameters:</p> Name Type Description Default <code>generator</code> <code>BaseSequenceGenerator | dict</code> <p>The sequence generator or its configuration.</p> required <code>descending</code> <code>bool</code> <p>Control the sorting order. If <code>True</code>, the elements are sorted in descending order by value.</p> <code>False</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; from startorch.sequence import RandUniform, Sort\n&gt;&gt;&gt; generator = Sort(RandUniform())\n&gt;&gt;&gt; generator\nSortSequenceGenerator(\n  (sequence): RandUniformSequenceGenerator(low=0.0, high=1.0, feature_size=(1,))\n)\n&gt;&gt;&gt; generator.generate(seq_len=12, batch_size=4)\ntensor([[...]])\n</code></pre>"},{"location":"refs/sequence/#startorch.sequence.SortSequenceGenerator","title":"startorch.sequence.SortSequenceGenerator","text":"<p>               Bases: <code>BaseWrapperSequenceGenerator</code></p> <p>Implement a sequence generator that sorts a generated sequence.</p> <p>Parameters:</p> Name Type Description Default <code>generator</code> <code>BaseSequenceGenerator | dict</code> <p>The sequence generator or its configuration.</p> required <code>descending</code> <code>bool</code> <p>Control the sorting order. If <code>True</code>, the elements are sorted in descending order by value.</p> <code>False</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; from startorch.sequence import RandUniform, Sort\n&gt;&gt;&gt; generator = Sort(RandUniform())\n&gt;&gt;&gt; generator\nSortSequenceGenerator(\n  (sequence): RandUniformSequenceGenerator(low=0.0, high=1.0, feature_size=(1,))\n)\n&gt;&gt;&gt; generator.generate(seq_len=12, batch_size=4)\ntensor([[...]])\n</code></pre>"},{"location":"refs/sequence/#startorch.sequence.Sqrt","title":"startorch.sequence.Sqrt","text":"<p>               Bases: <code>BaseWrapperSequenceGenerator</code></p> <p>Implement a sequence generator that computes the squared root of a batch of sequences.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; from startorch.sequence import Sqrt, RandUniform, RandNormal\n&gt;&gt;&gt; generator = Sqrt(RandUniform(1.0, 4.0))\n&gt;&gt;&gt; generator\nSqrtSequenceGenerator(\n  (sequence): RandUniformSequenceGenerator(low=1.0, high=4.0, feature_size=(1,))\n)\n&gt;&gt;&gt; generator.generate(seq_len=12, batch_size=4)\ntensor([[...]])\n</code></pre>"},{"location":"refs/sequence/#startorch.sequence.SqrtSequenceGenerator","title":"startorch.sequence.SqrtSequenceGenerator","text":"<p>               Bases: <code>BaseWrapperSequenceGenerator</code></p> <p>Implement a sequence generator that computes the squared root of a batch of sequences.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; from startorch.sequence import Sqrt, RandUniform, RandNormal\n&gt;&gt;&gt; generator = Sqrt(RandUniform(1.0, 4.0))\n&gt;&gt;&gt; generator\nSqrtSequenceGenerator(\n  (sequence): RandUniformSequenceGenerator(low=1.0, high=4.0, feature_size=(1,))\n)\n&gt;&gt;&gt; generator.generate(seq_len=12, batch_size=4)\ntensor([[...]])\n</code></pre>"},{"location":"refs/sequence/#startorch.sequence.Sub","title":"startorch.sequence.Sub","text":"<p>               Bases: <code>BaseSequenceGenerator</code></p> <p>Implement a sequence generator that subtracts sequences.</p> <p><code>sequence = sequence_1 - sequence_2</code></p> <p>Parameters:</p> Name Type Description Default <code>sequence1</code> <code>BaseSequenceGenerator | dict</code> <p>The first sequence generator or its configuration.</p> required <code>sequence2</code> <code>BaseSequenceGenerator | dict</code> <p>The second sequence generator or its configuration.</p> required <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; from startorch.sequence import Sub, RandUniform, RandNormal\n&gt;&gt;&gt; generator = Sub(RandUniform(), RandNormal())\n&gt;&gt;&gt; generator\nSubSequenceGenerator(\n  (sequence1): RandUniformSequenceGenerator(low=0.0, high=1.0, feature_size=(1,))\n  (sequence2): RandNormalSequenceGenerator(mean=0.0, std=1.0, feature_size=(1,))\n)\n&gt;&gt;&gt; generator.generate(seq_len=12, batch_size=4)\ntensor([[...]])\n</code></pre>"},{"location":"refs/sequence/#startorch.sequence.SubSequenceGenerator","title":"startorch.sequence.SubSequenceGenerator","text":"<p>               Bases: <code>BaseSequenceGenerator</code></p> <p>Implement a sequence generator that subtracts sequences.</p> <p><code>sequence = sequence_1 - sequence_2</code></p> <p>Parameters:</p> Name Type Description Default <code>sequence1</code> <code>BaseSequenceGenerator | dict</code> <p>The first sequence generator or its configuration.</p> required <code>sequence2</code> <code>BaseSequenceGenerator | dict</code> <p>The second sequence generator or its configuration.</p> required <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; from startorch.sequence import Sub, RandUniform, RandNormal\n&gt;&gt;&gt; generator = Sub(RandUniform(), RandNormal())\n&gt;&gt;&gt; generator\nSubSequenceGenerator(\n  (sequence1): RandUniformSequenceGenerator(low=0.0, high=1.0, feature_size=(1,))\n  (sequence2): RandNormalSequenceGenerator(mean=0.0, std=1.0, feature_size=(1,))\n)\n&gt;&gt;&gt; generator.generate(seq_len=12, batch_size=4)\ntensor([[...]])\n</code></pre>"},{"location":"refs/sequence/#startorch.sequence.Tanh","title":"startorch.sequence.Tanh","text":"<p>               Bases: <code>BaseWrapperSequenceGenerator</code></p> <p>Implement a sequence generator that computes the hyperbolic tangent (tanh) of each value.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; from startorch.sequence import Tanh, RandUniform\n&gt;&gt;&gt; generator = Tanh(RandUniform())\n&gt;&gt;&gt; generator\nTanhSequenceGenerator(\n  (sequence): RandUniformSequenceGenerator(low=0.0, high=1.0, feature_size=(1,))\n)\n&gt;&gt;&gt; generator.generate(seq_len=12, batch_size=4)\ntensor([[...]])\n</code></pre>"},{"location":"refs/sequence/#startorch.sequence.TanhSequenceGenerator","title":"startorch.sequence.TanhSequenceGenerator","text":"<p>               Bases: <code>BaseWrapperSequenceGenerator</code></p> <p>Implement a sequence generator that computes the hyperbolic tangent (tanh) of each value.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; from startorch.sequence import Tanh, RandUniform\n&gt;&gt;&gt; generator = Tanh(RandUniform())\n&gt;&gt;&gt; generator\nTanhSequenceGenerator(\n  (sequence): RandUniformSequenceGenerator(low=0.0, high=1.0, feature_size=(1,))\n)\n&gt;&gt;&gt; generator.generate(seq_len=12, batch_size=4)\ntensor([[...]])\n</code></pre>"},{"location":"refs/sequence/#startorch.sequence.TensorSequence","title":"startorch.sequence.TensorSequence","text":"<p>               Bases: <code>BaseSequenceGenerator</code></p> <p>Implement a sequence generator to generate sequences from a tensor generator.</p> <p>Parameters:</p> Name Type Description Default <code>tensor</code> <code>BaseTensorGenerator | dict</code> <p>A tensor generator (or its configuration).</p> required <code>feature_size</code> <code>tuple[int, ...] | list[int] | int</code> <p>The feature size.</p> <code>()</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; from startorch.sequence import TensorSequence\n&gt;&gt;&gt; from startorch.tensor import RandUniform\n&gt;&gt;&gt; generator = TensorSequence(RandUniform())\n&gt;&gt;&gt; generator\nTensorSequenceGenerator(\n  (tensor): RandUniformTensorGenerator(low=0.0, high=1.0)\n  (feature_size): ()\n)\n&gt;&gt;&gt; generator.generate(seq_len=12, batch_size=4)\ntensor([[...]])\n</code></pre>"},{"location":"refs/sequence/#startorch.sequence.Time","title":"startorch.sequence.Time","text":"<p>               Bases: <code>BaseWrapperSequenceGenerator</code></p> <p>Implement a sequence generator to generate time sequences.</p> <p>The time is represented as a float value. The unit depends on the context. If the unit is the second:</p> <ul> <li><code>1.2</code> -&gt; <code>00:00:01.200</code></li> <li><code>61.2</code> -&gt; <code>00:01:01.200</code></li> <li><code>3661.2</code> -&gt; <code>01:01:01.200</code></li> </ul> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; from startorch.sequence import RandUniform, Time\n&gt;&gt;&gt; generator = Time(RandUniform())\n&gt;&gt;&gt; generator\nTimeSequenceGenerator(\n  (sequence): RandUniformSequenceGenerator(low=0.0, high=1.0, feature_size=(1,))\n)\n&gt;&gt;&gt; generator.generate(seq_len=12, batch_size=4)\ntensor([[...]])\n</code></pre>"},{"location":"refs/sequence/#startorch.sequence.Time.create_exponential_constant_time_diff","title":"startorch.sequence.Time.create_exponential_constant_time_diff  <code>classmethod</code>","text":"<pre><code>create_exponential_constant_time_diff(\n    rate: float = 1.0,\n) -&gt; TimeSequenceGenerator\n</code></pre> <p>Create a time sequence generator where the time difference between two consecutive steps is constant and is sampled from an exponential distribution.</p> <p>Parameters:</p> Name Type Description Default <code>rate</code> <code>float</code> <p>The rate of the exponential distribution.</p> <code>1.0</code> <p>Returns:</p> Type Description <code>TimeSequenceGenerator</code> <p>A time sequence generator where the time difference between two consecutive steps is constant and is sampled from an exponential distribution.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; from startorch.sequence import RandUniform, Time\n&gt;&gt;&gt; generator = Time.create_exponential_constant_time_diff()\n&gt;&gt;&gt; generator\nTimeSequenceGenerator(\n  (sequence): CumsumSequenceGenerator(\n      (sequence): ConstantSequenceGenerator(\n          (sequence): ExponentialSequenceGenerator(\n              (rate): ConstantSequenceGenerator(\n                  (sequence): RandUniformSequenceGenerator(low=1.0, high=1.0, feature_size=(1,))\n                )\n            )\n        )\n    )\n)\n&gt;&gt;&gt; generator.generate(seq_len=12, batch_size=4)\ntensor([[...]])\n</code></pre>"},{"location":"refs/sequence/#startorch.sequence.Time.create_exponential_time_diff","title":"startorch.sequence.Time.create_exponential_time_diff  <code>classmethod</code>","text":"<pre><code>create_exponential_time_diff(\n    rate: float = 1.0,\n) -&gt; TimeSequenceGenerator\n</code></pre> <p>Create a time sequence generator where the time difference between two consecutive steps follows an exponential distribution.</p> <p>Parameters:</p> Name Type Description Default <code>rate</code> <code>float</code> <p>The rate of the exponential distribution.</p> <code>1.0</code> <p>Returns:</p> Type Description <code>TimeSequenceGenerator</code> <p>A time sequence generator where the time difference between two consecutive steps follows an exponential distribution.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; from startorch.sequence import RandUniform, Time\n&gt;&gt;&gt; generator = Time.create_exponential_time_diff()\n&gt;&gt;&gt; generator\nTimeSequenceGenerator(\n  (sequence): CumsumSequenceGenerator(\n      (sequence): ExponentialSequenceGenerator(\n          (rate): ConstantSequenceGenerator(\n              (sequence): RandUniformSequenceGenerator(low=1.0, high=1.0, feature_size=(1,))\n            )\n        )\n    )\n)\n&gt;&gt;&gt; generator.generate(seq_len=12, batch_size=4)\ntensor([[...]])\n</code></pre>"},{"location":"refs/sequence/#startorch.sequence.Time.create_poisson_constant_time_diff","title":"startorch.sequence.Time.create_poisson_constant_time_diff  <code>classmethod</code>","text":"<pre><code>create_poisson_constant_time_diff(\n    rate: float = 1.0,\n) -&gt; TimeSequenceGenerator\n</code></pre> <p>Create a time sequence generator where the time difference between two consecutive steps is constant and is sampled from a Poisson distribution.</p> <p>Parameters:</p> Name Type Description Default <code>rate</code> <code>float</code> <p>The rate of the Poisson distribution.</p> <code>1.0</code> <p>Returns:</p> Type Description <code>TimeSequenceGenerator</code> <p>A time sequence generator where the time difference between two consecutive steps is constant and is sampled from a Poisson distribution.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; from startorch.sequence import RandUniform, Time\n&gt;&gt;&gt; generator = Time.create_poisson_constant_time_diff()\n&gt;&gt;&gt; generator\nTimeSequenceGenerator(\n  (sequence): CumsumSequenceGenerator(\n      (sequence): ConstantSequenceGenerator(\n          (sequence): RandPoissonSequenceGenerator(rate=1.0, feature_size=(1,))\n        )\n    )\n)\n&gt;&gt;&gt; generator.generate(seq_len=12, batch_size=4)\ntensor([[...]])\n</code></pre>"},{"location":"refs/sequence/#startorch.sequence.Time.create_poisson_time_diff","title":"startorch.sequence.Time.create_poisson_time_diff  <code>classmethod</code>","text":"<pre><code>create_poisson_time_diff(\n    rate: float = 1.0,\n) -&gt; TimeSequenceGenerator\n</code></pre> <p>Create a time sequence generator where the time difference between two consecutive steps follows a Poisson distribution.</p> <p>Parameters:</p> Name Type Description Default <code>rate</code> <code>float</code> <p>The rate of the Poisson distribution.</p> <code>1.0</code> <p>Returns:</p> Type Description <code>TimeSequenceGenerator</code> <p>A time sequence generator where the time difference between two consecutive steps follows a Poisson distribution.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; from startorch.sequence import RandUniform, Time\n&gt;&gt;&gt; generator = Time.create_poisson_time_diff()\n&gt;&gt;&gt; generator\nTimeSequenceGenerator(\n  (sequence): CumsumSequenceGenerator(\n      (sequence): RandPoissonSequenceGenerator(rate=1.0, feature_size=(1,))\n    )\n)\n&gt;&gt;&gt; generator.generate(seq_len=12, batch_size=4)\ntensor([[...]])\n</code></pre>"},{"location":"refs/sequence/#startorch.sequence.Time.create_uniform_constant_time_diff","title":"startorch.sequence.Time.create_uniform_constant_time_diff  <code>classmethod</code>","text":"<pre><code>create_uniform_constant_time_diff(\n    min_time_diff: float = 0.0, max_time_diff: float = 1.0\n) -&gt; TimeSequenceGenerator\n</code></pre> <p>Create a time sequence generator where the time difference between two consecutive steps is constant and is sampled from a uniform distribution.</p> <p>Parameters:</p> Name Type Description Default <code>min_time_diff</code> <code>float</code> <p>The minimum time difference between two consecutive steps.</p> <code>0.0</code> <code>max_time_diff</code> <code>float</code> <p>The maximum time difference between two consecutive steps.</p> <code>1.0</code> <p>Returns:</p> Type Description <code>TimeSequenceGenerator</code> <p>A time sequence generator where the time difference between two consecutive steps is constant and is sampled from a uniform distribution.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>if <code>min_time_diff</code> is lower than 0.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; from startorch.sequence import RandUniform, Time\n&gt;&gt;&gt; generator = Time.create_uniform_constant_time_diff()\n&gt;&gt;&gt; generator\nTimeSequenceGenerator(\n  (sequence): CumsumSequenceGenerator(\n      (sequence): ConstantSequenceGenerator(\n          (sequence): RandUniformSequenceGenerator(low=0.0, high=1.0, feature_size=(1,))\n        )\n    )\n)\n&gt;&gt;&gt; generator.generate(seq_len=12, batch_size=4)\ntensor([[...]])\n</code></pre>"},{"location":"refs/sequence/#startorch.sequence.Time.create_uniform_time","title":"startorch.sequence.Time.create_uniform_time  <code>classmethod</code>","text":"<pre><code>create_uniform_time(\n    min_time: float = 0.0, max_time: float = 1.0\n) -&gt; TimeSequenceGenerator\n</code></pre> <p>Create a time sequence generator where the time is sampled from a uniform distribution.</p> <p>Parameters:</p> Name Type Description Default <code>min_time</code> <code>float</code> <p>The minimum time.</p> <code>0.0</code> <code>max_time</code> <code>float</code> <p>The maximum time.</p> <code>1.0</code> <p>Returns:</p> Type Description <code>TimeSequenceGenerator</code> <p>A time sequence generator where the time is sampled from a uniform distribution.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>if <code>min_time</code> is lower than 0.</p> <p>Example usage:</p> <p>```pycon</p> <pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; from startorch.sequence import RandUniform, Time\n&gt;&gt;&gt; generator = Time.create_uniform_time()\n&gt;&gt;&gt; generator\nTimeSequenceGenerator(\n  (sequence): SortSequenceGenerator(\n      (sequence): RandUniformSequenceGenerator(low=0.0, high=1.0, feature_size=(1,))\n    )\n)\n&gt;&gt;&gt; generator.generate(seq_len=12, batch_size=4)\ntensor([[...]])\n</code></pre>"},{"location":"refs/sequence/#startorch.sequence.Time.create_uniform_time_diff","title":"startorch.sequence.Time.create_uniform_time_diff  <code>classmethod</code>","text":"<pre><code>create_uniform_time_diff(\n    min_time_diff: float = 0.0, max_time_diff: float = 1.0\n) -&gt; TimeSequenceGenerator\n</code></pre> <p>Create a time sequence generator where the time difference between two consecutive steps follows a uniform distribution.</p> <p>Parameters:</p> Name Type Description Default <code>min_time_diff</code> <code>float</code> <p>The minimum time difference between two consecutive steps.</p> <code>0.0</code> <code>max_time_diff</code> <code>float</code> <p>The maximum time difference between two consecutive steps.</p> <code>1.0</code> <p>Returns:</p> Type Description <code>TimeSequenceGenerator</code> <p>A time sequence generator where the time difference between two consecutive steps follows a uniform distribution.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>if <code>min_time_diff</code> is lower than 0.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; from startorch.sequence import RandUniform, Time\n&gt;&gt;&gt; generator = Time.create_uniform_time_diff()\n&gt;&gt;&gt; generator\nTimeSequenceGenerator(\n  (sequence): CumsumSequenceGenerator(\n      (sequence): RandUniformSequenceGenerator(low=0.0, high=1.0, feature_size=(1,))\n    )\n)\n&gt;&gt;&gt; generator.generate(seq_len=12, batch_size=4)\ntensor([[...]])\n</code></pre>"},{"location":"refs/sequence/#startorch.sequence.TimeSequenceGenerator","title":"startorch.sequence.TimeSequenceGenerator","text":"<p>               Bases: <code>BaseWrapperSequenceGenerator</code></p> <p>Implement a sequence generator to generate time sequences.</p> <p>The time is represented as a float value. The unit depends on the context. If the unit is the second:</p> <ul> <li><code>1.2</code> -&gt; <code>00:00:01.200</code></li> <li><code>61.2</code> -&gt; <code>00:01:01.200</code></li> <li><code>3661.2</code> -&gt; <code>01:01:01.200</code></li> </ul> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; from startorch.sequence import RandUniform, Time\n&gt;&gt;&gt; generator = Time(RandUniform())\n&gt;&gt;&gt; generator\nTimeSequenceGenerator(\n  (sequence): RandUniformSequenceGenerator(low=0.0, high=1.0, feature_size=(1,))\n)\n&gt;&gt;&gt; generator.generate(seq_len=12, batch_size=4)\ntensor([[...]])\n</code></pre>"},{"location":"refs/sequence/#startorch.sequence.TimeSequenceGenerator.create_exponential_constant_time_diff","title":"startorch.sequence.TimeSequenceGenerator.create_exponential_constant_time_diff  <code>classmethod</code>","text":"<pre><code>create_exponential_constant_time_diff(\n    rate: float = 1.0,\n) -&gt; TimeSequenceGenerator\n</code></pre> <p>Create a time sequence generator where the time difference between two consecutive steps is constant and is sampled from an exponential distribution.</p> <p>Parameters:</p> Name Type Description Default <code>rate</code> <code>float</code> <p>The rate of the exponential distribution.</p> <code>1.0</code> <p>Returns:</p> Type Description <code>TimeSequenceGenerator</code> <p>A time sequence generator where the time difference between two consecutive steps is constant and is sampled from an exponential distribution.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; from startorch.sequence import RandUniform, Time\n&gt;&gt;&gt; generator = Time.create_exponential_constant_time_diff()\n&gt;&gt;&gt; generator\nTimeSequenceGenerator(\n  (sequence): CumsumSequenceGenerator(\n      (sequence): ConstantSequenceGenerator(\n          (sequence): ExponentialSequenceGenerator(\n              (rate): ConstantSequenceGenerator(\n                  (sequence): RandUniformSequenceGenerator(low=1.0, high=1.0, feature_size=(1,))\n                )\n            )\n        )\n    )\n)\n&gt;&gt;&gt; generator.generate(seq_len=12, batch_size=4)\ntensor([[...]])\n</code></pre>"},{"location":"refs/sequence/#startorch.sequence.TimeSequenceGenerator.create_exponential_time_diff","title":"startorch.sequence.TimeSequenceGenerator.create_exponential_time_diff  <code>classmethod</code>","text":"<pre><code>create_exponential_time_diff(\n    rate: float = 1.0,\n) -&gt; TimeSequenceGenerator\n</code></pre> <p>Create a time sequence generator where the time difference between two consecutive steps follows an exponential distribution.</p> <p>Parameters:</p> Name Type Description Default <code>rate</code> <code>float</code> <p>The rate of the exponential distribution.</p> <code>1.0</code> <p>Returns:</p> Type Description <code>TimeSequenceGenerator</code> <p>A time sequence generator where the time difference between two consecutive steps follows an exponential distribution.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; from startorch.sequence import RandUniform, Time\n&gt;&gt;&gt; generator = Time.create_exponential_time_diff()\n&gt;&gt;&gt; generator\nTimeSequenceGenerator(\n  (sequence): CumsumSequenceGenerator(\n      (sequence): ExponentialSequenceGenerator(\n          (rate): ConstantSequenceGenerator(\n              (sequence): RandUniformSequenceGenerator(low=1.0, high=1.0, feature_size=(1,))\n            )\n        )\n    )\n)\n&gt;&gt;&gt; generator.generate(seq_len=12, batch_size=4)\ntensor([[...]])\n</code></pre>"},{"location":"refs/sequence/#startorch.sequence.TimeSequenceGenerator.create_poisson_constant_time_diff","title":"startorch.sequence.TimeSequenceGenerator.create_poisson_constant_time_diff  <code>classmethod</code>","text":"<pre><code>create_poisson_constant_time_diff(\n    rate: float = 1.0,\n) -&gt; TimeSequenceGenerator\n</code></pre> <p>Create a time sequence generator where the time difference between two consecutive steps is constant and is sampled from a Poisson distribution.</p> <p>Parameters:</p> Name Type Description Default <code>rate</code> <code>float</code> <p>The rate of the Poisson distribution.</p> <code>1.0</code> <p>Returns:</p> Type Description <code>TimeSequenceGenerator</code> <p>A time sequence generator where the time difference between two consecutive steps is constant and is sampled from a Poisson distribution.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; from startorch.sequence import RandUniform, Time\n&gt;&gt;&gt; generator = Time.create_poisson_constant_time_diff()\n&gt;&gt;&gt; generator\nTimeSequenceGenerator(\n  (sequence): CumsumSequenceGenerator(\n      (sequence): ConstantSequenceGenerator(\n          (sequence): RandPoissonSequenceGenerator(rate=1.0, feature_size=(1,))\n        )\n    )\n)\n&gt;&gt;&gt; generator.generate(seq_len=12, batch_size=4)\ntensor([[...]])\n</code></pre>"},{"location":"refs/sequence/#startorch.sequence.TimeSequenceGenerator.create_poisson_time_diff","title":"startorch.sequence.TimeSequenceGenerator.create_poisson_time_diff  <code>classmethod</code>","text":"<pre><code>create_poisson_time_diff(\n    rate: float = 1.0,\n) -&gt; TimeSequenceGenerator\n</code></pre> <p>Create a time sequence generator where the time difference between two consecutive steps follows a Poisson distribution.</p> <p>Parameters:</p> Name Type Description Default <code>rate</code> <code>float</code> <p>The rate of the Poisson distribution.</p> <code>1.0</code> <p>Returns:</p> Type Description <code>TimeSequenceGenerator</code> <p>A time sequence generator where the time difference between two consecutive steps follows a Poisson distribution.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; from startorch.sequence import RandUniform, Time\n&gt;&gt;&gt; generator = Time.create_poisson_time_diff()\n&gt;&gt;&gt; generator\nTimeSequenceGenerator(\n  (sequence): CumsumSequenceGenerator(\n      (sequence): RandPoissonSequenceGenerator(rate=1.0, feature_size=(1,))\n    )\n)\n&gt;&gt;&gt; generator.generate(seq_len=12, batch_size=4)\ntensor([[...]])\n</code></pre>"},{"location":"refs/sequence/#startorch.sequence.TimeSequenceGenerator.create_uniform_constant_time_diff","title":"startorch.sequence.TimeSequenceGenerator.create_uniform_constant_time_diff  <code>classmethod</code>","text":"<pre><code>create_uniform_constant_time_diff(\n    min_time_diff: float = 0.0, max_time_diff: float = 1.0\n) -&gt; TimeSequenceGenerator\n</code></pre> <p>Create a time sequence generator where the time difference between two consecutive steps is constant and is sampled from a uniform distribution.</p> <p>Parameters:</p> Name Type Description Default <code>min_time_diff</code> <code>float</code> <p>The minimum time difference between two consecutive steps.</p> <code>0.0</code> <code>max_time_diff</code> <code>float</code> <p>The maximum time difference between two consecutive steps.</p> <code>1.0</code> <p>Returns:</p> Type Description <code>TimeSequenceGenerator</code> <p>A time sequence generator where the time difference between two consecutive steps is constant and is sampled from a uniform distribution.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>if <code>min_time_diff</code> is lower than 0.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; from startorch.sequence import RandUniform, Time\n&gt;&gt;&gt; generator = Time.create_uniform_constant_time_diff()\n&gt;&gt;&gt; generator\nTimeSequenceGenerator(\n  (sequence): CumsumSequenceGenerator(\n      (sequence): ConstantSequenceGenerator(\n          (sequence): RandUniformSequenceGenerator(low=0.0, high=1.0, feature_size=(1,))\n        )\n    )\n)\n&gt;&gt;&gt; generator.generate(seq_len=12, batch_size=4)\ntensor([[...]])\n</code></pre>"},{"location":"refs/sequence/#startorch.sequence.TimeSequenceGenerator.create_uniform_time","title":"startorch.sequence.TimeSequenceGenerator.create_uniform_time  <code>classmethod</code>","text":"<pre><code>create_uniform_time(\n    min_time: float = 0.0, max_time: float = 1.0\n) -&gt; TimeSequenceGenerator\n</code></pre> <p>Create a time sequence generator where the time is sampled from a uniform distribution.</p> <p>Parameters:</p> Name Type Description Default <code>min_time</code> <code>float</code> <p>The minimum time.</p> <code>0.0</code> <code>max_time</code> <code>float</code> <p>The maximum time.</p> <code>1.0</code> <p>Returns:</p> Type Description <code>TimeSequenceGenerator</code> <p>A time sequence generator where the time is sampled from a uniform distribution.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>if <code>min_time</code> is lower than 0.</p> <p>Example usage:</p> <p>```pycon</p> <pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; from startorch.sequence import RandUniform, Time\n&gt;&gt;&gt; generator = Time.create_uniform_time()\n&gt;&gt;&gt; generator\nTimeSequenceGenerator(\n  (sequence): SortSequenceGenerator(\n      (sequence): RandUniformSequenceGenerator(low=0.0, high=1.0, feature_size=(1,))\n    )\n)\n&gt;&gt;&gt; generator.generate(seq_len=12, batch_size=4)\ntensor([[...]])\n</code></pre>"},{"location":"refs/sequence/#startorch.sequence.TimeSequenceGenerator.create_uniform_time_diff","title":"startorch.sequence.TimeSequenceGenerator.create_uniform_time_diff  <code>classmethod</code>","text":"<pre><code>create_uniform_time_diff(\n    min_time_diff: float = 0.0, max_time_diff: float = 1.0\n) -&gt; TimeSequenceGenerator\n</code></pre> <p>Create a time sequence generator where the time difference between two consecutive steps follows a uniform distribution.</p> <p>Parameters:</p> Name Type Description Default <code>min_time_diff</code> <code>float</code> <p>The minimum time difference between two consecutive steps.</p> <code>0.0</code> <code>max_time_diff</code> <code>float</code> <p>The maximum time difference between two consecutive steps.</p> <code>1.0</code> <p>Returns:</p> Type Description <code>TimeSequenceGenerator</code> <p>A time sequence generator where the time difference between two consecutive steps follows a uniform distribution.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>if <code>min_time_diff</code> is lower than 0.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; from startorch.sequence import RandUniform, Time\n&gt;&gt;&gt; generator = Time.create_uniform_time_diff()\n&gt;&gt;&gt; generator\nTimeSequenceGenerator(\n  (sequence): CumsumSequenceGenerator(\n      (sequence): RandUniformSequenceGenerator(low=0.0, high=1.0, feature_size=(1,))\n    )\n)\n&gt;&gt;&gt; generator.generate(seq_len=12, batch_size=4)\ntensor([[...]])\n</code></pre>"},{"location":"refs/sequence/#startorch.sequence.TruncCauchy","title":"startorch.sequence.TruncCauchy","text":"<p>               Bases: <code>BaseSequenceGenerator</code></p> <p>Implement a class to generate sequence by sampling values from a Cauchy distribution.</p> <p>Parameters:</p> Name Type Description Default <code>loc</code> <code>BaseSequenceGenerator | dict</code> <p>A sequence generator (or its configuration) to generate the location.</p> required <code>scale</code> <code>BaseSequenceGenerator | dict</code> <p>A sequence generator (or its configuration) to generate the scale.</p> required <code>min_value</code> <code>BaseSequenceGenerator | dict</code> <p>A sequence generator (or its configuration) to generate the minimum value (included).</p> required <code>max_value</code> <code>BaseSequenceGenerator | dict</code> <p>A sequence generator (or its configuration) to generate the  maximum value (excluded).</p> required <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.sequence import RandUniform, TruncCauchy\n&gt;&gt;&gt; generator = TruncCauchy(\n...     loc=RandUniform(low=-1.0, high=1.0),\n...     scale=RandUniform(low=1.0, high=2.0),\n...     min_value=RandUniform(low=-10.0, high=-5.0),\n...     max_value=RandUniform(low=5.0, high=10.0),\n... )\n&gt;&gt;&gt; generator\nTruncCauchySequenceGenerator(\n  (loc): RandUniformSequenceGenerator(low=-1.0, high=1.0, feature_size=(1,))\n  (scale): RandUniformSequenceGenerator(low=1.0, high=2.0, feature_size=(1,))\n  (min_value): RandUniformSequenceGenerator(low=-10.0, high=-5.0, feature_size=(1,))\n  (max_value): RandUniformSequenceGenerator(low=5.0, high=10.0, feature_size=(1,))\n)\n&gt;&gt;&gt; generator.generate(seq_len=6, batch_size=2)\ntensor([[...]])\n</code></pre>"},{"location":"refs/sequence/#startorch.sequence.TruncCauchySequenceGenerator","title":"startorch.sequence.TruncCauchySequenceGenerator","text":"<p>               Bases: <code>BaseSequenceGenerator</code></p> <p>Implement a class to generate sequence by sampling values from a Cauchy distribution.</p> <p>Parameters:</p> Name Type Description Default <code>loc</code> <code>BaseSequenceGenerator | dict</code> <p>A sequence generator (or its configuration) to generate the location.</p> required <code>scale</code> <code>BaseSequenceGenerator | dict</code> <p>A sequence generator (or its configuration) to generate the scale.</p> required <code>min_value</code> <code>BaseSequenceGenerator | dict</code> <p>A sequence generator (or its configuration) to generate the minimum value (included).</p> required <code>max_value</code> <code>BaseSequenceGenerator | dict</code> <p>A sequence generator (or its configuration) to generate the  maximum value (excluded).</p> required <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.sequence import RandUniform, TruncCauchy\n&gt;&gt;&gt; generator = TruncCauchy(\n...     loc=RandUniform(low=-1.0, high=1.0),\n...     scale=RandUniform(low=1.0, high=2.0),\n...     min_value=RandUniform(low=-10.0, high=-5.0),\n...     max_value=RandUniform(low=5.0, high=10.0),\n... )\n&gt;&gt;&gt; generator\nTruncCauchySequenceGenerator(\n  (loc): RandUniformSequenceGenerator(low=-1.0, high=1.0, feature_size=(1,))\n  (scale): RandUniformSequenceGenerator(low=1.0, high=2.0, feature_size=(1,))\n  (min_value): RandUniformSequenceGenerator(low=-10.0, high=-5.0, feature_size=(1,))\n  (max_value): RandUniformSequenceGenerator(low=5.0, high=10.0, feature_size=(1,))\n)\n&gt;&gt;&gt; generator.generate(seq_len=6, batch_size=2)\ntensor([[...]])\n</code></pre>"},{"location":"refs/sequence/#startorch.sequence.TruncExponential","title":"startorch.sequence.TruncExponential","text":"<p>               Bases: <code>BaseSequenceGenerator</code></p> <p>Implement a class to generate sequence by sampling values from an Exponential distribution.</p> <p>Parameters:</p> Name Type Description Default <code>rate</code> <code>BaseSequenceGenerator | dict</code> <p>A sequence generator (or its configuration) to generate the rate.</p> required <code>max_value</code> <code>BaseSequenceGenerator | dict</code> <p>A sequence generator (or its configuration) to generate the maximum value (excluded).</p> required <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.sequence import RandUniform, TruncExponential\n&gt;&gt;&gt; generator = TruncExponential(\n...     rate=RandUniform(low=1.0, high=10.0),\n...     max_value=RandUniform(low=1.0, high=100.0),\n... )\n&gt;&gt;&gt; generator\nTruncExponentialSequenceGenerator(\n  (rate): RandUniformSequenceGenerator(low=1.0, high=10.0, feature_size=(1,))\n  (max_value): RandUniformSequenceGenerator(low=1.0, high=100.0, feature_size=(1,))\n)\n&gt;&gt;&gt; generator.generate(seq_len=6, batch_size=2)\ntensor([[...]])\n</code></pre>"},{"location":"refs/sequence/#startorch.sequence.TruncExponentialSequenceGenerator","title":"startorch.sequence.TruncExponentialSequenceGenerator","text":"<p>               Bases: <code>BaseSequenceGenerator</code></p> <p>Implement a class to generate sequence by sampling values from an Exponential distribution.</p> <p>Parameters:</p> Name Type Description Default <code>rate</code> <code>BaseSequenceGenerator | dict</code> <p>A sequence generator (or its configuration) to generate the rate.</p> required <code>max_value</code> <code>BaseSequenceGenerator | dict</code> <p>A sequence generator (or its configuration) to generate the maximum value (excluded).</p> required <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.sequence import RandUniform, TruncExponential\n&gt;&gt;&gt; generator = TruncExponential(\n...     rate=RandUniform(low=1.0, high=10.0),\n...     max_value=RandUniform(low=1.0, high=100.0),\n... )\n&gt;&gt;&gt; generator\nTruncExponentialSequenceGenerator(\n  (rate): RandUniformSequenceGenerator(low=1.0, high=10.0, feature_size=(1,))\n  (max_value): RandUniformSequenceGenerator(low=1.0, high=100.0, feature_size=(1,))\n)\n&gt;&gt;&gt; generator.generate(seq_len=6, batch_size=2)\ntensor([[...]])\n</code></pre>"},{"location":"refs/sequence/#startorch.sequence.TruncHalfCauchy","title":"startorch.sequence.TruncHalfCauchy","text":"<p>               Bases: <code>BaseSequenceGenerator</code></p> <p>Implement a class to generate sequence by sampling values from a half-Cauchy distribution.</p> <p>Parameters:</p> Name Type Description Default <code>scale</code> <code>BaseSequenceGenerator | dict</code> <p>A sequence generator (or its configuration) to generate the scale.</p> required <code>max_value</code> <code>BaseSequenceGenerator | dict</code> <p>A sequence generator (or its configuration) to generate the maximum value (excluded).</p> required <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.sequence import RandUniform, TruncHalfCauchy\n&gt;&gt;&gt; generator = TruncHalfCauchy(\n...     scale=RandUniform(low=1.0, high=2.0),\n...     max_value=RandUniform(low=5.0, high=10.0),\n... )\n&gt;&gt;&gt; generator\nTruncHalfCauchySequenceGenerator(\n  (scale): RandUniformSequenceGenerator(low=1.0, high=2.0, feature_size=(1,))\n  (max_value): RandUniformSequenceGenerator(low=5.0, high=10.0, feature_size=(1,))\n)\n&gt;&gt;&gt; generator.generate(seq_len=6, batch_size=2)\ntensor([[...]])\n</code></pre>"},{"location":"refs/sequence/#startorch.sequence.TruncHalfCauchySequenceGenerator","title":"startorch.sequence.TruncHalfCauchySequenceGenerator","text":"<p>               Bases: <code>BaseSequenceGenerator</code></p> <p>Implement a class to generate sequence by sampling values from a half-Cauchy distribution.</p> <p>Parameters:</p> Name Type Description Default <code>scale</code> <code>BaseSequenceGenerator | dict</code> <p>A sequence generator (or its configuration) to generate the scale.</p> required <code>max_value</code> <code>BaseSequenceGenerator | dict</code> <p>A sequence generator (or its configuration) to generate the maximum value (excluded).</p> required <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.sequence import RandUniform, TruncHalfCauchy\n&gt;&gt;&gt; generator = TruncHalfCauchy(\n...     scale=RandUniform(low=1.0, high=2.0),\n...     max_value=RandUniform(low=5.0, high=10.0),\n... )\n&gt;&gt;&gt; generator\nTruncHalfCauchySequenceGenerator(\n  (scale): RandUniformSequenceGenerator(low=1.0, high=2.0, feature_size=(1,))\n  (max_value): RandUniformSequenceGenerator(low=5.0, high=10.0, feature_size=(1,))\n)\n&gt;&gt;&gt; generator.generate(seq_len=6, batch_size=2)\ntensor([[...]])\n</code></pre>"},{"location":"refs/sequence/#startorch.sequence.TruncHalfNormal","title":"startorch.sequence.TruncHalfNormal","text":"<p>               Bases: <code>BaseSequenceGenerator</code></p> <p>Implement a class to generate sequence by sampling values from a half-Normal distribution.</p> <p>Parameters:</p> Name Type Description Default <code>std</code> <code>BaseSequenceGenerator | dict</code> <p>A sequence generator (or its configuration) to generate the std.</p> required <code>max_value</code> <code>BaseSequenceGenerator | dict</code> <p>A sequence generator (or its configuration) to generate the maximum value (excluded).</p> required <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.sequence import RandUniform, TruncHalfNormal\n&gt;&gt;&gt; generator = TruncHalfNormal(\n...     std=RandUniform(low=1.0, high=2.0),\n...     max_value=RandUniform(low=5.0, high=10.0),\n... )\n&gt;&gt;&gt; generator\nTruncHalfNormalSequenceGenerator(\n  (std): RandUniformSequenceGenerator(low=1.0, high=2.0, feature_size=(1,))\n  (max_value): RandUniformSequenceGenerator(low=5.0, high=10.0, feature_size=(1,))\n)\n&gt;&gt;&gt; generator.generate(seq_len=6, batch_size=2)\ntensor([[...]])\n</code></pre>"},{"location":"refs/sequence/#startorch.sequence.TruncHalfNormalSequenceGenerator","title":"startorch.sequence.TruncHalfNormalSequenceGenerator","text":"<p>               Bases: <code>BaseSequenceGenerator</code></p> <p>Implement a class to generate sequence by sampling values from a half-Normal distribution.</p> <p>Parameters:</p> Name Type Description Default <code>std</code> <code>BaseSequenceGenerator | dict</code> <p>A sequence generator (or its configuration) to generate the std.</p> required <code>max_value</code> <code>BaseSequenceGenerator | dict</code> <p>A sequence generator (or its configuration) to generate the maximum value (excluded).</p> required <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.sequence import RandUniform, TruncHalfNormal\n&gt;&gt;&gt; generator = TruncHalfNormal(\n...     std=RandUniform(low=1.0, high=2.0),\n...     max_value=RandUniform(low=5.0, high=10.0),\n... )\n&gt;&gt;&gt; generator\nTruncHalfNormalSequenceGenerator(\n  (std): RandUniformSequenceGenerator(low=1.0, high=2.0, feature_size=(1,))\n  (max_value): RandUniformSequenceGenerator(low=5.0, high=10.0, feature_size=(1,))\n)\n&gt;&gt;&gt; generator.generate(seq_len=6, batch_size=2)\ntensor([[...]])\n</code></pre>"},{"location":"refs/sequence/#startorch.sequence.TruncLogNormal","title":"startorch.sequence.TruncLogNormal","text":"<p>               Bases: <code>BaseSequenceGenerator</code></p> <p>Implement a class to generate sequence by sampling values from a truncated log-Normal distribution.</p> <p>Parameters:</p> Name Type Description Default <code>mean</code> <code>BaseSequenceGenerator | dict</code> <p>A sequence generator (or its configuration) to generate the mean of the underlying Normal distribution.</p> required <code>std</code> <code>BaseSequenceGenerator | dict</code> <p>A sequence generator (or its configuration) to generate the standard deviation of the underlying Normal distribution.</p> required <code>min_value</code> <code>BaseSequenceGenerator | dict</code> <p>A sequence generator (or its configuration) to generate the minimum value (included).</p> required <code>max_value</code> <code>BaseSequenceGenerator | dict</code> <p>A sequence generator (or its configuration) to generate the maximum value (excluded).</p> required <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.sequence import RandUniform, TruncLogNormal\n&gt;&gt;&gt; generator = TruncLogNormal(\n...     mean=RandUniform(low=-1.0, high=1.0),\n...     std=RandUniform(low=1.0, high=2.0),\n...     min_value=RandUniform(low=0.0, high=2.0),\n...     max_value=RandUniform(low=5.0, high=10.0),\n... )\n&gt;&gt;&gt; generator\nTruncLogNormalSequenceGenerator(\n  (mean): RandUniformSequenceGenerator(low=-1.0, high=1.0, feature_size=(1,))\n  (std): RandUniformSequenceGenerator(low=1.0, high=2.0, feature_size=(1,))\n  (min_value): RandUniformSequenceGenerator(low=0.0, high=2.0, feature_size=(1,))\n  (max_value): RandUniformSequenceGenerator(low=5.0, high=10.0, feature_size=(1,))\n)\n&gt;&gt;&gt; generator.generate(seq_len=6, batch_size=2)\ntensor([[...]])\n</code></pre>"},{"location":"refs/sequence/#startorch.sequence.TruncLogNormalSequenceGenerator","title":"startorch.sequence.TruncLogNormalSequenceGenerator","text":"<p>               Bases: <code>BaseSequenceGenerator</code></p> <p>Implement a class to generate sequence by sampling values from a truncated log-Normal distribution.</p> <p>Parameters:</p> Name Type Description Default <code>mean</code> <code>BaseSequenceGenerator | dict</code> <p>A sequence generator (or its configuration) to generate the mean of the underlying Normal distribution.</p> required <code>std</code> <code>BaseSequenceGenerator | dict</code> <p>A sequence generator (or its configuration) to generate the standard deviation of the underlying Normal distribution.</p> required <code>min_value</code> <code>BaseSequenceGenerator | dict</code> <p>A sequence generator (or its configuration) to generate the minimum value (included).</p> required <code>max_value</code> <code>BaseSequenceGenerator | dict</code> <p>A sequence generator (or its configuration) to generate the maximum value (excluded).</p> required <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.sequence import RandUniform, TruncLogNormal\n&gt;&gt;&gt; generator = TruncLogNormal(\n...     mean=RandUniform(low=-1.0, high=1.0),\n...     std=RandUniform(low=1.0, high=2.0),\n...     min_value=RandUniform(low=0.0, high=2.0),\n...     max_value=RandUniform(low=5.0, high=10.0),\n... )\n&gt;&gt;&gt; generator\nTruncLogNormalSequenceGenerator(\n  (mean): RandUniformSequenceGenerator(low=-1.0, high=1.0, feature_size=(1,))\n  (std): RandUniformSequenceGenerator(low=1.0, high=2.0, feature_size=(1,))\n  (min_value): RandUniformSequenceGenerator(low=0.0, high=2.0, feature_size=(1,))\n  (max_value): RandUniformSequenceGenerator(low=5.0, high=10.0, feature_size=(1,))\n)\n&gt;&gt;&gt; generator.generate(seq_len=6, batch_size=2)\ntensor([[...]])\n</code></pre>"},{"location":"refs/sequence/#startorch.sequence.TruncNormal","title":"startorch.sequence.TruncNormal","text":"<p>               Bases: <code>BaseSequenceGenerator</code></p> <p>Implement a class to generate sequence by sampling values from a truncated Normal distribution.</p> <p>Parameters:</p> Name Type Description Default <code>mean</code> <code>BaseSequenceGenerator | dict</code> <p>A sequence generator (or its configuration) to generate the mean.</p> required <code>std</code> <code>BaseSequenceGenerator | dict</code> <p>A sequence generator (or its configuration) to generate the standard deviation.</p> required <code>min_value</code> <code>BaseSequenceGenerator | dict</code> <p>A sequence generator (or its configuration) to generate the minimum value (included).</p> required <code>max_value</code> <code>BaseSequenceGenerator | dict</code> <p>A sequence generator (or its configuration) to generate the maximum value (excluded).</p> required <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.sequence import RandUniform, TruncNormal\n&gt;&gt;&gt; generator = TruncNormal(\n...     mean=RandUniform(low=-1.0, high=1.0),\n...     std=RandUniform(low=1.0, high=2.0),\n...     min_value=RandUniform(low=-10.0, high=-5.0),\n...     max_value=RandUniform(low=5.0, high=10.0),\n... )\n&gt;&gt;&gt; generator\nTruncNormalSequenceGenerator(\n  (mean): RandUniformSequenceGenerator(low=-1.0, high=1.0, feature_size=(1,))\n  (std): RandUniformSequenceGenerator(low=1.0, high=2.0, feature_size=(1,))\n  (min_value): RandUniformSequenceGenerator(low=-10.0, high=-5.0, feature_size=(1,))\n  (max_value): RandUniformSequenceGenerator(low=5.0, high=10.0, feature_size=(1,))\n)\n&gt;&gt;&gt; generator.generate(seq_len=6, batch_size=2)\ntensor([[...]])\n</code></pre>"},{"location":"refs/sequence/#startorch.sequence.TruncNormalSequenceGenerator","title":"startorch.sequence.TruncNormalSequenceGenerator","text":"<p>               Bases: <code>BaseSequenceGenerator</code></p> <p>Implement a class to generate sequence by sampling values from a truncated Normal distribution.</p> <p>Parameters:</p> Name Type Description Default <code>mean</code> <code>BaseSequenceGenerator | dict</code> <p>A sequence generator (or its configuration) to generate the mean.</p> required <code>std</code> <code>BaseSequenceGenerator | dict</code> <p>A sequence generator (or its configuration) to generate the standard deviation.</p> required <code>min_value</code> <code>BaseSequenceGenerator | dict</code> <p>A sequence generator (or its configuration) to generate the minimum value (included).</p> required <code>max_value</code> <code>BaseSequenceGenerator | dict</code> <p>A sequence generator (or its configuration) to generate the maximum value (excluded).</p> required <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.sequence import RandUniform, TruncNormal\n&gt;&gt;&gt; generator = TruncNormal(\n...     mean=RandUniform(low=-1.0, high=1.0),\n...     std=RandUniform(low=1.0, high=2.0),\n...     min_value=RandUniform(low=-10.0, high=-5.0),\n...     max_value=RandUniform(low=5.0, high=10.0),\n... )\n&gt;&gt;&gt; generator\nTruncNormalSequenceGenerator(\n  (mean): RandUniformSequenceGenerator(low=-1.0, high=1.0, feature_size=(1,))\n  (std): RandUniformSequenceGenerator(low=1.0, high=2.0, feature_size=(1,))\n  (min_value): RandUniformSequenceGenerator(low=-10.0, high=-5.0, feature_size=(1,))\n  (max_value): RandUniformSequenceGenerator(low=5.0, high=10.0, feature_size=(1,))\n)\n&gt;&gt;&gt; generator.generate(seq_len=6, batch_size=2)\ntensor([[...]])\n</code></pre>"},{"location":"refs/sequence/#startorch.sequence.Uniform","title":"startorch.sequence.Uniform","text":"<p>               Bases: <code>BaseSequenceGenerator</code></p> <p>Implement a sequence generator to generate sequences by sampling values from a uniform distribution.</p> <p>Parameters:</p> Name Type Description Default <code>low</code> <code>BaseSequenceGenerator | dict</code> <p>A sequence generator (or its configuration) to generate the minimum value (inclusive).</p> required <code>high</code> <code>BaseSequenceGenerator | dict</code> <p>A sequence generator (or its configuration) to generate the maximum value (exclusive).</p> required <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; from startorch.sequence import Uniform, RandUniform\n&gt;&gt;&gt; generator = Uniform(low=RandUniform(-1.0, 0.0), high=RandUniform(0.0, 1.0))\n&gt;&gt;&gt; generator\nUniformSequenceGenerator(\n  (low): RandUniformSequenceGenerator(low=-1.0, high=0.0, feature_size=(1,))\n  (high): RandUniformSequenceGenerator(low=0.0, high=1.0, feature_size=(1,))\n)\n&gt;&gt;&gt; generator.generate(seq_len=12, batch_size=4)\ntensor([[...]])\n</code></pre>"},{"location":"refs/sequence/#startorch.sequence.UniformCategorical","title":"startorch.sequence.UniformCategorical","text":"<p>               Bases: <code>BaseSequenceGenerator</code></p> <p>Implement a class to generate sequences of uniformly distributed categorical variables.</p> <p>All the categories have the same probability.</p> Note <p>It is a more efficient implementation of <code>Multinomial.generate_uniform_weights</code>.</p> <p>Parameters:</p> Name Type Description Default <code>num_categories</code> <code>int</code> <p>The number of categories.</p> required <code>feature_size</code> <code>tuple[int, ...] | list[int] | int</code> <p>The feature size.</p> <code>()</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>if <code>num_categories</code> is negative.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; from startorch.sequence import UniformCategorical\n&gt;&gt;&gt; generator = UniformCategorical(10)\n&gt;&gt;&gt; generator\nUniformCategoricalSequenceGenerator(num_categories=10, feature_size=())\n&gt;&gt;&gt; generator.generate(seq_len=12, batch_size=4)\ntensor([[...]])\n</code></pre>"},{"location":"refs/sequence/#startorch.sequence.UniformCategoricalSequenceGenerator","title":"startorch.sequence.UniformCategoricalSequenceGenerator","text":"<p>               Bases: <code>BaseSequenceGenerator</code></p> <p>Implement a class to generate sequences of uniformly distributed categorical variables.</p> <p>All the categories have the same probability.</p> Note <p>It is a more efficient implementation of <code>Multinomial.generate_uniform_weights</code>.</p> <p>Parameters:</p> Name Type Description Default <code>num_categories</code> <code>int</code> <p>The number of categories.</p> required <code>feature_size</code> <code>tuple[int, ...] | list[int] | int</code> <p>The feature size.</p> <code>()</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>if <code>num_categories</code> is negative.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; from startorch.sequence import UniformCategorical\n&gt;&gt;&gt; generator = UniformCategorical(10)\n&gt;&gt;&gt; generator\nUniformCategoricalSequenceGenerator(num_categories=10, feature_size=())\n&gt;&gt;&gt; generator.generate(seq_len=12, batch_size=4)\ntensor([[...]])\n</code></pre>"},{"location":"refs/sequence/#startorch.sequence.UniformSequenceGenerator","title":"startorch.sequence.UniformSequenceGenerator","text":"<p>               Bases: <code>BaseSequenceGenerator</code></p> <p>Implement a sequence generator to generate sequences by sampling values from a uniform distribution.</p> <p>Parameters:</p> Name Type Description Default <code>low</code> <code>BaseSequenceGenerator | dict</code> <p>A sequence generator (or its configuration) to generate the minimum value (inclusive).</p> required <code>high</code> <code>BaseSequenceGenerator | dict</code> <p>A sequence generator (or its configuration) to generate the maximum value (exclusive).</p> required <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; from startorch.sequence import Uniform, RandUniform\n&gt;&gt;&gt; generator = Uniform(low=RandUniform(-1.0, 0.0), high=RandUniform(0.0, 1.0))\n&gt;&gt;&gt; generator\nUniformSequenceGenerator(\n  (low): RandUniformSequenceGenerator(low=-1.0, high=0.0, feature_size=(1,))\n  (high): RandUniformSequenceGenerator(low=0.0, high=1.0, feature_size=(1,))\n)\n&gt;&gt;&gt; generator.generate(seq_len=12, batch_size=4)\ntensor([[...]])\n</code></pre>"},{"location":"refs/sequence/#startorch.sequence.is_sequence_generator_config","title":"startorch.sequence.is_sequence_generator_config","text":"<pre><code>is_sequence_generator_config(config: dict) -&gt; bool\n</code></pre> <p>Indicate if the input configuration is a configuration for a <code>BaseSequenceGenerator</code>.</p> <p>This function only checks if the value of the key  <code>_target_</code> is valid. It does not check the other values. If <code>_target_</code> indicates a function, the returned type hint is used to check the class.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>dict</code> <p>The configuration to check.</p> required <p>Returns:</p> Type Description <code>bool</code> <p><code>True</code> if the input configuration is a configuration for a <code>BaseSequenceGenerator</code> object.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.sequence import is_sequence_generator_config\n&gt;&gt;&gt; is_sequence_generator_config({\"_target_\": \"startorch.sequence.RandUniform\"})\nTrue\n</code></pre>"},{"location":"refs/sequence/#startorch.sequence.setup_sequence_generator","title":"startorch.sequence.setup_sequence_generator","text":"<pre><code>setup_sequence_generator(\n    generator: BaseSequenceGenerator | dict,\n) -&gt; BaseSequenceGenerator\n</code></pre> <p>Set up a sequence generator.</p> <p>The sequence generator is instantiated from its configuration by using the <code>BaseSequenceGenerator</code> factory function.</p> <p>Parameters:</p> Name Type Description Default <code>generator</code> <code>BaseSequenceGenerator | dict</code> <p>A sequence generator or its configuration.</p> required <p>Returns:</p> Type Description <code>BaseSequenceGenerator</code> <p>A sequence generator.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.sequence import setup_sequence_generator\n&gt;&gt;&gt; setup_sequence_generator({\"_target_\": \"startorch.sequence.RandUniform\"})\nRandUniformSequenceGenerator(low=0.0, high=1.0, feature_size=(1,))\n</code></pre>"},{"location":"refs/tensor/","title":"tensor","text":""},{"location":"refs/tensor/#startorch.tensor","title":"startorch.tensor","text":"<p>Contain tensor generators.</p>"},{"location":"refs/tensor/#startorch.tensor.Abs","title":"startorch.tensor.Abs","text":"<p>               Bases: <code>BaseWrapperTensorGenerator</code></p> <p>Implement a tensor generator that computes the absolute value of a tensor.</p> <p>This tensor generator is equivalent to: <code>output = abs(tensor)</code></p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.tensor import Abs, RandNormal\n&gt;&gt;&gt; generator = Abs(RandNormal())\n&gt;&gt;&gt; generator\nAbsTensorGenerator(\n  (tensor): RandNormalTensorGenerator(mean=0.0, std=1.0)\n)\n&gt;&gt;&gt; generator.generate((2, 6))\ntensor([[...]])\n</code></pre>"},{"location":"refs/tensor/#startorch.tensor.AbsTensorGenerator","title":"startorch.tensor.AbsTensorGenerator","text":"<p>               Bases: <code>BaseWrapperTensorGenerator</code></p> <p>Implement a tensor generator that computes the absolute value of a tensor.</p> <p>This tensor generator is equivalent to: <code>output = abs(tensor)</code></p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.tensor import Abs, RandNormal\n&gt;&gt;&gt; generator = Abs(RandNormal())\n&gt;&gt;&gt; generator\nAbsTensorGenerator(\n  (tensor): RandNormalTensorGenerator(mean=0.0, std=1.0)\n)\n&gt;&gt;&gt; generator.generate((2, 6))\ntensor([[...]])\n</code></pre>"},{"location":"refs/tensor/#startorch.tensor.Acosh","title":"startorch.tensor.Acosh","text":"<p>               Bases: <code>BaseWrapperTensorGenerator</code></p> <p>Implement a tensor generator that computes the inverse hyperbolic cosine (arccosh) of each value.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.tensor import Acosh, RandUniform\n&gt;&gt;&gt; generator = Acosh(RandUniform(low=1.0, high=5.0))\n&gt;&gt;&gt; generator\nAcoshTensorGenerator(\n  (tensor): RandUniformTensorGenerator(low=1.0, high=5.0)\n)\n&gt;&gt;&gt; generator.generate((2, 6))\ntensor([[...]])\n</code></pre>"},{"location":"refs/tensor/#startorch.tensor.AcoshTensorGenerator","title":"startorch.tensor.AcoshTensorGenerator","text":"<p>               Bases: <code>BaseWrapperTensorGenerator</code></p> <p>Implement a tensor generator that computes the inverse hyperbolic cosine (arccosh) of each value.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.tensor import Acosh, RandUniform\n&gt;&gt;&gt; generator = Acosh(RandUniform(low=1.0, high=5.0))\n&gt;&gt;&gt; generator\nAcoshTensorGenerator(\n  (tensor): RandUniformTensorGenerator(low=1.0, high=5.0)\n)\n&gt;&gt;&gt; generator.generate((2, 6))\ntensor([[...]])\n</code></pre>"},{"location":"refs/tensor/#startorch.tensor.Add","title":"startorch.tensor.Add","text":"<p>               Bases: <code>BaseTensorGenerator</code></p> <p>Implement a tensor generator that adds several tensor.</p> <p>This tensor generator is equivalent to: <code>output = tensor_1 + tensor_2 + ... + tensor_n</code></p> <p>Parameters:</p> Name Type Description Default <code>generators</code> <code>Sequence[BaseTensorGenerator | dict]</code> <p>The tensor generators.</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>if no sequence generator is provided.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.tensor import Add, RandNormal, RandUniform\n&gt;&gt;&gt; generator = Add([RandUniform(), RandNormal()])\n&gt;&gt;&gt; generator\nAddTensorGenerator(\n  (0): RandUniformTensorGenerator(low=0.0, high=1.0)\n  (1): RandNormalTensorGenerator(mean=0.0, std=1.0)\n)\n&gt;&gt;&gt; generator.generate((2, 6))\ntensor([[...]])\n</code></pre>"},{"location":"refs/tensor/#startorch.tensor.AddScalar","title":"startorch.tensor.AddScalar","text":"<p>               Bases: <code>BaseWrapperTensorGenerator</code></p> <p>Implement a tensor generator that adds a scalar value to a generated batch of tensors.</p> <p>This tensor generator is equivalent to: <code>output = tensor + scalar</code></p> <p>Parameters:</p> Name Type Description Default <code>generator</code> <code>BaseTensorGenerator | dict</code> <p>The tensor generator or its configuration.</p> required <code>value</code> <code>float</code> <p>The scalar value to add.</p> required <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.tensor import AddScalar, RandUniform\n&gt;&gt;&gt; generator = AddScalar(RandUniform(), 10.0)\n&gt;&gt;&gt; generator\nAddScalarTensorGenerator(\n  (tensor): RandUniformTensorGenerator(low=0.0, high=1.0)\n  (value): 10.0\n)\n&gt;&gt;&gt; generator.generate((2, 6))\ntensor([[...]])\n</code></pre>"},{"location":"refs/tensor/#startorch.tensor.AddScalarTensorGenerator","title":"startorch.tensor.AddScalarTensorGenerator","text":"<p>               Bases: <code>BaseWrapperTensorGenerator</code></p> <p>Implement a tensor generator that adds a scalar value to a generated batch of tensors.</p> <p>This tensor generator is equivalent to: <code>output = tensor + scalar</code></p> <p>Parameters:</p> Name Type Description Default <code>generator</code> <code>BaseTensorGenerator | dict</code> <p>The tensor generator or its configuration.</p> required <code>value</code> <code>float</code> <p>The scalar value to add.</p> required <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.tensor import AddScalar, RandUniform\n&gt;&gt;&gt; generator = AddScalar(RandUniform(), 10.0)\n&gt;&gt;&gt; generator\nAddScalarTensorGenerator(\n  (tensor): RandUniformTensorGenerator(low=0.0, high=1.0)\n  (value): 10.0\n)\n&gt;&gt;&gt; generator.generate((2, 6))\ntensor([[...]])\n</code></pre>"},{"location":"refs/tensor/#startorch.tensor.AddTensorGenerator","title":"startorch.tensor.AddTensorGenerator","text":"<p>               Bases: <code>BaseTensorGenerator</code></p> <p>Implement a tensor generator that adds several tensor.</p> <p>This tensor generator is equivalent to: <code>output = tensor_1 + tensor_2 + ... + tensor_n</code></p> <p>Parameters:</p> Name Type Description Default <code>generators</code> <code>Sequence[BaseTensorGenerator | dict]</code> <p>The tensor generators.</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>if no sequence generator is provided.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.tensor import Add, RandNormal, RandUniform\n&gt;&gt;&gt; generator = Add([RandUniform(), RandNormal()])\n&gt;&gt;&gt; generator\nAddTensorGenerator(\n  (0): RandUniformTensorGenerator(low=0.0, high=1.0)\n  (1): RandNormalTensorGenerator(mean=0.0, std=1.0)\n)\n&gt;&gt;&gt; generator.generate((2, 6))\ntensor([[...]])\n</code></pre>"},{"location":"refs/tensor/#startorch.tensor.Asinh","title":"startorch.tensor.Asinh","text":"<p>               Bases: <code>BaseWrapperTensorGenerator</code></p> <p>Implement a tensor generator that computes the inverse hyperbolic sine (arcsinh) of each value.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.tensor import Asinh, RandUniform\n&gt;&gt;&gt; generator = Asinh(RandUniform(low=0.0, high=1000.0))\n&gt;&gt;&gt; generator\nAsinhTensorGenerator(\n  (tensor): RandUniformTensorGenerator(low=0.0, high=1000.0)\n)\n&gt;&gt;&gt; generator.generate((2, 6))\ntensor([[...]])\n</code></pre>"},{"location":"refs/tensor/#startorch.tensor.AsinhTensorGenerator","title":"startorch.tensor.AsinhTensorGenerator","text":"<p>               Bases: <code>BaseWrapperTensorGenerator</code></p> <p>Implement a tensor generator that computes the inverse hyperbolic sine (arcsinh) of each value.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.tensor import Asinh, RandUniform\n&gt;&gt;&gt; generator = Asinh(RandUniform(low=0.0, high=1000.0))\n&gt;&gt;&gt; generator\nAsinhTensorGenerator(\n  (tensor): RandUniformTensorGenerator(low=0.0, high=1000.0)\n)\n&gt;&gt;&gt; generator.generate((2, 6))\ntensor([[...]])\n</code></pre>"},{"location":"refs/tensor/#startorch.tensor.AsinhUniform","title":"startorch.tensor.AsinhUniform","text":"<p>               Bases: <code>BaseTensorGenerator</code></p> <p>Implement a tensor generator to generate tensors by sampling values from an asinh-uniform distribution.</p> <p>Parameters:</p> Name Type Description Default <code>low</code> <code>BaseTensorGenerator | dict</code> <p>A tensor generator (or its configuration) to generate the minimum value (inclusive).</p> required <code>high</code> <code>BaseTensorGenerator | dict</code> <p>A tensor generator (or its configuration) to generate the maximum value (exclusive).</p> required <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.tensor import RandUniform, AsinhUniform\n&gt;&gt;&gt; generator = AsinhUniform(\n...     low=RandUniform(low=-1000, high=-100), high=RandUniform(low=100, high=1000)\n... )\n&gt;&gt;&gt; generator\nAsinhUniformTensorGenerator(\n  (low): RandUniformTensorGenerator(low=-1000.0, high=-100.0)\n  (high): RandUniformTensorGenerator(low=100.0, high=1000.0)\n)\n&gt;&gt;&gt; generator.generate((2, 6))\ntensor([[...]])\n</code></pre>"},{"location":"refs/tensor/#startorch.tensor.AsinhUniformTensorGenerator","title":"startorch.tensor.AsinhUniformTensorGenerator","text":"<p>               Bases: <code>BaseTensorGenerator</code></p> <p>Implement a tensor generator to generate tensors by sampling values from an asinh-uniform distribution.</p> <p>Parameters:</p> Name Type Description Default <code>low</code> <code>BaseTensorGenerator | dict</code> <p>A tensor generator (or its configuration) to generate the minimum value (inclusive).</p> required <code>high</code> <code>BaseTensorGenerator | dict</code> <p>A tensor generator (or its configuration) to generate the maximum value (exclusive).</p> required <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.tensor import RandUniform, AsinhUniform\n&gt;&gt;&gt; generator = AsinhUniform(\n...     low=RandUniform(low=-1000, high=-100), high=RandUniform(low=100, high=1000)\n... )\n&gt;&gt;&gt; generator\nAsinhUniformTensorGenerator(\n  (low): RandUniformTensorGenerator(low=-1000.0, high=-100.0)\n  (high): RandUniformTensorGenerator(low=100.0, high=1000.0)\n)\n&gt;&gt;&gt; generator.generate((2, 6))\ntensor([[...]])\n</code></pre>"},{"location":"refs/tensor/#startorch.tensor.Atanh","title":"startorch.tensor.Atanh","text":"<p>               Bases: <code>BaseWrapperTensorGenerator</code></p> <p>Implement a tensor generator that computes the inverse hyperbolic tangent (arctanh) of each value.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.tensor import Atanh, RandUniform\n&gt;&gt;&gt; generator = Atanh(RandUniform(low=-0.5, high=0.5))\n&gt;&gt;&gt; generator\nAtanhTensorGenerator(\n  (tensor): RandUniformTensorGenerator(low=-0.5, high=0.5)\n)\n&gt;&gt;&gt; generator.generate((2, 6))\ntensor([[...]])\n</code></pre>"},{"location":"refs/tensor/#startorch.tensor.AtanhTensorGenerator","title":"startorch.tensor.AtanhTensorGenerator","text":"<p>               Bases: <code>BaseWrapperTensorGenerator</code></p> <p>Implement a tensor generator that computes the inverse hyperbolic tangent (arctanh) of each value.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.tensor import Atanh, RandUniform\n&gt;&gt;&gt; generator = Atanh(RandUniform(low=-0.5, high=0.5))\n&gt;&gt;&gt; generator\nAtanhTensorGenerator(\n  (tensor): RandUniformTensorGenerator(low=-0.5, high=0.5)\n)\n&gt;&gt;&gt; generator.generate((2, 6))\ntensor([[...]])\n</code></pre>"},{"location":"refs/tensor/#startorch.tensor.BaseTensorGenerator","title":"startorch.tensor.BaseTensorGenerator","text":"<p>               Bases: <code>ABC</code></p> <p>Define the base class to generate tensor.</p> <p>A child class has to implement the <code>generate</code> method.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; from startorch.tensor import RandUniform\n&gt;&gt;&gt; generator = RandUniform()\n&gt;&gt;&gt; generator\nRandUniformTensorGenerator(low=0.0, high=1.0)\n&gt;&gt;&gt; generator.generate(size=(4, 12))\ntensor([[...]])\n</code></pre>"},{"location":"refs/tensor/#startorch.tensor.BaseTensorGenerator.generate","title":"startorch.tensor.BaseTensorGenerator.generate  <code>abstractmethod</code>","text":"<pre><code>generate(\n    size: tuple[int, ...], rng: Generator | None = None\n) -&gt; Tensor\n</code></pre> <p>Generate a tensor.</p> <p>Parameters:</p> Name Type Description Default <code>size</code> <code>tuple[int, ...]</code> <p>The size of the tensor to generate.</p> required <code>rng</code> <code>Generator | None</code> <p>An optional random number generator.</p> <code>None</code> <p>Returns:</p> Type Description <code>Tensor</code> <p>The generated tensor with the specified size.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; from startorch.tensor import RandUniform\n&gt;&gt;&gt; generator = RandUniform()\n&gt;&gt;&gt; generator.generate(size=(4, 12))\ntensor([[...]])\n</code></pre>"},{"location":"refs/tensor/#startorch.tensor.BaseWrapperTensorGenerator","title":"startorch.tensor.BaseWrapperTensorGenerator","text":"<p>               Bases: <code>BaseTensorGenerator</code></p> <p>Define a base class to easily wrap a tensor generator into another tensor generator.</p> Note <p>It is possible to wrap a tensor generator into another tensor generator without using this base class. This class makes it more convenient and reduce duplicate code.</p> <p>Parameters:</p> Name Type Description Default <code>generator</code> <code>BaseTensorGenerator | dict</code> <p>The tensor generator or its configuration.</p> required"},{"location":"refs/tensor/#startorch.tensor.Cauchy","title":"startorch.tensor.Cauchy","text":"<p>               Bases: <code>BaseTensorGenerator</code></p> <p>Implement a class to generate tensor by sampling values from a Cauchy distribution.</p> <p>Parameters:</p> Name Type Description Default <code>loc</code> <code>BaseTensorGenerator | dict</code> <p>A tensor generator (or its configuration) to generate the location.</p> required <code>scale</code> <code>BaseTensorGenerator | dict</code> <p>A tensor generator (or its configuration) to generate the scale.</p> required <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.tensor import Cauchy, RandUniform\n&gt;&gt;&gt; generator = Cauchy(\n...     loc=RandUniform(low=-1.0, high=1.0), scale=RandUniform(low=1.0, high=2.0)\n... )\n&gt;&gt;&gt; generator\nCauchyTensorGenerator(\n  (loc): RandUniformTensorGenerator(low=-1.0, high=1.0)\n  (scale): RandUniformTensorGenerator(low=1.0, high=2.0)\n)\n&gt;&gt;&gt; generator.generate((2, 6))\ntensor([[...]])\n</code></pre>"},{"location":"refs/tensor/#startorch.tensor.CauchyTensorGenerator","title":"startorch.tensor.CauchyTensorGenerator","text":"<p>               Bases: <code>BaseTensorGenerator</code></p> <p>Implement a class to generate tensor by sampling values from a Cauchy distribution.</p> <p>Parameters:</p> Name Type Description Default <code>loc</code> <code>BaseTensorGenerator | dict</code> <p>A tensor generator (or its configuration) to generate the location.</p> required <code>scale</code> <code>BaseTensorGenerator | dict</code> <p>A tensor generator (or its configuration) to generate the scale.</p> required <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.tensor import Cauchy, RandUniform\n&gt;&gt;&gt; generator = Cauchy(\n...     loc=RandUniform(low=-1.0, high=1.0), scale=RandUniform(low=1.0, high=2.0)\n... )\n&gt;&gt;&gt; generator\nCauchyTensorGenerator(\n  (loc): RandUniformTensorGenerator(low=-1.0, high=1.0)\n  (scale): RandUniformTensorGenerator(low=1.0, high=2.0)\n)\n&gt;&gt;&gt; generator.generate((2, 6))\ntensor([[...]])\n</code></pre>"},{"location":"refs/tensor/#startorch.tensor.Clamp","title":"startorch.tensor.Clamp","text":"<p>               Bases: <code>BaseWrapperTensorGenerator</code></p> <p>Implement a tensor generator to generate tensors where the values are clamped.</p> <p>Note: <code>min_value</code> and <code>max_value</code> cannot be both <code>None</code>.</p> <p>Parameters:</p> Name Type Description Default <code>generator</code> <code>BaseTensorGenerator | dict</code> <p>The tensor generator or its configuration.</p> required <code>min_value</code> <code>float | None</code> <p>The lower bound. If <code>min_value</code> is <code>None</code>, there is no lower bound.</p> required <code>max_value</code> <code>float | None</code> <p>The upper bound. If <code>max_value</code> is <code>None</code>, there is no upper bound.</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>if both <code>min</code> and <code>max</code> are <code>None</code></p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.tensor import Clamp, RandUniform\n&gt;&gt;&gt; generator = Clamp(RandUniform(low=1.0, high=50.0), min_value=2.0, max_value=10.0)\n&gt;&gt;&gt; generator\nClampTensorGenerator(\n  (tensor): RandUniformTensorGenerator(low=1.0, high=50.0)\n  (min_value): 2.0\n  (max_value): 10.0\n)\n&gt;&gt;&gt; generator.generate((2, 6))\ntensor([[...]])\n</code></pre>"},{"location":"refs/tensor/#startorch.tensor.ClampTensorGenerator","title":"startorch.tensor.ClampTensorGenerator","text":"<p>               Bases: <code>BaseWrapperTensorGenerator</code></p> <p>Implement a tensor generator to generate tensors where the values are clamped.</p> <p>Note: <code>min_value</code> and <code>max_value</code> cannot be both <code>None</code>.</p> <p>Parameters:</p> Name Type Description Default <code>generator</code> <code>BaseTensorGenerator | dict</code> <p>The tensor generator or its configuration.</p> required <code>min_value</code> <code>float | None</code> <p>The lower bound. If <code>min_value</code> is <code>None</code>, there is no lower bound.</p> required <code>max_value</code> <code>float | None</code> <p>The upper bound. If <code>max_value</code> is <code>None</code>, there is no upper bound.</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>if both <code>min</code> and <code>max</code> are <code>None</code></p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.tensor import Clamp, RandUniform\n&gt;&gt;&gt; generator = Clamp(RandUniform(low=1.0, high=50.0), min_value=2.0, max_value=10.0)\n&gt;&gt;&gt; generator\nClampTensorGenerator(\n  (tensor): RandUniformTensorGenerator(low=1.0, high=50.0)\n  (min_value): 2.0\n  (max_value): 10.0\n)\n&gt;&gt;&gt; generator.generate((2, 6))\ntensor([[...]])\n</code></pre>"},{"location":"refs/tensor/#startorch.tensor.Cosh","title":"startorch.tensor.Cosh","text":"<p>               Bases: <code>BaseWrapperTensorGenerator</code></p> <p>Implement a tensor generator that computes the hyperbolic cosine (cosh) of each value.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.tensor import Cosh, RandUniform\n&gt;&gt;&gt; generator = Cosh(RandUniform())\n&gt;&gt;&gt; generator\nCoshTensorGenerator(\n  (tensor): RandUniformTensorGenerator(low=0.0, high=1.0)\n)\n&gt;&gt;&gt; generator.generate((2, 6))\ntensor([[...]])\n</code></pre>"},{"location":"refs/tensor/#startorch.tensor.CoshTensorGenerator","title":"startorch.tensor.CoshTensorGenerator","text":"<p>               Bases: <code>BaseWrapperTensorGenerator</code></p> <p>Implement a tensor generator that computes the hyperbolic cosine (cosh) of each value.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.tensor import Cosh, RandUniform\n&gt;&gt;&gt; generator = Cosh(RandUniform())\n&gt;&gt;&gt; generator\nCoshTensorGenerator(\n  (tensor): RandUniformTensorGenerator(low=0.0, high=1.0)\n)\n&gt;&gt;&gt; generator.generate((2, 6))\ntensor([[...]])\n</code></pre>"},{"location":"refs/tensor/#startorch.tensor.Div","title":"startorch.tensor.Div","text":"<p>               Bases: <code>BaseTensorGenerator</code></p> <p>Implement a tensor generator that divides one tensor by another one.</p> This tensor generator is equivalent to <ul> <li><code>output = dividend / divisor</code> (a.k.a. true division)</li> <li><code>output = dividend // divisor</code> (a.k.a. floor division)</li> </ul> <p>Parameters:</p> Name Type Description Default <code>dividend</code> <code>BaseTensorGenerator | dict</code> <p>The dividend tensor generator or its configuration.</p> required <code>divisor</code> <code>BaseTensorGenerator | dict</code> <p>The divisor tensor generator or its configuration.</p> required <code>rounding_mode</code> <code>str | None</code> <p>The type of rounding applied to the result. - <code>None</code>: true division. - <code>\"trunc\"</code>: rounds the results of the division     towards zero. - <code>\"floor\"</code>: floor division.</p> <code>None</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.tensor import Div, RandUniform\n&gt;&gt;&gt; generator = Div(RandUniform(), RandUniform(low=1.0, high=10.0))\n&gt;&gt;&gt; generator\nDivTensorGenerator(\n  (dividend): RandUniformTensorGenerator(low=0.0, high=1.0)\n  (divisor): RandUniformTensorGenerator(low=1.0, high=10.0)\n)\n&gt;&gt;&gt; generator.generate((2, 6))\ntensor([[...]])\n</code></pre>"},{"location":"refs/tensor/#startorch.tensor.DivTensorGenerator","title":"startorch.tensor.DivTensorGenerator","text":"<p>               Bases: <code>BaseTensorGenerator</code></p> <p>Implement a tensor generator that divides one tensor by another one.</p> This tensor generator is equivalent to <ul> <li><code>output = dividend / divisor</code> (a.k.a. true division)</li> <li><code>output = dividend // divisor</code> (a.k.a. floor division)</li> </ul> <p>Parameters:</p> Name Type Description Default <code>dividend</code> <code>BaseTensorGenerator | dict</code> <p>The dividend tensor generator or its configuration.</p> required <code>divisor</code> <code>BaseTensorGenerator | dict</code> <p>The divisor tensor generator or its configuration.</p> required <code>rounding_mode</code> <code>str | None</code> <p>The type of rounding applied to the result. - <code>None</code>: true division. - <code>\"trunc\"</code>: rounds the results of the division     towards zero. - <code>\"floor\"</code>: floor division.</p> <code>None</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.tensor import Div, RandUniform\n&gt;&gt;&gt; generator = Div(RandUniform(), RandUniform(low=1.0, high=10.0))\n&gt;&gt;&gt; generator\nDivTensorGenerator(\n  (dividend): RandUniformTensorGenerator(low=0.0, high=1.0)\n  (divisor): RandUniformTensorGenerator(low=1.0, high=10.0)\n)\n&gt;&gt;&gt; generator.generate((2, 6))\ntensor([[...]])\n</code></pre>"},{"location":"refs/tensor/#startorch.tensor.Exp","title":"startorch.tensor.Exp","text":"<p>               Bases: <code>BaseWrapperTensorGenerator</code></p> <p>Implement a tensor generator that computes the exponential of a tensor.</p> <p>This tensor generator is equivalent to: <code>output = exp(tensor)</code></p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.tensor import Exp, RandUniform\n&gt;&gt;&gt; generator = Exp(RandUniform(low=1.0, high=5.0))\n&gt;&gt;&gt; generator\nExpTensorGenerator(\n  (tensor): RandUniformTensorGenerator(low=1.0, high=5.0)\n)\n&gt;&gt;&gt; generator.generate((2, 6))\ntensor([[...]])\n</code></pre>"},{"location":"refs/tensor/#startorch.tensor.ExpTensorGenerator","title":"startorch.tensor.ExpTensorGenerator","text":"<p>               Bases: <code>BaseWrapperTensorGenerator</code></p> <p>Implement a tensor generator that computes the exponential of a tensor.</p> <p>This tensor generator is equivalent to: <code>output = exp(tensor)</code></p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.tensor import Exp, RandUniform\n&gt;&gt;&gt; generator = Exp(RandUniform(low=1.0, high=5.0))\n&gt;&gt;&gt; generator\nExpTensorGenerator(\n  (tensor): RandUniformTensorGenerator(low=1.0, high=5.0)\n)\n&gt;&gt;&gt; generator.generate((2, 6))\ntensor([[...]])\n</code></pre>"},{"location":"refs/tensor/#startorch.tensor.Exponential","title":"startorch.tensor.Exponential","text":"<p>               Bases: <code>BaseTensorGenerator</code></p> <p>Implement a class to generate tensors by sampling values from an Exponential distribution.</p> <p>The rates of the Exponential distribution are generated by the rate generator. The rate generator should return the rate for each value in the sequence.</p> <p>Parameters:</p> Name Type Description Default <code>rate</code> <code>BaseTensorGenerator | dict</code> <p>The rate generator or its configuration. The rate generator should return valid rate values.</p> required <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.tensor import Exponential, RandUniform\n&gt;&gt;&gt; generator = Exponential(rate=RandUniform(low=1.0, high=100.0))\n&gt;&gt;&gt; generator\nExponentialTensorGenerator(\n  (rate): RandUniformTensorGenerator(low=1.0, high=100.0)\n)\n&gt;&gt;&gt; generator.generate((2, 6))\ntensor([[...]])\n</code></pre>"},{"location":"refs/tensor/#startorch.tensor.ExponentialTensorGenerator","title":"startorch.tensor.ExponentialTensorGenerator","text":"<p>               Bases: <code>BaseTensorGenerator</code></p> <p>Implement a class to generate tensors by sampling values from an Exponential distribution.</p> <p>The rates of the Exponential distribution are generated by the rate generator. The rate generator should return the rate for each value in the sequence.</p> <p>Parameters:</p> Name Type Description Default <code>rate</code> <code>BaseTensorGenerator | dict</code> <p>The rate generator or its configuration. The rate generator should return valid rate values.</p> required <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.tensor import Exponential, RandUniform\n&gt;&gt;&gt; generator = Exponential(rate=RandUniform(low=1.0, high=100.0))\n&gt;&gt;&gt; generator\nExponentialTensorGenerator(\n  (rate): RandUniformTensorGenerator(low=1.0, high=100.0)\n)\n&gt;&gt;&gt; generator.generate((2, 6))\ntensor([[...]])\n</code></pre>"},{"location":"refs/tensor/#startorch.tensor.Float","title":"startorch.tensor.Float","text":"<p>               Bases: <code>BaseWrapperTensorGenerator</code></p> <p>Implement a sequence generator that converts tensor values to float.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.tensor import Float, RandInt\n&gt;&gt;&gt; generator = Float(RandInt(low=0, high=10))\n&gt;&gt;&gt; generator\nFloatTensorGenerator(\n  (tensor): RandIntTensorGenerator(low=0, high=10)\n)\n&gt;&gt;&gt; generator.generate((2, 6))\ntensor([[...]])\n</code></pre>"},{"location":"refs/tensor/#startorch.tensor.FloatTensorGenerator","title":"startorch.tensor.FloatTensorGenerator","text":"<p>               Bases: <code>BaseWrapperTensorGenerator</code></p> <p>Implement a sequence generator that converts tensor values to float.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.tensor import Float, RandInt\n&gt;&gt;&gt; generator = Float(RandInt(low=0, high=10))\n&gt;&gt;&gt; generator\nFloatTensorGenerator(\n  (tensor): RandIntTensorGenerator(low=0, high=10)\n)\n&gt;&gt;&gt; generator.generate((2, 6))\ntensor([[...]])\n</code></pre>"},{"location":"refs/tensor/#startorch.tensor.Fmod","title":"startorch.tensor.Fmod","text":"<p>               Bases: <code>BaseTensorGenerator</code></p> <p>Implement a tensor generator that computes the element-wise remainder of division.</p> <p>This tensor generator is equivalent to: <code>output = dividend % divisor</code></p> <p>Parameters:</p> Name Type Description Default <code>dividend</code> <code>BaseTensorGenerator | dict</code> <p>The tensor generator (or its configuration) that generates the dividend values.</p> required <code>divisor</code> <code>BaseTensorGenerator | dict | float</code> <p>The divisor.</p> required <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.tensor import Fmod, RandUniform\n&gt;&gt;&gt; generator = Fmod(dividend=RandUniform(low=-100, high=100), divisor=10.0)\n&gt;&gt;&gt; generator\nFmodTensorGenerator(\n  (dividend): RandUniformTensorGenerator(low=-100.0, high=100.0)\n  (divisor): 10.0\n)\n&gt;&gt;&gt; generator.generate((2, 6))\ntensor([[...]])\n&gt;&gt;&gt; generator = Fmod(\n...     dividend=RandUniform(low=-100, high=100), divisor=RandUniform(low=1, high=10)\n... )\n&gt;&gt;&gt; generator\nFmodTensorGenerator(\n  (dividend): RandUniformTensorGenerator(low=-100.0, high=100.0)\n  (divisor): RandUniformTensorGenerator(low=1.0, high=10.0)\n)\n&gt;&gt;&gt; generator.generate((2, 6))\ntensor([[...]])\n</code></pre>"},{"location":"refs/tensor/#startorch.tensor.FmodTensorGenerator","title":"startorch.tensor.FmodTensorGenerator","text":"<p>               Bases: <code>BaseTensorGenerator</code></p> <p>Implement a tensor generator that computes the element-wise remainder of division.</p> <p>This tensor generator is equivalent to: <code>output = dividend % divisor</code></p> <p>Parameters:</p> Name Type Description Default <code>dividend</code> <code>BaseTensorGenerator | dict</code> <p>The tensor generator (or its configuration) that generates the dividend values.</p> required <code>divisor</code> <code>BaseTensorGenerator | dict | float</code> <p>The divisor.</p> required <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.tensor import Fmod, RandUniform\n&gt;&gt;&gt; generator = Fmod(dividend=RandUniform(low=-100, high=100), divisor=10.0)\n&gt;&gt;&gt; generator\nFmodTensorGenerator(\n  (dividend): RandUniformTensorGenerator(low=-100.0, high=100.0)\n  (divisor): 10.0\n)\n&gt;&gt;&gt; generator.generate((2, 6))\ntensor([[...]])\n&gt;&gt;&gt; generator = Fmod(\n...     dividend=RandUniform(low=-100, high=100), divisor=RandUniform(low=1, high=10)\n... )\n&gt;&gt;&gt; generator\nFmodTensorGenerator(\n  (dividend): RandUniformTensorGenerator(low=-100.0, high=100.0)\n  (divisor): RandUniformTensorGenerator(low=1.0, high=10.0)\n)\n&gt;&gt;&gt; generator.generate((2, 6))\ntensor([[...]])\n</code></pre>"},{"location":"refs/tensor/#startorch.tensor.Full","title":"startorch.tensor.Full","text":"<p>               Bases: <code>BaseTensorGenerator</code></p> <p>Implement a tensor generator that fills the tensor with a given value.</p> <p>Parameters:</p> Name Type Description Default <code>value</code> <code>bool | float</code> <p>The fill value.</p> required <code>dtype</code> <code>dtype | None</code> <p>The target dtype. <code>None</code> means the data type is infered from the value type.</p> <code>None</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.tensor import Full\n&gt;&gt;&gt; generator = Full(value=42)\n&gt;&gt;&gt; generator\nFullTensorGenerator(value=42, dtype=None)\n&gt;&gt;&gt; generator.generate((2, 6))\ntensor([[42, 42, 42, 42, 42, 42],\n        [42, 42, 42, 42, 42, 42]])\n</code></pre>"},{"location":"refs/tensor/#startorch.tensor.FullTensorGenerator","title":"startorch.tensor.FullTensorGenerator","text":"<p>               Bases: <code>BaseTensorGenerator</code></p> <p>Implement a tensor generator that fills the tensor with a given value.</p> <p>Parameters:</p> Name Type Description Default <code>value</code> <code>bool | float</code> <p>The fill value.</p> required <code>dtype</code> <code>dtype | None</code> <p>The target dtype. <code>None</code> means the data type is infered from the value type.</p> <code>None</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.tensor import Full\n&gt;&gt;&gt; generator = Full(value=42)\n&gt;&gt;&gt; generator\nFullTensorGenerator(value=42, dtype=None)\n&gt;&gt;&gt; generator.generate((2, 6))\ntensor([[42, 42, 42, 42, 42, 42],\n        [42, 42, 42, 42, 42, 42]])\n</code></pre>"},{"location":"refs/tensor/#startorch.tensor.HalfCauchy","title":"startorch.tensor.HalfCauchy","text":"<p>               Bases: <code>BaseTensorGenerator</code></p> <p>Implement a class to generate tensor by sampling values from a half-Cauchy distribution.</p> <p>Parameters:</p> Name Type Description Default <code>scale</code> <code>BaseTensorGenerator | dict</code> <p>A tensor generator (or its configuration) to generate the scale.</p> required <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.tensor import HalfCauchy, RandUniform\n&gt;&gt;&gt; generator = HalfCauchy(scale=RandUniform(low=1.0, high=2.0))\n&gt;&gt;&gt; generator\nHalfCauchyTensorGenerator(\n  (scale): RandUniformTensorGenerator(low=1.0, high=2.0)\n)\n&gt;&gt;&gt; generator.generate((2, 6))\ntensor([[...]])\n</code></pre>"},{"location":"refs/tensor/#startorch.tensor.HalfCauchyTensorGenerator","title":"startorch.tensor.HalfCauchyTensorGenerator","text":"<p>               Bases: <code>BaseTensorGenerator</code></p> <p>Implement a class to generate tensor by sampling values from a half-Cauchy distribution.</p> <p>Parameters:</p> Name Type Description Default <code>scale</code> <code>BaseTensorGenerator | dict</code> <p>A tensor generator (or its configuration) to generate the scale.</p> required <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.tensor import HalfCauchy, RandUniform\n&gt;&gt;&gt; generator = HalfCauchy(scale=RandUniform(low=1.0, high=2.0))\n&gt;&gt;&gt; generator\nHalfCauchyTensorGenerator(\n  (scale): RandUniformTensorGenerator(low=1.0, high=2.0)\n)\n&gt;&gt;&gt; generator.generate((2, 6))\ntensor([[...]])\n</code></pre>"},{"location":"refs/tensor/#startorch.tensor.HalfNormal","title":"startorch.tensor.HalfNormal","text":"<p>               Bases: <code>BaseTensorGenerator</code></p> <p>Implement a class to generate tensor by sampling values from a half-Normal distribution.</p> <p>Parameters:</p> Name Type Description Default <code>std</code> <code>BaseTensorGenerator | dict</code> <p>A tensor generator (or its configuration) to generate the standard deviation.</p> required <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.tensor import HalfNormal, RandUniform\n&gt;&gt;&gt; generator = HalfNormal(std=RandUniform(low=1.0, high=2.0))\n&gt;&gt;&gt; generator\nHalfNormalTensorGenerator(\n  (std): RandUniformTensorGenerator(low=1.0, high=2.0)\n)\n&gt;&gt;&gt; generator.generate(size=(2, 6))\ntensor([[...]])\n</code></pre>"},{"location":"refs/tensor/#startorch.tensor.HalfNormalTensorGenerator","title":"startorch.tensor.HalfNormalTensorGenerator","text":"<p>               Bases: <code>BaseTensorGenerator</code></p> <p>Implement a class to generate tensor by sampling values from a half-Normal distribution.</p> <p>Parameters:</p> Name Type Description Default <code>std</code> <code>BaseTensorGenerator | dict</code> <p>A tensor generator (or its configuration) to generate the standard deviation.</p> required <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.tensor import HalfNormal, RandUniform\n&gt;&gt;&gt; generator = HalfNormal(std=RandUniform(low=1.0, high=2.0))\n&gt;&gt;&gt; generator\nHalfNormalTensorGenerator(\n  (std): RandUniformTensorGenerator(low=1.0, high=2.0)\n)\n&gt;&gt;&gt; generator.generate(size=(2, 6))\ntensor([[...]])\n</code></pre>"},{"location":"refs/tensor/#startorch.tensor.Log","title":"startorch.tensor.Log","text":"<p>               Bases: <code>BaseWrapperTensorGenerator</code></p> <p>Implement a tensor generator that computes the logarithm of a tensor.</p> <p>This tensor generator is equivalent to: <code>output = log(tensor)</code></p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.tensor import Log, RandUniform\n&gt;&gt;&gt; generator = Log(RandUniform(low=1.0, high=100.0))\n&gt;&gt;&gt; generator\nLogTensorGenerator(\n  (tensor): RandUniformTensorGenerator(low=1.0, high=100.0)\n)\n&gt;&gt;&gt; generator.generate((2, 6))\ntensor([[...]])\n</code></pre>"},{"location":"refs/tensor/#startorch.tensor.LogNormal","title":"startorch.tensor.LogNormal","text":"<p>               Bases: <code>BaseTensorGenerator</code></p> <p>Implement a class to generate tensor by sampling values from a log-Normal distribution.</p> <p>Parameters:</p> Name Type Description Default <code>mean</code> <code>BaseTensorGenerator | dict</code> <p>A tensor generator (or its configuration) to generate the mean of the underlying Normal distribution.</p> required <code>std</code> <code>BaseTensorGenerator | dict</code> <p>A tensor generator (or its configuration) to generate the standard deviation of the underlying Normal distribution.</p> required <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.tensor import LogNormal, RandUniform\n&gt;&gt;&gt; generator = LogNormal(\n...     mean=RandUniform(low=-1.0, high=1.0), std=RandUniform(low=1.0, high=2.0)\n... )\n&gt;&gt;&gt; generator\nLogNormalTensorGenerator(\n  (mean): RandUniformTensorGenerator(low=-1.0, high=1.0)\n  (std): RandUniformTensorGenerator(low=1.0, high=2.0)\n)\n&gt;&gt;&gt; generator.generate(size=(2, 6))\ntensor([[...]])\n</code></pre>"},{"location":"refs/tensor/#startorch.tensor.LogNormalTensorGenerator","title":"startorch.tensor.LogNormalTensorGenerator","text":"<p>               Bases: <code>BaseTensorGenerator</code></p> <p>Implement a class to generate tensor by sampling values from a log-Normal distribution.</p> <p>Parameters:</p> Name Type Description Default <code>mean</code> <code>BaseTensorGenerator | dict</code> <p>A tensor generator (or its configuration) to generate the mean of the underlying Normal distribution.</p> required <code>std</code> <code>BaseTensorGenerator | dict</code> <p>A tensor generator (or its configuration) to generate the standard deviation of the underlying Normal distribution.</p> required <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.tensor import LogNormal, RandUniform\n&gt;&gt;&gt; generator = LogNormal(\n...     mean=RandUniform(low=-1.0, high=1.0), std=RandUniform(low=1.0, high=2.0)\n... )\n&gt;&gt;&gt; generator\nLogNormalTensorGenerator(\n  (mean): RandUniformTensorGenerator(low=-1.0, high=1.0)\n  (std): RandUniformTensorGenerator(low=1.0, high=2.0)\n)\n&gt;&gt;&gt; generator.generate(size=(2, 6))\ntensor([[...]])\n</code></pre>"},{"location":"refs/tensor/#startorch.tensor.LogTensorGenerator","title":"startorch.tensor.LogTensorGenerator","text":"<p>               Bases: <code>BaseWrapperTensorGenerator</code></p> <p>Implement a tensor generator that computes the logarithm of a tensor.</p> <p>This tensor generator is equivalent to: <code>output = log(tensor)</code></p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.tensor import Log, RandUniform\n&gt;&gt;&gt; generator = Log(RandUniform(low=1.0, high=100.0))\n&gt;&gt;&gt; generator\nLogTensorGenerator(\n  (tensor): RandUniformTensorGenerator(low=1.0, high=100.0)\n)\n&gt;&gt;&gt; generator.generate((2, 6))\ntensor([[...]])\n</code></pre>"},{"location":"refs/tensor/#startorch.tensor.LogUniform","title":"startorch.tensor.LogUniform","text":"<p>               Bases: <code>BaseTensorGenerator</code></p> <p>Implement a tensor generator to generate tensors by sampling values from a log-uniform distribution.</p> <p>Parameters:</p> Name Type Description Default <code>low</code> <code>BaseTensorGenerator | dict</code> <p>A tensor generator (or its configuration) to generate the minimum value (inclusive).</p> required <code>high</code> <code>BaseTensorGenerator | dict</code> <p>A tensor generator (or its configuration) to generate the maximum value (exclusive).</p> required <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.tensor import RandUniform, LogUniform\n&gt;&gt;&gt; generator = LogUniform(\n...     low=RandUniform(low=0.1, high=1.0), high=RandUniform(low=100, high=1000)\n... )\n&gt;&gt;&gt; generator\nLogUniformTensorGenerator(\n  (low): RandUniformTensorGenerator(low=0.1, high=1.0)\n  (high): RandUniformTensorGenerator(low=100.0, high=1000.0)\n)\n&gt;&gt;&gt; generator.generate((2, 6))\ntensor([[...]])\n</code></pre>"},{"location":"refs/tensor/#startorch.tensor.LogUniformTensorGenerator","title":"startorch.tensor.LogUniformTensorGenerator","text":"<p>               Bases: <code>BaseTensorGenerator</code></p> <p>Implement a tensor generator to generate tensors by sampling values from a log-uniform distribution.</p> <p>Parameters:</p> Name Type Description Default <code>low</code> <code>BaseTensorGenerator | dict</code> <p>A tensor generator (or its configuration) to generate the minimum value (inclusive).</p> required <code>high</code> <code>BaseTensorGenerator | dict</code> <p>A tensor generator (or its configuration) to generate the maximum value (exclusive).</p> required <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.tensor import RandUniform, LogUniform\n&gt;&gt;&gt; generator = LogUniform(\n...     low=RandUniform(low=0.1, high=1.0), high=RandUniform(low=100, high=1000)\n... )\n&gt;&gt;&gt; generator\nLogUniformTensorGenerator(\n  (low): RandUniformTensorGenerator(low=0.1, high=1.0)\n  (high): RandUniformTensorGenerator(low=100.0, high=1000.0)\n)\n&gt;&gt;&gt; generator.generate((2, 6))\ntensor([[...]])\n</code></pre>"},{"location":"refs/tensor/#startorch.tensor.Long","title":"startorch.tensor.Long","text":"<p>               Bases: <code>BaseWrapperTensorGenerator</code></p> <p>Implement a sequence generator that converts a tensor values to long.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.tensor import Long, RandUniform\n&gt;&gt;&gt; generator = Long(RandUniform(low=0, high=10))\n&gt;&gt;&gt; generator\nLongTensorGenerator(\n  (tensor): RandUniformTensorGenerator(low=0.0, high=10.0)\n)\n&gt;&gt;&gt; generator.generate((2, 6))\ntensor([[...]])\n</code></pre>"},{"location":"refs/tensor/#startorch.tensor.LongTensorGenerator","title":"startorch.tensor.LongTensorGenerator","text":"<p>               Bases: <code>BaseWrapperTensorGenerator</code></p> <p>Implement a sequence generator that converts a tensor values to long.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.tensor import Long, RandUniform\n&gt;&gt;&gt; generator = Long(RandUniform(low=0, high=10))\n&gt;&gt;&gt; generator\nLongTensorGenerator(\n  (tensor): RandUniformTensorGenerator(low=0.0, high=10.0)\n)\n&gt;&gt;&gt; generator.generate((2, 6))\ntensor([[...]])\n</code></pre>"},{"location":"refs/tensor/#startorch.tensor.Mul","title":"startorch.tensor.Mul","text":"<p>               Bases: <code>BaseTensorGenerator</code></p> <p>Implement a tensor generator that multiplies multiple tensors.</p> <p>This tensor generator is equivalent to: <code>output = tensor_1 * tensor_2 * ... * tensor_n</code></p> <p>Parameters:</p> Name Type Description Default <code>generators</code> <code>Sequence[BaseTensorGenerator | dict]</code> <p>The tensor generators.</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>if no sequence generator is provided.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; from startorch.tensor import Mul, RandUniform, RandNormal\n&gt;&gt;&gt; generator = Mul([RandUniform(), RandNormal()])\n&gt;&gt;&gt; generator\nMulTensorGenerator(\n  (0): RandUniformTensorGenerator(low=0.0, high=1.0)\n  (1): RandNormalTensorGenerator(mean=0.0, std=1.0)\n)\n&gt;&gt;&gt; generator.generate((2, 6))\ntensor([[...]])\n</code></pre>"},{"location":"refs/tensor/#startorch.tensor.MulScalar","title":"startorch.tensor.MulScalar","text":"<p>               Bases: <code>BaseWrapperTensorGenerator</code></p> <p>Implement a tensor generator that multiplies a scalar value to a generated batch of tensors.</p> <p>This tensor generator is equivalent to: <code>output = tensor * scalar</code></p> <p>Parameters:</p> Name Type Description Default <code>generator</code> <code>BaseTensorGenerator | dict</code> <p>The tensor generator or its configuration.</p> required <code>value</code> <code>float</code> <p>The scalar value to multiply.</p> required <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; from startorch.tensor import MulScalar, RandUniform, RandNormal\n&gt;&gt;&gt; generator = MulScalar(RandUniform(), 42)\n&gt;&gt;&gt; generator\nMulScalarTensorGenerator(\n  (tensor): RandUniformTensorGenerator(low=0.0, high=1.0)\n)\n&gt;&gt;&gt; generator.generate((2, 6))\ntensor([[...]])\n</code></pre>"},{"location":"refs/tensor/#startorch.tensor.MulScalarTensorGenerator","title":"startorch.tensor.MulScalarTensorGenerator","text":"<p>               Bases: <code>BaseWrapperTensorGenerator</code></p> <p>Implement a tensor generator that multiplies a scalar value to a generated batch of tensors.</p> <p>This tensor generator is equivalent to: <code>output = tensor * scalar</code></p> <p>Parameters:</p> Name Type Description Default <code>generator</code> <code>BaseTensorGenerator | dict</code> <p>The tensor generator or its configuration.</p> required <code>value</code> <code>float</code> <p>The scalar value to multiply.</p> required <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; from startorch.tensor import MulScalar, RandUniform, RandNormal\n&gt;&gt;&gt; generator = MulScalar(RandUniform(), 42)\n&gt;&gt;&gt; generator\nMulScalarTensorGenerator(\n  (tensor): RandUniformTensorGenerator(low=0.0, high=1.0)\n)\n&gt;&gt;&gt; generator.generate((2, 6))\ntensor([[...]])\n</code></pre>"},{"location":"refs/tensor/#startorch.tensor.MulTensorGenerator","title":"startorch.tensor.MulTensorGenerator","text":"<p>               Bases: <code>BaseTensorGenerator</code></p> <p>Implement a tensor generator that multiplies multiple tensors.</p> <p>This tensor generator is equivalent to: <code>output = tensor_1 * tensor_2 * ... * tensor_n</code></p> <p>Parameters:</p> Name Type Description Default <code>generators</code> <code>Sequence[BaseTensorGenerator | dict]</code> <p>The tensor generators.</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>if no sequence generator is provided.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; from startorch.tensor import Mul, RandUniform, RandNormal\n&gt;&gt;&gt; generator = Mul([RandUniform(), RandNormal()])\n&gt;&gt;&gt; generator\nMulTensorGenerator(\n  (0): RandUniformTensorGenerator(low=0.0, high=1.0)\n  (1): RandNormalTensorGenerator(mean=0.0, std=1.0)\n)\n&gt;&gt;&gt; generator.generate((2, 6))\ntensor([[...]])\n</code></pre>"},{"location":"refs/tensor/#startorch.tensor.Multinomial","title":"startorch.tensor.Multinomial","text":"<p>               Bases: <code>BaseTensorGenerator</code></p> <p>Implement a class to generate tensors of categorical variables where each value is sampled from a multinomial distribution.</p> <p>Parameters:</p> Name Type Description Default <code>weights</code> <code>Tensor | Sequence[float]</code> <p>The vector of weights associated at each category. It must be a float tensor of shape <code>(num_categories,)</code>. The weights have to be positive but do not need to sum to 1.</p> required <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; from startorch.tensor import Multinomial\n&gt;&gt;&gt; generator = Multinomial(torch.ones(10))\n&gt;&gt;&gt; generator\nMultinomialTensorGenerator(num_categories=10)\n&gt;&gt;&gt; generator.generate(size=(4, 12))\ntensor([[...]])\n</code></pre>"},{"location":"refs/tensor/#startorch.tensor.Multinomial.create_exp_weights","title":"startorch.tensor.Multinomial.create_exp_weights  <code>classmethod</code>","text":"<pre><code>create_exp_weights(\n    num_categories: int, scale: float = 0.1\n) -&gt; MultinomialTensorGenerator\n</code></pre> <p>Instantiate the weights with an exponential pattern.</p> <p>The weight of the <code>i</code>-th category (<code>w_i</code>) is generated with the rule: <code>w_i = exp(-scale * i)</code></p> <p>Parameters:</p> Name Type Description Default <code>num_categories</code> <code>int</code> <p>The number of categories.</p> required <code>scale</code> <code>float</code> <p>The scale parameter that controls the exponential function.</p> <code>0.1</code> <p>Returns:</p> Type Description <code>MultinomialTensorGenerator</code> <p>A tensor generator where the weights of the multinomial distribution follow an exponential pattern.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; from startorch.tensor import Multinomial\n&gt;&gt;&gt; generator = Multinomial.create_exp_weights(10)\n&gt;&gt;&gt; generator\nMultinomialTensorGenerator(num_categories=10)\n&gt;&gt;&gt; generator.generate(size=(4, 12))\ntensor([[...]])\n</code></pre>"},{"location":"refs/tensor/#startorch.tensor.Multinomial.create_linear_weights","title":"startorch.tensor.Multinomial.create_linear_weights  <code>classmethod</code>","text":"<pre><code>create_linear_weights(\n    num_categories: int,\n) -&gt; MultinomialTensorGenerator\n</code></pre> <p>Instantiate the weights with a linear pattern.</p> <p>The weight of the <code>i</code>-th category (<code>w_i</code>) is generated with the rule: <code>w_i = num_categories - i</code></p> <p>Parameters:</p> Name Type Description Default <code>num_categories</code> <code>int</code> <p>The number of categories.</p> required <p>Returns:</p> Type Description <code>MultinomialTensorGenerator</code> <p>A tensor generator where the weights of the multinomial distribution follow a linear pattern.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; from startorch.tensor import Multinomial\n&gt;&gt;&gt; generator = Multinomial.create_linear_weights(10)\n&gt;&gt;&gt; generator\nMultinomialTensorGenerator(num_categories=10)\n&gt;&gt;&gt; generator.generate(size=(4, 12))\ntensor([[...]])\n</code></pre>"},{"location":"refs/tensor/#startorch.tensor.Multinomial.create_uniform_weights","title":"startorch.tensor.Multinomial.create_uniform_weights  <code>classmethod</code>","text":"<pre><code>create_uniform_weights(\n    num_categories: int,\n) -&gt; MultinomialTensorGenerator\n</code></pre> <p>Instantiate the weights with a uniform pattern.</p> <p>All the categories have the same probability. The weight of the <code>i</code>-th category (<code>w_i</code>) is generated with the rule: <code>w_i = 1</code></p> <p>Parameters:</p> Name Type Description Default <code>num_categories</code> <code>int</code> <p>The number of categories.</p> required <p>Returns:</p> Type Description <code>MultinomialTensorGenerator</code> <p>A tensor generator where the weights of the multinomial distribution follow a uniform pattern.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; from startorch.tensor import Multinomial\n&gt;&gt;&gt; generator = Multinomial.create_uniform_weights(10)\n&gt;&gt;&gt; generator\nMultinomialTensorGenerator(num_categories=10)\n&gt;&gt;&gt; generator.generate(size=(4, 12))\ntensor([[...]])\n</code></pre>"},{"location":"refs/tensor/#startorch.tensor.MultinomialChoice","title":"startorch.tensor.MultinomialChoice","text":"<p>               Bases: <code>BaseTensorGenerator</code></p> <p>Implement a tensor generator that select a tensor generator at each batch.</p> <p>This tensor generator is used to generate tensors with different generation processes. The user can specify a list of tensor generators with an associated weight. The weight is used to sample the tensor generator with a multinomial distribution. Higher weight means that the tensor generator has a higher probability to be selected at each batch. Each dictionary in the <code>generators</code> input should have the following items:</p> <pre><code>- a key ``'generator'`` which indicates the tensor generator\n    or its configuration.\n- an optional key ``'weight'`` with a float value which\n    indicates the weight of the tensor generator.\n    If this key is absent, the weight is set to ``1.0``.\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>generators</code> <code>Sequence[dict[str, BaseTensorGenerator | dict]]</code> <p>The tensor generators and their weights. See above to learn about the expected format.</p> required <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.tensor import MultinomialChoice, RandUniform, RandNormal\n&gt;&gt;&gt; generator = MultinomialChoice(\n...     (\n...         {\"weight\": 2.0, \"generator\": RandUniform()},\n...         {\"weight\": 1.0, \"generator\": RandNormal()},\n...     )\n... )\n&gt;&gt;&gt; generator\nMultinomialChoiceTensorGenerator(\n  (0) [weight=2.0] RandUniformTensorGenerator(low=0.0, high=1.0)\n  (1) [weight=1.0] RandNormalTensorGenerator(mean=0.0, std=1.0)\n)\n&gt;&gt;&gt; generator.generate(size=(4, 12))\ntensor([[...]])\n</code></pre>"},{"location":"refs/tensor/#startorch.tensor.MultinomialChoiceTensorGenerator","title":"startorch.tensor.MultinomialChoiceTensorGenerator","text":"<p>               Bases: <code>BaseTensorGenerator</code></p> <p>Implement a tensor generator that select a tensor generator at each batch.</p> <p>This tensor generator is used to generate tensors with different generation processes. The user can specify a list of tensor generators with an associated weight. The weight is used to sample the tensor generator with a multinomial distribution. Higher weight means that the tensor generator has a higher probability to be selected at each batch. Each dictionary in the <code>generators</code> input should have the following items:</p> <pre><code>- a key ``'generator'`` which indicates the tensor generator\n    or its configuration.\n- an optional key ``'weight'`` with a float value which\n    indicates the weight of the tensor generator.\n    If this key is absent, the weight is set to ``1.0``.\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>generators</code> <code>Sequence[dict[str, BaseTensorGenerator | dict]]</code> <p>The tensor generators and their weights. See above to learn about the expected format.</p> required <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.tensor import MultinomialChoice, RandUniform, RandNormal\n&gt;&gt;&gt; generator = MultinomialChoice(\n...     (\n...         {\"weight\": 2.0, \"generator\": RandUniform()},\n...         {\"weight\": 1.0, \"generator\": RandNormal()},\n...     )\n... )\n&gt;&gt;&gt; generator\nMultinomialChoiceTensorGenerator(\n  (0) [weight=2.0] RandUniformTensorGenerator(low=0.0, high=1.0)\n  (1) [weight=1.0] RandNormalTensorGenerator(mean=0.0, std=1.0)\n)\n&gt;&gt;&gt; generator.generate(size=(4, 12))\ntensor([[...]])\n</code></pre>"},{"location":"refs/tensor/#startorch.tensor.MultinomialTensorGenerator","title":"startorch.tensor.MultinomialTensorGenerator","text":"<p>               Bases: <code>BaseTensorGenerator</code></p> <p>Implement a class to generate tensors of categorical variables where each value is sampled from a multinomial distribution.</p> <p>Parameters:</p> Name Type Description Default <code>weights</code> <code>Tensor | Sequence[float]</code> <p>The vector of weights associated at each category. It must be a float tensor of shape <code>(num_categories,)</code>. The weights have to be positive but do not need to sum to 1.</p> required <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; from startorch.tensor import Multinomial\n&gt;&gt;&gt; generator = Multinomial(torch.ones(10))\n&gt;&gt;&gt; generator\nMultinomialTensorGenerator(num_categories=10)\n&gt;&gt;&gt; generator.generate(size=(4, 12))\ntensor([[...]])\n</code></pre>"},{"location":"refs/tensor/#startorch.tensor.MultinomialTensorGenerator.create_exp_weights","title":"startorch.tensor.MultinomialTensorGenerator.create_exp_weights  <code>classmethod</code>","text":"<pre><code>create_exp_weights(\n    num_categories: int, scale: float = 0.1\n) -&gt; MultinomialTensorGenerator\n</code></pre> <p>Instantiate the weights with an exponential pattern.</p> <p>The weight of the <code>i</code>-th category (<code>w_i</code>) is generated with the rule: <code>w_i = exp(-scale * i)</code></p> <p>Parameters:</p> Name Type Description Default <code>num_categories</code> <code>int</code> <p>The number of categories.</p> required <code>scale</code> <code>float</code> <p>The scale parameter that controls the exponential function.</p> <code>0.1</code> <p>Returns:</p> Type Description <code>MultinomialTensorGenerator</code> <p>A tensor generator where the weights of the multinomial distribution follow an exponential pattern.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; from startorch.tensor import Multinomial\n&gt;&gt;&gt; generator = Multinomial.create_exp_weights(10)\n&gt;&gt;&gt; generator\nMultinomialTensorGenerator(num_categories=10)\n&gt;&gt;&gt; generator.generate(size=(4, 12))\ntensor([[...]])\n</code></pre>"},{"location":"refs/tensor/#startorch.tensor.MultinomialTensorGenerator.create_linear_weights","title":"startorch.tensor.MultinomialTensorGenerator.create_linear_weights  <code>classmethod</code>","text":"<pre><code>create_linear_weights(\n    num_categories: int,\n) -&gt; MultinomialTensorGenerator\n</code></pre> <p>Instantiate the weights with a linear pattern.</p> <p>The weight of the <code>i</code>-th category (<code>w_i</code>) is generated with the rule: <code>w_i = num_categories - i</code></p> <p>Parameters:</p> Name Type Description Default <code>num_categories</code> <code>int</code> <p>The number of categories.</p> required <p>Returns:</p> Type Description <code>MultinomialTensorGenerator</code> <p>A tensor generator where the weights of the multinomial distribution follow a linear pattern.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; from startorch.tensor import Multinomial\n&gt;&gt;&gt; generator = Multinomial.create_linear_weights(10)\n&gt;&gt;&gt; generator\nMultinomialTensorGenerator(num_categories=10)\n&gt;&gt;&gt; generator.generate(size=(4, 12))\ntensor([[...]])\n</code></pre>"},{"location":"refs/tensor/#startorch.tensor.MultinomialTensorGenerator.create_uniform_weights","title":"startorch.tensor.MultinomialTensorGenerator.create_uniform_weights  <code>classmethod</code>","text":"<pre><code>create_uniform_weights(\n    num_categories: int,\n) -&gt; MultinomialTensorGenerator\n</code></pre> <p>Instantiate the weights with a uniform pattern.</p> <p>All the categories have the same probability. The weight of the <code>i</code>-th category (<code>w_i</code>) is generated with the rule: <code>w_i = 1</code></p> <p>Parameters:</p> Name Type Description Default <code>num_categories</code> <code>int</code> <p>The number of categories.</p> required <p>Returns:</p> Type Description <code>MultinomialTensorGenerator</code> <p>A tensor generator where the weights of the multinomial distribution follow a uniform pattern.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; from startorch.tensor import Multinomial\n&gt;&gt;&gt; generator = Multinomial.create_uniform_weights(10)\n&gt;&gt;&gt; generator\nMultinomialTensorGenerator(num_categories=10)\n&gt;&gt;&gt; generator.generate(size=(4, 12))\ntensor([[...]])\n</code></pre>"},{"location":"refs/tensor/#startorch.tensor.Neg","title":"startorch.tensor.Neg","text":"<p>               Bases: <code>BaseWrapperTensorGenerator</code></p> <p>Implement a tensor generator that computes the negation of a generated tensor.</p> <p>This tensor generator is equivalent to: <code>output = -tensor</code></p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; from startorch.tensor import Neg, RandNormal\n&gt;&gt;&gt; generator = Neg(RandNormal())\n&gt;&gt;&gt; generator\nNegTensorGenerator(\n  (tensor): RandNormalTensorGenerator(mean=0.0, std=1.0)\n)\n&gt;&gt;&gt; generator.generate((2, 6))\ntensor([[...]])\n</code></pre>"},{"location":"refs/tensor/#startorch.tensor.NegTensorGenerator","title":"startorch.tensor.NegTensorGenerator","text":"<p>               Bases: <code>BaseWrapperTensorGenerator</code></p> <p>Implement a tensor generator that computes the negation of a generated tensor.</p> <p>This tensor generator is equivalent to: <code>output = -tensor</code></p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; from startorch.tensor import Neg, RandNormal\n&gt;&gt;&gt; generator = Neg(RandNormal())\n&gt;&gt;&gt; generator\nNegTensorGenerator(\n  (tensor): RandNormalTensorGenerator(mean=0.0, std=1.0)\n)\n&gt;&gt;&gt; generator.generate((2, 6))\ntensor([[...]])\n</code></pre>"},{"location":"refs/tensor/#startorch.tensor.Normal","title":"startorch.tensor.Normal","text":"<p>               Bases: <code>BaseTensorGenerator</code></p> <p>Implement a class to generate sequence by sampling values from a Normal distribution.</p> <p>Parameters:</p> Name Type Description Default <code>mean</code> <code>BaseTensorGenerator | dict</code> <p>A tensor generator (or its configuration) to generate the mean.</p> required <code>std</code> <code>BaseTensorGenerator | dict</code> <p>A tensor generator (or its configuration) to generate the standard deviation.</p> required <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.tensor import Normal, RandUniform\n&gt;&gt;&gt; generator = Normal(\n...     mean=RandUniform(low=-1.0, high=1.0), std=RandUniform(low=1.0, high=2.0)\n... )\n&gt;&gt;&gt; generator\nNormalTensorGenerator(\n  (mean): RandUniformTensorGenerator(low=-1.0, high=1.0)\n  (std): RandUniformTensorGenerator(low=1.0, high=2.0)\n)\n&gt;&gt;&gt; generator.generate((2, 6))\ntensor([[...]])\n</code></pre>"},{"location":"refs/tensor/#startorch.tensor.NormalTensorGenerator","title":"startorch.tensor.NormalTensorGenerator","text":"<p>               Bases: <code>BaseTensorGenerator</code></p> <p>Implement a class to generate sequence by sampling values from a Normal distribution.</p> <p>Parameters:</p> Name Type Description Default <code>mean</code> <code>BaseTensorGenerator | dict</code> <p>A tensor generator (or its configuration) to generate the mean.</p> required <code>std</code> <code>BaseTensorGenerator | dict</code> <p>A tensor generator (or its configuration) to generate the standard deviation.</p> required <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.tensor import Normal, RandUniform\n&gt;&gt;&gt; generator = Normal(\n...     mean=RandUniform(low=-1.0, high=1.0), std=RandUniform(low=1.0, high=2.0)\n... )\n&gt;&gt;&gt; generator\nNormalTensorGenerator(\n  (mean): RandUniformTensorGenerator(low=-1.0, high=1.0)\n  (std): RandUniformTensorGenerator(low=1.0, high=2.0)\n)\n&gt;&gt;&gt; generator.generate((2, 6))\ntensor([[...]])\n</code></pre>"},{"location":"refs/tensor/#startorch.tensor.Poisson","title":"startorch.tensor.Poisson","text":"<p>               Bases: <code>BaseTensorGenerator</code></p> <p>Implement a class to generate tensors by sampling values from a Poisson distribution.</p> <p>The rates of the Poisson distribution are generated by the rate generator. The rate generator should return the rate for each value in the tensor. The rate values should be greater than 0.</p> <p>Parameters:</p> Name Type Description Default <code>rate</code> <code>BaseTensorGenerator | dict</code> <p>The rate generator or its configuration. The rate generator should return valid rate values.</p> required <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.tensor import RandUniform, Poisson\n&gt;&gt;&gt; generator = Poisson(rate=RandUniform(low=1.0, high=2.0))\n&gt;&gt;&gt; generator\nPoissonTensorGenerator(\n  (rate): RandUniformTensorGenerator(low=1.0, high=2.0)\n)\n&gt;&gt;&gt; generator.generate((2, 6))\ntensor([[...]])\n</code></pre>"},{"location":"refs/tensor/#startorch.tensor.PoissonTensorGenerator","title":"startorch.tensor.PoissonTensorGenerator","text":"<p>               Bases: <code>BaseTensorGenerator</code></p> <p>Implement a class to generate tensors by sampling values from a Poisson distribution.</p> <p>The rates of the Poisson distribution are generated by the rate generator. The rate generator should return the rate for each value in the tensor. The rate values should be greater than 0.</p> <p>Parameters:</p> Name Type Description Default <code>rate</code> <code>BaseTensorGenerator | dict</code> <p>The rate generator or its configuration. The rate generator should return valid rate values.</p> required <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.tensor import RandUniform, Poisson\n&gt;&gt;&gt; generator = Poisson(rate=RandUniform(low=1.0, high=2.0))\n&gt;&gt;&gt; generator\nPoissonTensorGenerator(\n  (rate): RandUniformTensorGenerator(low=1.0, high=2.0)\n)\n&gt;&gt;&gt; generator.generate((2, 6))\ntensor([[...]])\n</code></pre>"},{"location":"refs/tensor/#startorch.tensor.RandAsinhUniform","title":"startorch.tensor.RandAsinhUniform","text":"<p>               Bases: <code>BaseTensorGenerator</code></p> <p>Implement a tensor generator by sampling values from an asinh- uniform distribution.</p> <p>Parameters:</p> Name Type Description Default <code>low</code> <code>float</code> <p>The minimum value (inclusive).</p> required <code>high</code> <code>float</code> <p>The maximum value (exclusive).</p> required <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.tensor import RandAsinhUniform\n&gt;&gt;&gt; generator = RandAsinhUniform(low=-1000, high=1000)\n&gt;&gt;&gt; generator\nRandAsinhUniformTensorGenerator(low=-1000.0, high=1000.0)\n&gt;&gt;&gt; generator.generate((2, 6))\ntensor([[...]])\n</code></pre>"},{"location":"refs/tensor/#startorch.tensor.RandAsinhUniformTensorGenerator","title":"startorch.tensor.RandAsinhUniformTensorGenerator","text":"<p>               Bases: <code>BaseTensorGenerator</code></p> <p>Implement a tensor generator by sampling values from an asinh- uniform distribution.</p> <p>Parameters:</p> Name Type Description Default <code>low</code> <code>float</code> <p>The minimum value (inclusive).</p> required <code>high</code> <code>float</code> <p>The maximum value (exclusive).</p> required <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.tensor import RandAsinhUniform\n&gt;&gt;&gt; generator = RandAsinhUniform(low=-1000, high=1000)\n&gt;&gt;&gt; generator\nRandAsinhUniformTensorGenerator(low=-1000.0, high=1000.0)\n&gt;&gt;&gt; generator.generate((2, 6))\ntensor([[...]])\n</code></pre>"},{"location":"refs/tensor/#startorch.tensor.RandCauchy","title":"startorch.tensor.RandCauchy","text":"<p>               Bases: <code>BaseTensorGenerator</code></p> <p>Implement a class to generate tensor by sampling values from a Cauchy distribution.</p> <p>Parameters:</p> Name Type Description Default <code>loc</code> <code>float</code> <p>The location/median of the Cauchy distribution.</p> <code>0.0</code> <code>scale</code> <code>float</code> <p>The scale of the distribution.</p> <code>1.0</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>if <code>scale</code> is not a positive number.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.tensor import RandCauchy\n&gt;&gt;&gt; generator = RandCauchy(loc=0.0, scale=1.0)\n&gt;&gt;&gt; generator\nRandCauchyTensorGenerator(loc=0.0, scale=1.0)\n&gt;&gt;&gt; generator.generate((2, 6))\ntensor([[...]])\n</code></pre>"},{"location":"refs/tensor/#startorch.tensor.RandCauchyTensorGenerator","title":"startorch.tensor.RandCauchyTensorGenerator","text":"<p>               Bases: <code>BaseTensorGenerator</code></p> <p>Implement a class to generate tensor by sampling values from a Cauchy distribution.</p> <p>Parameters:</p> Name Type Description Default <code>loc</code> <code>float</code> <p>The location/median of the Cauchy distribution.</p> <code>0.0</code> <code>scale</code> <code>float</code> <p>The scale of the distribution.</p> <code>1.0</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>if <code>scale</code> is not a positive number.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.tensor import RandCauchy\n&gt;&gt;&gt; generator = RandCauchy(loc=0.0, scale=1.0)\n&gt;&gt;&gt; generator\nRandCauchyTensorGenerator(loc=0.0, scale=1.0)\n&gt;&gt;&gt; generator.generate((2, 6))\ntensor([[...]])\n</code></pre>"},{"location":"refs/tensor/#startorch.tensor.RandExponential","title":"startorch.tensor.RandExponential","text":"<p>               Bases: <code>BaseTensorGenerator</code></p> <p>Implement a class to generate sequences by sampling values from an Exponential distribution.</p> <p>Parameters:</p> Name Type Description Default <code>rate</code> <code>float</code> <p>The rate of the Exponential distribution.</p> <code>1.0</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>if <code>rate</code> is not a positive number.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.tensor import RandExponential\n&gt;&gt;&gt; generator = RandExponential(rate=1.0)\n&gt;&gt;&gt; generator\nRandExponentialTensorGenerator(rate=1.0)\n&gt;&gt;&gt; generator.generate((2, 6))\ntensor([[...]])\n</code></pre>"},{"location":"refs/tensor/#startorch.tensor.RandExponentialTensorGenerator","title":"startorch.tensor.RandExponentialTensorGenerator","text":"<p>               Bases: <code>BaseTensorGenerator</code></p> <p>Implement a class to generate sequences by sampling values from an Exponential distribution.</p> <p>Parameters:</p> Name Type Description Default <code>rate</code> <code>float</code> <p>The rate of the Exponential distribution.</p> <code>1.0</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>if <code>rate</code> is not a positive number.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.tensor import RandExponential\n&gt;&gt;&gt; generator = RandExponential(rate=1.0)\n&gt;&gt;&gt; generator\nRandExponentialTensorGenerator(rate=1.0)\n&gt;&gt;&gt; generator.generate((2, 6))\ntensor([[...]])\n</code></pre>"},{"location":"refs/tensor/#startorch.tensor.RandHalfCauchy","title":"startorch.tensor.RandHalfCauchy","text":"<p>               Bases: <code>BaseTensorGenerator</code></p> <p>Implement a class to generate tensor by sampling values from a half-Cauchy distribution.</p> <p>Parameters:</p> Name Type Description Default <code>scale</code> <code>float</code> <p>The scale of the distribution.</p> <code>1.0</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>if <code>scale</code> is not a positive number.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.tensor import RandHalfCauchy\n&gt;&gt;&gt; generator = RandHalfCauchy(scale=1.0)\n&gt;&gt;&gt; generator\nRandHalfCauchyTensorGenerator(scale=1.0)\n&gt;&gt;&gt; generator.generate((2, 6))\ntensor([[...]])\n</code></pre>"},{"location":"refs/tensor/#startorch.tensor.RandHalfCauchyTensorGenerator","title":"startorch.tensor.RandHalfCauchyTensorGenerator","text":"<p>               Bases: <code>BaseTensorGenerator</code></p> <p>Implement a class to generate tensor by sampling values from a half-Cauchy distribution.</p> <p>Parameters:</p> Name Type Description Default <code>scale</code> <code>float</code> <p>The scale of the distribution.</p> <code>1.0</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>if <code>scale</code> is not a positive number.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.tensor import RandHalfCauchy\n&gt;&gt;&gt; generator = RandHalfCauchy(scale=1.0)\n&gt;&gt;&gt; generator\nRandHalfCauchyTensorGenerator(scale=1.0)\n&gt;&gt;&gt; generator.generate((2, 6))\ntensor([[...]])\n</code></pre>"},{"location":"refs/tensor/#startorch.tensor.RandHalfNormal","title":"startorch.tensor.RandHalfNormal","text":"<p>               Bases: <code>BaseTensorGenerator</code></p> <p>Implement a class to generate tensor by sampling values from a half-Normal distribution.</p> <p>Parameters:</p> Name Type Description Default <code>std</code> <code>float</code> <p>The std of the distribution.</p> <code>1.0</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>if <code>std</code> is not a positive number.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.tensor import RandHalfNormal\n&gt;&gt;&gt; generator = RandHalfNormal(std=1.0)\n&gt;&gt;&gt; generator\nRandHalfNormalTensorGenerator(std=1.0)\n&gt;&gt;&gt; generator.generate(size=(2, 6))\ntensor([[...]])\n</code></pre>"},{"location":"refs/tensor/#startorch.tensor.RandHalfNormalTensorGenerator","title":"startorch.tensor.RandHalfNormalTensorGenerator","text":"<p>               Bases: <code>BaseTensorGenerator</code></p> <p>Implement a class to generate tensor by sampling values from a half-Normal distribution.</p> <p>Parameters:</p> Name Type Description Default <code>std</code> <code>float</code> <p>The std of the distribution.</p> <code>1.0</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>if <code>std</code> is not a positive number.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.tensor import RandHalfNormal\n&gt;&gt;&gt; generator = RandHalfNormal(std=1.0)\n&gt;&gt;&gt; generator\nRandHalfNormalTensorGenerator(std=1.0)\n&gt;&gt;&gt; generator.generate(size=(2, 6))\ntensor([[...]])\n</code></pre>"},{"location":"refs/tensor/#startorch.tensor.RandInt","title":"startorch.tensor.RandInt","text":"<p>               Bases: <code>BaseTensorGenerator</code></p> <p>Implement a tensor generator by sampling integer values from a uniform distribution.</p> <p>Parameters:</p> Name Type Description Default <code>low</code> <code>int</code> <p>The minimum value (inclusive).</p> required <code>high</code> <code>int</code> <p>The maximum value (exclusive).</p> required <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.tensor import RandInt\n&gt;&gt;&gt; generator = RandInt(low=0, high=10)\n&gt;&gt;&gt; generator\nRandIntTensorGenerator(low=0, high=10)\n&gt;&gt;&gt; generator.generate((2, 6))\ntensor([[...]])\n</code></pre>"},{"location":"refs/tensor/#startorch.tensor.RandIntTensorGenerator","title":"startorch.tensor.RandIntTensorGenerator","text":"<p>               Bases: <code>BaseTensorGenerator</code></p> <p>Implement a tensor generator by sampling integer values from a uniform distribution.</p> <p>Parameters:</p> Name Type Description Default <code>low</code> <code>int</code> <p>The minimum value (inclusive).</p> required <code>high</code> <code>int</code> <p>The maximum value (exclusive).</p> required <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.tensor import RandInt\n&gt;&gt;&gt; generator = RandInt(low=0, high=10)\n&gt;&gt;&gt; generator\nRandIntTensorGenerator(low=0, high=10)\n&gt;&gt;&gt; generator.generate((2, 6))\ntensor([[...]])\n</code></pre>"},{"location":"refs/tensor/#startorch.tensor.RandLogNormal","title":"startorch.tensor.RandLogNormal","text":"<p>               Bases: <code>BaseTensorGenerator</code></p> <p>Implement a class to generate tensor by sampling values from a log-Normal distribution.</p> <p>Parameters:</p> Name Type Description Default <code>mean</code> <code>float</code> <p>The mean of the underlying Normal distribution.</p> <code>0.0</code> <code>std</code> <code>float</code> <p>The standard deviation of the underlying Normal distribution.</p> <code>1.0</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>if <code>std</code> is not a positive number.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.tensor import RandLogNormal\n&gt;&gt;&gt; generator = RandLogNormal(mean=0.0, std=1.0)\n&gt;&gt;&gt; generator\nRandLogNormalTensorGenerator(mean=0.0, std=1.0)\n&gt;&gt;&gt; generator.generate(size=(2, 6))\ntensor([[...]])\n</code></pre>"},{"location":"refs/tensor/#startorch.tensor.RandLogNormalTensorGenerator","title":"startorch.tensor.RandLogNormalTensorGenerator","text":"<p>               Bases: <code>BaseTensorGenerator</code></p> <p>Implement a class to generate tensor by sampling values from a log-Normal distribution.</p> <p>Parameters:</p> Name Type Description Default <code>mean</code> <code>float</code> <p>The mean of the underlying Normal distribution.</p> <code>0.0</code> <code>std</code> <code>float</code> <p>The standard deviation of the underlying Normal distribution.</p> <code>1.0</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>if <code>std</code> is not a positive number.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.tensor import RandLogNormal\n&gt;&gt;&gt; generator = RandLogNormal(mean=0.0, std=1.0)\n&gt;&gt;&gt; generator\nRandLogNormalTensorGenerator(mean=0.0, std=1.0)\n&gt;&gt;&gt; generator.generate(size=(2, 6))\ntensor([[...]])\n</code></pre>"},{"location":"refs/tensor/#startorch.tensor.RandLogUniform","title":"startorch.tensor.RandLogUniform","text":"<p>               Bases: <code>BaseTensorGenerator</code></p> <p>Implement a tensor generator to generate tensors by sampling values from a log-uniform distribution.</p> <p>Parameters:</p> Name Type Description Default <code>low</code> <code>float</code> <p>The minimum value (inclusive).</p> required <code>high</code> <code>float</code> <p>The maximum value (exclusive).</p> required <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.tensor import RandLogUniform\n&gt;&gt;&gt; generator = RandLogUniform(low=0.1, high=100.0)\n&gt;&gt;&gt; generator\nRandLogUniformTensorGenerator(low=0.1, high=100.0)\n&gt;&gt;&gt; generator.generate((2, 6))\ntensor([[...]])\n</code></pre>"},{"location":"refs/tensor/#startorch.tensor.RandLogUniformTensorGenerator","title":"startorch.tensor.RandLogUniformTensorGenerator","text":"<p>               Bases: <code>BaseTensorGenerator</code></p> <p>Implement a tensor generator to generate tensors by sampling values from a log-uniform distribution.</p> <p>Parameters:</p> Name Type Description Default <code>low</code> <code>float</code> <p>The minimum value (inclusive).</p> required <code>high</code> <code>float</code> <p>The maximum value (exclusive).</p> required <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.tensor import RandLogUniform\n&gt;&gt;&gt; generator = RandLogUniform(low=0.1, high=100.0)\n&gt;&gt;&gt; generator\nRandLogUniformTensorGenerator(low=0.1, high=100.0)\n&gt;&gt;&gt; generator.generate((2, 6))\ntensor([[...]])\n</code></pre>"},{"location":"refs/tensor/#startorch.tensor.RandNormal","title":"startorch.tensor.RandNormal","text":"<p>               Bases: <code>BaseTensorGenerator</code></p> <p>Implement a sequence generator to generate cyclic sequences by sampling values from a Normal distribution.</p> <p>Parameters:</p> Name Type Description Default <code>mean</code> <code>float</code> <p>The mean of the Normal distribution.</p> <code>0.0</code> <code>std</code> <code>float</code> <p>The standard deviation of the Normal distribution.</p> <code>1.0</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>if <code>std</code> is not a postive number.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.tensor import RandNormal\n&gt;&gt;&gt; generator = RandNormal(mean=0.0, std=1.0)\n&gt;&gt;&gt; generator\nRandNormalTensorGenerator(mean=0.0, std=1.0)\n&gt;&gt;&gt; generator.generate((2, 6))\ntensor([[...]])\n</code></pre>"},{"location":"refs/tensor/#startorch.tensor.RandNormalTensorGenerator","title":"startorch.tensor.RandNormalTensorGenerator","text":"<p>               Bases: <code>BaseTensorGenerator</code></p> <p>Implement a sequence generator to generate cyclic sequences by sampling values from a Normal distribution.</p> <p>Parameters:</p> Name Type Description Default <code>mean</code> <code>float</code> <p>The mean of the Normal distribution.</p> <code>0.0</code> <code>std</code> <code>float</code> <p>The standard deviation of the Normal distribution.</p> <code>1.0</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>if <code>std</code> is not a postive number.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.tensor import RandNormal\n&gt;&gt;&gt; generator = RandNormal(mean=0.0, std=1.0)\n&gt;&gt;&gt; generator\nRandNormalTensorGenerator(mean=0.0, std=1.0)\n&gt;&gt;&gt; generator.generate((2, 6))\ntensor([[...]])\n</code></pre>"},{"location":"refs/tensor/#startorch.tensor.RandPoisson","title":"startorch.tensor.RandPoisson","text":"<p>               Bases: <code>BaseTensorGenerator</code></p> <p>Implement a class to generate tensors by sampling values from a Poisson distribution.</p> <p>Parameters:</p> Name Type Description Default <code>rate</code> <code>float</code> <p>The rate of the Poisson distribution. This value has to be greater than 0.</p> <code>1.0</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>if <code>rate</code> is not a positive number.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.tensor import RandPoisson\n&gt;&gt;&gt; generator = RandPoisson(rate=1.0)\n&gt;&gt;&gt; generator\nRandPoissonTensorGenerator(rate=1.0)\n&gt;&gt;&gt; generator.generate((2, 6))\ntensor([[...]])\n</code></pre>"},{"location":"refs/tensor/#startorch.tensor.RandPoissonTensorGenerator","title":"startorch.tensor.RandPoissonTensorGenerator","text":"<p>               Bases: <code>BaseTensorGenerator</code></p> <p>Implement a class to generate tensors by sampling values from a Poisson distribution.</p> <p>Parameters:</p> Name Type Description Default <code>rate</code> <code>float</code> <p>The rate of the Poisson distribution. This value has to be greater than 0.</p> <code>1.0</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>if <code>rate</code> is not a positive number.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.tensor import RandPoisson\n&gt;&gt;&gt; generator = RandPoisson(rate=1.0)\n&gt;&gt;&gt; generator\nRandPoissonTensorGenerator(rate=1.0)\n&gt;&gt;&gt; generator.generate((2, 6))\ntensor([[...]])\n</code></pre>"},{"location":"refs/tensor/#startorch.tensor.RandTruncCauchy","title":"startorch.tensor.RandTruncCauchy","text":"<p>               Bases: <code>BaseTensorGenerator</code></p> <p>Implement a class to generate tensor by sampling values from a truncated Cauchy distribution.</p> <p>Parameters:</p> Name Type Description Default <code>loc</code> <code>float</code> <p>The location/median of the Cauchy distribution.</p> <code>0.0</code> <code>scale</code> <code>float</code> <p>The scale of the distribution.</p> <code>1.0</code> <code>min_value</code> <code>float</code> <p>The minimum value (included).</p> <code>-2.0</code> <code>max_value</code> <code>float</code> <p>The maximum value (excluded).</p> <code>2.0</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>if <code>std</code> is not a positive number.</p> <code>ValueError</code> <p>if <code>max_value</code> is lower than <code>min_value</code>.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.tensor import RandTruncCauchy\n&gt;&gt;&gt; generator = RandTruncCauchy(loc=0.0, scale=1.0, min_value=-1.0, max_value=1.0)\n&gt;&gt;&gt; generator\nRandTruncCauchyTensorGenerator(loc=0.0, scale=1.0, min_value=-1.0, max_value=1.0)\n&gt;&gt;&gt; generator.generate((2, 6))\ntensor([[...]])\n</code></pre>"},{"location":"refs/tensor/#startorch.tensor.RandTruncCauchyTensorGenerator","title":"startorch.tensor.RandTruncCauchyTensorGenerator","text":"<p>               Bases: <code>BaseTensorGenerator</code></p> <p>Implement a class to generate tensor by sampling values from a truncated Cauchy distribution.</p> <p>Parameters:</p> Name Type Description Default <code>loc</code> <code>float</code> <p>The location/median of the Cauchy distribution.</p> <code>0.0</code> <code>scale</code> <code>float</code> <p>The scale of the distribution.</p> <code>1.0</code> <code>min_value</code> <code>float</code> <p>The minimum value (included).</p> <code>-2.0</code> <code>max_value</code> <code>float</code> <p>The maximum value (excluded).</p> <code>2.0</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>if <code>std</code> is not a positive number.</p> <code>ValueError</code> <p>if <code>max_value</code> is lower than <code>min_value</code>.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.tensor import RandTruncCauchy\n&gt;&gt;&gt; generator = RandTruncCauchy(loc=0.0, scale=1.0, min_value=-1.0, max_value=1.0)\n&gt;&gt;&gt; generator\nRandTruncCauchyTensorGenerator(loc=0.0, scale=1.0, min_value=-1.0, max_value=1.0)\n&gt;&gt;&gt; generator.generate((2, 6))\ntensor([[...]])\n</code></pre>"},{"location":"refs/tensor/#startorch.tensor.RandTruncExponential","title":"startorch.tensor.RandTruncExponential","text":"<p>               Bases: <code>BaseTensorGenerator</code></p> <p>Implement a class to generate sequences by sampling values from a truncated Exponential distribution.</p> <p>Parameters:</p> Name Type Description Default <code>rate</code> <code>float</code> <p>The rate of the Exponential distribution.</p> <code>1.0</code> <code>max_value</code> <code>float</code> <p>The maximum value.</p> <code>5.0</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>if <code>rate</code> is not a positive number.</p> <code>ValueError</code> <p>if <code>max_value</code> is not a positive number.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.tensor import RandTruncExponential\n&gt;&gt;&gt; generator = RandTruncExponential(rate=1.0, max_value=3.0)\n&gt;&gt;&gt; generator\nRandTruncExponentialTensorGenerator(rate=1.0, max_value=3.0)\n&gt;&gt;&gt; generator.generate((2, 6))\ntensor([[...]])\n</code></pre>"},{"location":"refs/tensor/#startorch.tensor.RandTruncExponentialTensorGenerator","title":"startorch.tensor.RandTruncExponentialTensorGenerator","text":"<p>               Bases: <code>BaseTensorGenerator</code></p> <p>Implement a class to generate sequences by sampling values from a truncated Exponential distribution.</p> <p>Parameters:</p> Name Type Description Default <code>rate</code> <code>float</code> <p>The rate of the Exponential distribution.</p> <code>1.0</code> <code>max_value</code> <code>float</code> <p>The maximum value.</p> <code>5.0</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>if <code>rate</code> is not a positive number.</p> <code>ValueError</code> <p>if <code>max_value</code> is not a positive number.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.tensor import RandTruncExponential\n&gt;&gt;&gt; generator = RandTruncExponential(rate=1.0, max_value=3.0)\n&gt;&gt;&gt; generator\nRandTruncExponentialTensorGenerator(rate=1.0, max_value=3.0)\n&gt;&gt;&gt; generator.generate((2, 6))\ntensor([[...]])\n</code></pre>"},{"location":"refs/tensor/#startorch.tensor.RandTruncHalfCauchy","title":"startorch.tensor.RandTruncHalfCauchy","text":"<p>               Bases: <code>BaseTensorGenerator</code></p> <p>Implement a class to generate tensor by sampling values from a truncated half-Cauchy distribution.</p> <p>Parameters:</p> Name Type Description Default <code>scale</code> <code>float</code> <p>The scale of the distribution.</p> <code>1.0</code> <code>max_value</code> <code>float</code> <p>The maximum value.</p> <code>4.0</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>if <code>scale</code> is not a positive number.</p> <code>ValueError</code> <p>if <code>max_value</code> is not a positive number.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.tensor import RandTruncHalfCauchy\n&gt;&gt;&gt; generator = RandTruncHalfCauchy(scale=1.0, max_value=5.0)\n&gt;&gt;&gt; generator\nRandTruncHalfCauchyTensorGenerator(scale=1.0, max_value=5.0)\n&gt;&gt;&gt; generator.generate((2, 6))\ntensor([[...]])\n</code></pre>"},{"location":"refs/tensor/#startorch.tensor.RandTruncHalfCauchyTensorGenerator","title":"startorch.tensor.RandTruncHalfCauchyTensorGenerator","text":"<p>               Bases: <code>BaseTensorGenerator</code></p> <p>Implement a class to generate tensor by sampling values from a truncated half-Cauchy distribution.</p> <p>Parameters:</p> Name Type Description Default <code>scale</code> <code>float</code> <p>The scale of the distribution.</p> <code>1.0</code> <code>max_value</code> <code>float</code> <p>The maximum value.</p> <code>4.0</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>if <code>scale</code> is not a positive number.</p> <code>ValueError</code> <p>if <code>max_value</code> is not a positive number.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.tensor import RandTruncHalfCauchy\n&gt;&gt;&gt; generator = RandTruncHalfCauchy(scale=1.0, max_value=5.0)\n&gt;&gt;&gt; generator\nRandTruncHalfCauchyTensorGenerator(scale=1.0, max_value=5.0)\n&gt;&gt;&gt; generator.generate((2, 6))\ntensor([[...]])\n</code></pre>"},{"location":"refs/tensor/#startorch.tensor.RandTruncHalfNormal","title":"startorch.tensor.RandTruncHalfNormal","text":"<p>               Bases: <code>BaseTensorGenerator</code></p> <p>Implement a class to generate tensor by sampling values from a truncated half-Normal distribution.</p> <p>Parameters:</p> Name Type Description Default <code>std</code> <code>float</code> <p>The std of the distribution.</p> <code>1.0</code> <code>max_value</code> <code>float</code> <p>The maximum value.</p> <code>3.0</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>if <code>std</code> is not a positive number.</p> <code>ValueError</code> <p>if <code>max_value</code> is not a positive number.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.tensor import RandTruncHalfNormal\n&gt;&gt;&gt; generator = RandTruncHalfNormal(std=1.0, max_value=1.0)\n&gt;&gt;&gt; generator\nRandTruncHalfNormalTensorGenerator(std=1.0, max_value=1.0)\n&gt;&gt;&gt; generator.generate(size=(2, 6))\ntensor([[...]])\n</code></pre>"},{"location":"refs/tensor/#startorch.tensor.RandTruncHalfNormalTensorGenerator","title":"startorch.tensor.RandTruncHalfNormalTensorGenerator","text":"<p>               Bases: <code>BaseTensorGenerator</code></p> <p>Implement a class to generate tensor by sampling values from a truncated half-Normal distribution.</p> <p>Parameters:</p> Name Type Description Default <code>std</code> <code>float</code> <p>The std of the distribution.</p> <code>1.0</code> <code>max_value</code> <code>float</code> <p>The maximum value.</p> <code>3.0</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>if <code>std</code> is not a positive number.</p> <code>ValueError</code> <p>if <code>max_value</code> is not a positive number.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.tensor import RandTruncHalfNormal\n&gt;&gt;&gt; generator = RandTruncHalfNormal(std=1.0, max_value=1.0)\n&gt;&gt;&gt; generator\nRandTruncHalfNormalTensorGenerator(std=1.0, max_value=1.0)\n&gt;&gt;&gt; generator.generate(size=(2, 6))\ntensor([[...]])\n</code></pre>"},{"location":"refs/tensor/#startorch.tensor.RandTruncLogNormal","title":"startorch.tensor.RandTruncLogNormal","text":"<p>               Bases: <code>BaseTensorGenerator</code></p> <p>Implement a tensor generator to generate cyclic tensors by sampling values from a truncated log-Normal distribution.</p> <p>Parameters:</p> Name Type Description Default <code>mean</code> <code>float</code> <p>The mean of the log-Normal distribution.</p> <code>0.0</code> <code>std</code> <code>float</code> <p>The standard deviation of the log-Normal distribution.</p> <code>1.0</code> <code>min_value</code> <code>float</code> <p>The minimum value.</p> <code>0.0</code> <code>max_value</code> <code>float</code> <p>The maximum value.</p> <code>5.0</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>if <code>std</code> is not a positive number.</p> <code>ValueError</code> <p>if <code>max_value</code> is lower than <code>min_value</code>.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.tensor import RandTruncLogNormal\n&gt;&gt;&gt; generator = RandTruncLogNormal(mean=0.0, std=1.0, min_value=0.0, max_value=1.0)\n&gt;&gt;&gt; generator\nRandTruncLogNormalTensorGenerator(mean=0.0, std=1.0, min_value=0.0, max_value=1.0)\n&gt;&gt;&gt; generator.generate(size=(2, 6))\ntensor([[...]])\n</code></pre>"},{"location":"refs/tensor/#startorch.tensor.RandTruncLogNormalTensorGenerator","title":"startorch.tensor.RandTruncLogNormalTensorGenerator","text":"<p>               Bases: <code>BaseTensorGenerator</code></p> <p>Implement a tensor generator to generate cyclic tensors by sampling values from a truncated log-Normal distribution.</p> <p>Parameters:</p> Name Type Description Default <code>mean</code> <code>float</code> <p>The mean of the log-Normal distribution.</p> <code>0.0</code> <code>std</code> <code>float</code> <p>The standard deviation of the log-Normal distribution.</p> <code>1.0</code> <code>min_value</code> <code>float</code> <p>The minimum value.</p> <code>0.0</code> <code>max_value</code> <code>float</code> <p>The maximum value.</p> <code>5.0</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>if <code>std</code> is not a positive number.</p> <code>ValueError</code> <p>if <code>max_value</code> is lower than <code>min_value</code>.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.tensor import RandTruncLogNormal\n&gt;&gt;&gt; generator = RandTruncLogNormal(mean=0.0, std=1.0, min_value=0.0, max_value=1.0)\n&gt;&gt;&gt; generator\nRandTruncLogNormalTensorGenerator(mean=0.0, std=1.0, min_value=0.0, max_value=1.0)\n&gt;&gt;&gt; generator.generate(size=(2, 6))\ntensor([[...]])\n</code></pre>"},{"location":"refs/tensor/#startorch.tensor.RandTruncNormal","title":"startorch.tensor.RandTruncNormal","text":"<p>               Bases: <code>BaseTensorGenerator</code></p> <p>Implement a sequence generator to generate cyclic sequences by sampling values from a truncated Normal distribution.</p> <p>Parameters:</p> Name Type Description Default <code>mean</code> <code>float</code> <p>The mean of the Normal distribution.</p> <code>0.0</code> <code>std</code> <code>float</code> <p>The standard deviation of the Normal distribution.</p> <code>1.0</code> <code>min_value</code> <code>float</code> <p>The minimum value.</p> <code>-3.0</code> <code>max_value</code> <code>float</code> <p>The maximum value.</p> <code>3.0</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>if <code>std</code> is not a postive number.</p> <code>ValueError</code> <p>if <code>max_value</code> is lower than <code>min_value</code>.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.tensor import RandTruncNormal\n&gt;&gt;&gt; generator = RandTruncNormal(mean=0.0, std=1.0, min_value=-1.0, max_value=1.0)\n&gt;&gt;&gt; generator\nRandTruncNormalTensorGenerator(mean=0.0, std=1.0, min_value=-1.0, max_value=1.0)\n&gt;&gt;&gt; generator.generate((2, 6))\ntensor([[...]])\n</code></pre>"},{"location":"refs/tensor/#startorch.tensor.RandTruncNormalTensorGenerator","title":"startorch.tensor.RandTruncNormalTensorGenerator","text":"<p>               Bases: <code>BaseTensorGenerator</code></p> <p>Implement a sequence generator to generate cyclic sequences by sampling values from a truncated Normal distribution.</p> <p>Parameters:</p> Name Type Description Default <code>mean</code> <code>float</code> <p>The mean of the Normal distribution.</p> <code>0.0</code> <code>std</code> <code>float</code> <p>The standard deviation of the Normal distribution.</p> <code>1.0</code> <code>min_value</code> <code>float</code> <p>The minimum value.</p> <code>-3.0</code> <code>max_value</code> <code>float</code> <p>The maximum value.</p> <code>3.0</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>if <code>std</code> is not a postive number.</p> <code>ValueError</code> <p>if <code>max_value</code> is lower than <code>min_value</code>.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.tensor import RandTruncNormal\n&gt;&gt;&gt; generator = RandTruncNormal(mean=0.0, std=1.0, min_value=-1.0, max_value=1.0)\n&gt;&gt;&gt; generator\nRandTruncNormalTensorGenerator(mean=0.0, std=1.0, min_value=-1.0, max_value=1.0)\n&gt;&gt;&gt; generator.generate((2, 6))\ntensor([[...]])\n</code></pre>"},{"location":"refs/tensor/#startorch.tensor.RandUniform","title":"startorch.tensor.RandUniform","text":"<p>               Bases: <code>BaseTensorGenerator</code></p> <p>Implement a tensor generator by sampling values from a uniform distribution.</p> <p>Parameters:</p> Name Type Description Default <code>low</code> <code>float</code> <p>The minimum value (inclusive).</p> <code>0.0</code> <code>high</code> <code>float</code> <p>The maximum value (exclusive).</p> <code>1.0</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.tensor import RandUniform\n&gt;&gt;&gt; generator = RandUniform(low=0, high=10)\n&gt;&gt;&gt; generator\nRandUniformTensorGenerator(low=0.0, high=10.0)\n&gt;&gt;&gt; generator.generate((2, 6))\ntensor([[...]])\n</code></pre>"},{"location":"refs/tensor/#startorch.tensor.RandUniformTensorGenerator","title":"startorch.tensor.RandUniformTensorGenerator","text":"<p>               Bases: <code>BaseTensorGenerator</code></p> <p>Implement a tensor generator by sampling values from a uniform distribution.</p> <p>Parameters:</p> Name Type Description Default <code>low</code> <code>float</code> <p>The minimum value (inclusive).</p> <code>0.0</code> <code>high</code> <code>float</code> <p>The maximum value (exclusive).</p> <code>1.0</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.tensor import RandUniform\n&gt;&gt;&gt; generator = RandUniform(low=0, high=10)\n&gt;&gt;&gt; generator\nRandUniformTensorGenerator(low=0.0, high=10.0)\n&gt;&gt;&gt; generator.generate((2, 6))\ntensor([[...]])\n</code></pre>"},{"location":"refs/tensor/#startorch.tensor.Sinh","title":"startorch.tensor.Sinh","text":"<p>               Bases: <code>BaseWrapperTensorGenerator</code></p> <p>Implement a tensor generator that computes the hyperbolic sine (sinh) of each value.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.tensor import RandUniform, Sinh\n&gt;&gt;&gt; generator = Sinh(RandUniform(low=0.0, high=1.0))\n&gt;&gt;&gt; generator\nSinhTensorGenerator(\n  (tensor): RandUniformTensorGenerator(low=0.0, high=1.0)\n)\n&gt;&gt;&gt; generator.generate((2, 6))\ntensor([[...]])\n</code></pre>"},{"location":"refs/tensor/#startorch.tensor.SinhTensorGenerator","title":"startorch.tensor.SinhTensorGenerator","text":"<p>               Bases: <code>BaseWrapperTensorGenerator</code></p> <p>Implement a tensor generator that computes the hyperbolic sine (sinh) of each value.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.tensor import RandUniform, Sinh\n&gt;&gt;&gt; generator = Sinh(RandUniform(low=0.0, high=1.0))\n&gt;&gt;&gt; generator\nSinhTensorGenerator(\n  (tensor): RandUniformTensorGenerator(low=0.0, high=1.0)\n)\n&gt;&gt;&gt; generator.generate((2, 6))\ntensor([[...]])\n</code></pre>"},{"location":"refs/tensor/#startorch.tensor.Sqrt","title":"startorch.tensor.Sqrt","text":"<p>               Bases: <code>BaseWrapperTensorGenerator</code></p> <p>Implement a tensor generator that computes the squared root of a tensor.</p> <p>This tensor generator is equivalent to: <code>output = sqrt(tensor)</code></p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.tensor import RandUniform, Sqrt\n&gt;&gt;&gt; generator = Sqrt(RandUniform(low=1.0, high=100.0))\n&gt;&gt;&gt; generator\nSqrtTensorGenerator(\n  (tensor): RandUniformTensorGenerator(low=1.0, high=100.0)\n)\n&gt;&gt;&gt; generator.generate((2, 6))\ntensor([[...]])\n</code></pre>"},{"location":"refs/tensor/#startorch.tensor.SqrtTensorGenerator","title":"startorch.tensor.SqrtTensorGenerator","text":"<p>               Bases: <code>BaseWrapperTensorGenerator</code></p> <p>Implement a tensor generator that computes the squared root of a tensor.</p> <p>This tensor generator is equivalent to: <code>output = sqrt(tensor)</code></p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.tensor import RandUniform, Sqrt\n&gt;&gt;&gt; generator = Sqrt(RandUniform(low=1.0, high=100.0))\n&gt;&gt;&gt; generator\nSqrtTensorGenerator(\n  (tensor): RandUniformTensorGenerator(low=1.0, high=100.0)\n)\n&gt;&gt;&gt; generator.generate((2, 6))\ntensor([[...]])\n</code></pre>"},{"location":"refs/tensor/#startorch.tensor.Sub","title":"startorch.tensor.Sub","text":"<p>               Bases: <code>BaseTensorGenerator</code></p> <p>Implement a tensor generator that subtracts two tensors.</p> <p>This tensor generator is equivalent to: <code>output = tensor_1 - tensor_2</code></p> <p>Parameters:</p> Name Type Description Default <code>tensor1</code> <code>BaseTensorGenerator | dict</code> <p>The first tensor generator or its configuration.</p> required <code>tensor2</code> <code>BaseTensorGenerator | dict</code> <p>The second tensor generator or its configuration.</p> required <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.tensor import RandNormal, RandUniform, Sub\n&gt;&gt;&gt; generator = Sub(RandUniform(), RandNormal())\n&gt;&gt;&gt; generator\nSubTensorGenerator(\n  (tensor1): RandUniformTensorGenerator(low=0.0, high=1.0)\n  (tensor2): RandNormalTensorGenerator(mean=0.0, std=1.0)\n)\n&gt;&gt;&gt; generator.generate((2, 6))\ntensor([[...]])\n</code></pre>"},{"location":"refs/tensor/#startorch.tensor.SubTensorGenerator","title":"startorch.tensor.SubTensorGenerator","text":"<p>               Bases: <code>BaseTensorGenerator</code></p> <p>Implement a tensor generator that subtracts two tensors.</p> <p>This tensor generator is equivalent to: <code>output = tensor_1 - tensor_2</code></p> <p>Parameters:</p> Name Type Description Default <code>tensor1</code> <code>BaseTensorGenerator | dict</code> <p>The first tensor generator or its configuration.</p> required <code>tensor2</code> <code>BaseTensorGenerator | dict</code> <p>The second tensor generator or its configuration.</p> required <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.tensor import RandNormal, RandUniform, Sub\n&gt;&gt;&gt; generator = Sub(RandUniform(), RandNormal())\n&gt;&gt;&gt; generator\nSubTensorGenerator(\n  (tensor1): RandUniformTensorGenerator(low=0.0, high=1.0)\n  (tensor2): RandNormalTensorGenerator(mean=0.0, std=1.0)\n)\n&gt;&gt;&gt; generator.generate((2, 6))\ntensor([[...]])\n</code></pre>"},{"location":"refs/tensor/#startorch.tensor.Tanh","title":"startorch.tensor.Tanh","text":"<p>               Bases: <code>BaseWrapperTensorGenerator</code></p> <p>Implement a tensor generator that computes the hyperbolic tangent (tanh) of each value.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.tensor import RandUniform, Tanh\n&gt;&gt;&gt; generator = Tanh(RandUniform(low=0.0, high=1.0))\n&gt;&gt;&gt; generator\nTanhTensorGenerator(\n  (tensor): RandUniformTensorGenerator(low=0.0, high=1.0)\n)\n&gt;&gt;&gt; generator.generate((2, 6))\ntensor([[...]])\n</code></pre>"},{"location":"refs/tensor/#startorch.tensor.TanhTensorGenerator","title":"startorch.tensor.TanhTensorGenerator","text":"<p>               Bases: <code>BaseWrapperTensorGenerator</code></p> <p>Implement a tensor generator that computes the hyperbolic tangent (tanh) of each value.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.tensor import RandUniform, Tanh\n&gt;&gt;&gt; generator = Tanh(RandUniform(low=0.0, high=1.0))\n&gt;&gt;&gt; generator\nTanhTensorGenerator(\n  (tensor): RandUniformTensorGenerator(low=0.0, high=1.0)\n)\n&gt;&gt;&gt; generator.generate((2, 6))\ntensor([[...]])\n</code></pre>"},{"location":"refs/tensor/#startorch.tensor.TruncCauchy","title":"startorch.tensor.TruncCauchy","text":"<p>               Bases: <code>BaseTensorGenerator</code></p> <p>Implement a class to generate tensor by sampling values from a Cauchy distribution.</p> <p>Parameters:</p> Name Type Description Default <code>loc</code> <code>BaseTensorGenerator | dict</code> <p>A tensor generator (or its configuration) to generate the location.</p> required <code>scale</code> <code>BaseTensorGenerator | dict</code> <p>A tensor generator (or its configuration) to generate the scale.</p> required <code>min_value</code> <code>BaseTensorGenerator | dict</code> <p>A tensor generator (or its configuration) to generate the minimum value (included).</p> required <code>max_value</code> <code>BaseTensorGenerator | dict</code> <p>A tensor generator (or its configuration) to generate the maximum value (excluded).</p> required <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.tensor import RandUniform, TruncCauchy\n&gt;&gt;&gt; generator = TruncCauchy(\n...     loc=RandUniform(low=-1.0, high=1.0),\n...     scale=RandUniform(low=1.0, high=2.0),\n...     min_value=RandUniform(low=-10.0, high=-5.0),\n...     max_value=RandUniform(low=5.0, high=10.0),\n... )\n&gt;&gt;&gt; generator\nTruncCauchyTensorGenerator(\n  (loc): RandUniformTensorGenerator(low=-1.0, high=1.0)\n  (scale): RandUniformTensorGenerator(low=1.0, high=2.0)\n  (min_value): RandUniformTensorGenerator(low=-10.0, high=-5.0)\n  (max_value): RandUniformTensorGenerator(low=5.0, high=10.0)\n)\n&gt;&gt;&gt; generator.generate((2, 6))\ntensor([[...]])\n</code></pre>"},{"location":"refs/tensor/#startorch.tensor.TruncCauchyTensorGenerator","title":"startorch.tensor.TruncCauchyTensorGenerator","text":"<p>               Bases: <code>BaseTensorGenerator</code></p> <p>Implement a class to generate tensor by sampling values from a Cauchy distribution.</p> <p>Parameters:</p> Name Type Description Default <code>loc</code> <code>BaseTensorGenerator | dict</code> <p>A tensor generator (or its configuration) to generate the location.</p> required <code>scale</code> <code>BaseTensorGenerator | dict</code> <p>A tensor generator (or its configuration) to generate the scale.</p> required <code>min_value</code> <code>BaseTensorGenerator | dict</code> <p>A tensor generator (or its configuration) to generate the minimum value (included).</p> required <code>max_value</code> <code>BaseTensorGenerator | dict</code> <p>A tensor generator (or its configuration) to generate the maximum value (excluded).</p> required <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.tensor import RandUniform, TruncCauchy\n&gt;&gt;&gt; generator = TruncCauchy(\n...     loc=RandUniform(low=-1.0, high=1.0),\n...     scale=RandUniform(low=1.0, high=2.0),\n...     min_value=RandUniform(low=-10.0, high=-5.0),\n...     max_value=RandUniform(low=5.0, high=10.0),\n... )\n&gt;&gt;&gt; generator\nTruncCauchyTensorGenerator(\n  (loc): RandUniformTensorGenerator(low=-1.0, high=1.0)\n  (scale): RandUniformTensorGenerator(low=1.0, high=2.0)\n  (min_value): RandUniformTensorGenerator(low=-10.0, high=-5.0)\n  (max_value): RandUniformTensorGenerator(low=5.0, high=10.0)\n)\n&gt;&gt;&gt; generator.generate((2, 6))\ntensor([[...]])\n</code></pre>"},{"location":"refs/tensor/#startorch.tensor.TruncExponential","title":"startorch.tensor.TruncExponential","text":"<p>               Bases: <code>BaseTensorGenerator</code></p> <p>Implement a class to generate sequence by sampling values from an Exponential distribution.</p> <p>Parameters:</p> Name Type Description Default <code>rate</code> <code>BaseTensorGenerator | dict</code> <p>A sequence generator (or its configuration) to generate the rate.</p> required <code>max_value</code> <code>BaseTensorGenerator | dict</code> <p>A sequence generator (or its configuration) to generate the maximum value (excluded).</p> required <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.tensor import RandUniform, TruncExponential\n&gt;&gt;&gt; generator = TruncExponential(\n...     rate=RandUniform(low=1.0, high=10.0),\n...     max_value=RandUniform(low=1.0, high=100.0),\n... )\n&gt;&gt;&gt; generator\nTruncExponentialTensorGenerator(\n  (rate): RandUniformTensorGenerator(low=1.0, high=10.0)\n  (max_value): RandUniformTensorGenerator(low=1.0, high=100.0)\n)\n&gt;&gt;&gt; generator.generate((2, 6))\ntensor([[...]])\n</code></pre>"},{"location":"refs/tensor/#startorch.tensor.TruncExponentialTensorGenerator","title":"startorch.tensor.TruncExponentialTensorGenerator","text":"<p>               Bases: <code>BaseTensorGenerator</code></p> <p>Implement a class to generate sequence by sampling values from an Exponential distribution.</p> <p>Parameters:</p> Name Type Description Default <code>rate</code> <code>BaseTensorGenerator | dict</code> <p>A sequence generator (or its configuration) to generate the rate.</p> required <code>max_value</code> <code>BaseTensorGenerator | dict</code> <p>A sequence generator (or its configuration) to generate the maximum value (excluded).</p> required <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.tensor import RandUniform, TruncExponential\n&gt;&gt;&gt; generator = TruncExponential(\n...     rate=RandUniform(low=1.0, high=10.0),\n...     max_value=RandUniform(low=1.0, high=100.0),\n... )\n&gt;&gt;&gt; generator\nTruncExponentialTensorGenerator(\n  (rate): RandUniformTensorGenerator(low=1.0, high=10.0)\n  (max_value): RandUniformTensorGenerator(low=1.0, high=100.0)\n)\n&gt;&gt;&gt; generator.generate((2, 6))\ntensor([[...]])\n</code></pre>"},{"location":"refs/tensor/#startorch.tensor.TruncHalfCauchy","title":"startorch.tensor.TruncHalfCauchy","text":"<p>               Bases: <code>BaseTensorGenerator</code></p> <p>Implement a class to generate tensor by sampling values from a half-Cauchy distribution.</p> <p>Parameters:</p> Name Type Description Default <code>scale</code> <code>BaseTensorGenerator | dict</code> <p>A tensor generator (or its configuration) to generate the scale.</p> required <code>max_value</code> <code>BaseTensorGenerator | dict</code> <p>A tensor generator (or its configuration) to generate the maximum value (excluded).</p> required <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.tensor import RandUniform, TruncHalfCauchy\n&gt;&gt;&gt; generator = TruncHalfCauchy(\n...     scale=RandUniform(low=1.0, high=2.0),\n...     max_value=RandUniform(low=5.0, high=10.0),\n... )\n&gt;&gt;&gt; generator\nTruncHalfCauchyTensorGenerator(\n  (scale): RandUniformTensorGenerator(low=1.0, high=2.0)\n  (max_value): RandUniformTensorGenerator(low=5.0, high=10.0)\n)\n&gt;&gt;&gt; generator.generate((2, 6))\ntensor([[...]])\n</code></pre>"},{"location":"refs/tensor/#startorch.tensor.TruncHalfCauchyTensorGenerator","title":"startorch.tensor.TruncHalfCauchyTensorGenerator","text":"<p>               Bases: <code>BaseTensorGenerator</code></p> <p>Implement a class to generate tensor by sampling values from a half-Cauchy distribution.</p> <p>Parameters:</p> Name Type Description Default <code>scale</code> <code>BaseTensorGenerator | dict</code> <p>A tensor generator (or its configuration) to generate the scale.</p> required <code>max_value</code> <code>BaseTensorGenerator | dict</code> <p>A tensor generator (or its configuration) to generate the maximum value (excluded).</p> required <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.tensor import RandUniform, TruncHalfCauchy\n&gt;&gt;&gt; generator = TruncHalfCauchy(\n...     scale=RandUniform(low=1.0, high=2.0),\n...     max_value=RandUniform(low=5.0, high=10.0),\n... )\n&gt;&gt;&gt; generator\nTruncHalfCauchyTensorGenerator(\n  (scale): RandUniformTensorGenerator(low=1.0, high=2.0)\n  (max_value): RandUniformTensorGenerator(low=5.0, high=10.0)\n)\n&gt;&gt;&gt; generator.generate((2, 6))\ntensor([[...]])\n</code></pre>"},{"location":"refs/tensor/#startorch.tensor.TruncHalfNormal","title":"startorch.tensor.TruncHalfNormal","text":"<p>               Bases: <code>BaseTensorGenerator</code></p> <p>Implement a class to generate tensor by sampling values from a half-Normal distribution.</p> <p>Parameters:</p> Name Type Description Default <code>std</code> <code>BaseTensorGenerator | dict</code> <p>A tensor generator (or its configuration) to generate the std.</p> required <code>max_value</code> <code>BaseTensorGenerator | dict</code> <p>A tensor generator (or its configuration) to generate the maximum value (excluded).</p> required <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.tensor import RandUniform, TruncHalfNormal\n&gt;&gt;&gt; generator = TruncHalfNormal(\n...     std=RandUniform(low=1.0, high=2.0),\n...     max_value=RandUniform(low=5.0, high=10.0),\n... )\n&gt;&gt;&gt; generator\nTruncHalfNormalTensorGenerator(\n  (std): RandUniformTensorGenerator(low=1.0, high=2.0)\n  (max_value): RandUniformTensorGenerator(low=5.0, high=10.0)\n)\n&gt;&gt;&gt; generator.generate(size=(2, 6))\ntensor([[...]])\n</code></pre>"},{"location":"refs/tensor/#startorch.tensor.TruncHalfNormalTensorGenerator","title":"startorch.tensor.TruncHalfNormalTensorGenerator","text":"<p>               Bases: <code>BaseTensorGenerator</code></p> <p>Implement a class to generate tensor by sampling values from a half-Normal distribution.</p> <p>Parameters:</p> Name Type Description Default <code>std</code> <code>BaseTensorGenerator | dict</code> <p>A tensor generator (or its configuration) to generate the std.</p> required <code>max_value</code> <code>BaseTensorGenerator | dict</code> <p>A tensor generator (or its configuration) to generate the maximum value (excluded).</p> required <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.tensor import RandUniform, TruncHalfNormal\n&gt;&gt;&gt; generator = TruncHalfNormal(\n...     std=RandUniform(low=1.0, high=2.0),\n...     max_value=RandUniform(low=5.0, high=10.0),\n... )\n&gt;&gt;&gt; generator\nTruncHalfNormalTensorGenerator(\n  (std): RandUniformTensorGenerator(low=1.0, high=2.0)\n  (max_value): RandUniformTensorGenerator(low=5.0, high=10.0)\n)\n&gt;&gt;&gt; generator.generate(size=(2, 6))\ntensor([[...]])\n</code></pre>"},{"location":"refs/tensor/#startorch.tensor.TruncLogNormal","title":"startorch.tensor.TruncLogNormal","text":"<p>               Bases: <code>BaseTensorGenerator</code></p> <p>Implement a class to generate tensor by sampling values from a truncated log-Normal distribution.</p> <p>Parameters:</p> Name Type Description Default <code>mean</code> <code>BaseTensorGenerator | dict</code> <p>A tensor generator (or its configuration) to generate the mean of the underlying Normal distribution.</p> required <code>std</code> <code>BaseTensorGenerator | dict</code> <p>A tensor generator (or its configuration) to generate the standard deviation of the underlying Normal distribution.</p> required <code>min_value</code> <code>BaseTensorGenerator | dict</code> <p>A tensor generator (or its configuration) to generate the minimum value (included).</p> required <code>max_value</code> <code>BaseTensorGenerator | dict</code> <p>A tensor generator (or its configuration) to generate the maximum value (excluded).</p> required <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.tensor import RandUniform, TruncLogNormal\n&gt;&gt;&gt; generator = TruncLogNormal(\n...     mean=RandUniform(low=-1.0, high=1.0),\n...     std=RandUniform(low=1.0, high=2.0),\n...     min_value=RandUniform(low=0.0, high=2.0),\n...     max_value=RandUniform(low=5.0, high=10.0),\n... )\n&gt;&gt;&gt; generator\nTruncLogNormalTensorGenerator(\n  (mean): RandUniformTensorGenerator(low=-1.0, high=1.0)\n  (std): RandUniformTensorGenerator(low=1.0, high=2.0)\n  (min_value): RandUniformTensorGenerator(low=0.0, high=2.0)\n  (max_value): RandUniformTensorGenerator(low=5.0, high=10.0)\n)\n&gt;&gt;&gt; generator.generate(size=(2, 6))\ntensor([[...]])\n</code></pre>"},{"location":"refs/tensor/#startorch.tensor.TruncLogNormalTensorGenerator","title":"startorch.tensor.TruncLogNormalTensorGenerator","text":"<p>               Bases: <code>BaseTensorGenerator</code></p> <p>Implement a class to generate tensor by sampling values from a truncated log-Normal distribution.</p> <p>Parameters:</p> Name Type Description Default <code>mean</code> <code>BaseTensorGenerator | dict</code> <p>A tensor generator (or its configuration) to generate the mean of the underlying Normal distribution.</p> required <code>std</code> <code>BaseTensorGenerator | dict</code> <p>A tensor generator (or its configuration) to generate the standard deviation of the underlying Normal distribution.</p> required <code>min_value</code> <code>BaseTensorGenerator | dict</code> <p>A tensor generator (or its configuration) to generate the minimum value (included).</p> required <code>max_value</code> <code>BaseTensorGenerator | dict</code> <p>A tensor generator (or its configuration) to generate the maximum value (excluded).</p> required <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.tensor import RandUniform, TruncLogNormal\n&gt;&gt;&gt; generator = TruncLogNormal(\n...     mean=RandUniform(low=-1.0, high=1.0),\n...     std=RandUniform(low=1.0, high=2.0),\n...     min_value=RandUniform(low=0.0, high=2.0),\n...     max_value=RandUniform(low=5.0, high=10.0),\n... )\n&gt;&gt;&gt; generator\nTruncLogNormalTensorGenerator(\n  (mean): RandUniformTensorGenerator(low=-1.0, high=1.0)\n  (std): RandUniformTensorGenerator(low=1.0, high=2.0)\n  (min_value): RandUniformTensorGenerator(low=0.0, high=2.0)\n  (max_value): RandUniformTensorGenerator(low=5.0, high=10.0)\n)\n&gt;&gt;&gt; generator.generate(size=(2, 6))\ntensor([[...]])\n</code></pre>"},{"location":"refs/tensor/#startorch.tensor.TruncNormal","title":"startorch.tensor.TruncNormal","text":"<p>               Bases: <code>BaseTensorGenerator</code></p> <p>Implement a class to generate sequence by sampling values from a truncated Normal distribution.</p> <p>Parameters:</p> Name Type Description Default <code>mean</code> <code>BaseTensorGenerator | dict</code> <p>A sequence generator (or its configuration) to generate the mean.</p> required <code>std</code> <code>BaseTensorGenerator | dict</code> <p>A sequence generator (or its configuration) to generate the standard deviation.</p> required <code>min_value</code> <code>BaseTensorGenerator | dict</code> <p>A sequence generator (or its configuration) to generate the minimum value (included).</p> required <code>max_value</code> <code>BaseTensorGenerator | dict</code> <p>A sequence generator (or its configuration) to generate the maximum value (excluded).</p> required <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.tensor import RandUniform, TruncNormal\n&gt;&gt;&gt; generator = TruncNormal(\n...     mean=RandUniform(low=-1.0, high=1.0),\n...     std=RandUniform(low=1.0, high=2.0),\n...     min_value=RandUniform(low=-10.0, high=-5.0),\n...     max_value=RandUniform(low=5.0, high=10.0),\n... )\n&gt;&gt;&gt; generator\nTruncNormalTensorGenerator(\n  (mean): RandUniformTensorGenerator(low=-1.0, high=1.0)\n  (std): RandUniformTensorGenerator(low=1.0, high=2.0)\n  (min_value): RandUniformTensorGenerator(low=-10.0, high=-5.0)\n  (max_value): RandUniformTensorGenerator(low=5.0, high=10.0)\n)\n&gt;&gt;&gt; generator.generate((2, 6))\ntensor([[...]])\n</code></pre>"},{"location":"refs/tensor/#startorch.tensor.TruncNormalTensorGenerator","title":"startorch.tensor.TruncNormalTensorGenerator","text":"<p>               Bases: <code>BaseTensorGenerator</code></p> <p>Implement a class to generate sequence by sampling values from a truncated Normal distribution.</p> <p>Parameters:</p> Name Type Description Default <code>mean</code> <code>BaseTensorGenerator | dict</code> <p>A sequence generator (or its configuration) to generate the mean.</p> required <code>std</code> <code>BaseTensorGenerator | dict</code> <p>A sequence generator (or its configuration) to generate the standard deviation.</p> required <code>min_value</code> <code>BaseTensorGenerator | dict</code> <p>A sequence generator (or its configuration) to generate the minimum value (included).</p> required <code>max_value</code> <code>BaseTensorGenerator | dict</code> <p>A sequence generator (or its configuration) to generate the maximum value (excluded).</p> required <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.tensor import RandUniform, TruncNormal\n&gt;&gt;&gt; generator = TruncNormal(\n...     mean=RandUniform(low=-1.0, high=1.0),\n...     std=RandUniform(low=1.0, high=2.0),\n...     min_value=RandUniform(low=-10.0, high=-5.0),\n...     max_value=RandUniform(low=5.0, high=10.0),\n... )\n&gt;&gt;&gt; generator\nTruncNormalTensorGenerator(\n  (mean): RandUniformTensorGenerator(low=-1.0, high=1.0)\n  (std): RandUniformTensorGenerator(low=1.0, high=2.0)\n  (min_value): RandUniformTensorGenerator(low=-10.0, high=-5.0)\n  (max_value): RandUniformTensorGenerator(low=5.0, high=10.0)\n)\n&gt;&gt;&gt; generator.generate((2, 6))\ntensor([[...]])\n</code></pre>"},{"location":"refs/tensor/#startorch.tensor.Uniform","title":"startorch.tensor.Uniform","text":"<p>               Bases: <code>BaseTensorGenerator</code></p> <p>Implement a tensor generator by sampling values from a uniform distribution.</p> <p>Parameters:</p> Name Type Description Default <code>low</code> <code>BaseTensorGenerator | dict</code> <p>A tensor generator (or its configuration) to generate the minimum value (inclusive).</p> required <code>high</code> <code>BaseTensorGenerator | dict</code> <p>A tensor generator (or its configuration) to generate the maximum value (exclusive).</p> required <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.tensor import RandUniform, Uniform\n&gt;&gt;&gt; generator = UniformTensorGenerator(\n...     low=RandUniform(low=0, high=2), high=RandUniform(low=8, high=10)\n... )\n&gt;&gt;&gt; generator\nUniformTensorGenerator(\n  (low): RandUniformTensorGenerator(low=0.0, high=2.0)\n  (high): RandUniformTensorGenerator(low=8.0, high=10.0)\n)\n&gt;&gt;&gt; generator.generate((2, 6))\ntensor([[...]])\n</code></pre>"},{"location":"refs/tensor/#startorch.tensor.UniformCategorical","title":"startorch.tensor.UniformCategorical","text":"<p>               Bases: <code>BaseTensorGenerator</code></p> <p>Implement a class to generate tensors of uniformly distributed categorical variables.</p> <p>All the categories have the same probability.</p> <p>Note: it is a more efficient implementation of <code>Multinomial.generate_uniform_weights</code>.</p> <p>Parameters:</p> Name Type Description Default <code>num_categories</code> <code>int</code> <p>The number of categories.</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>if <code>num_categories</code> is negative.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; from startorch.tensor import UniformCategorical\n&gt;&gt;&gt; generator = UniformCategorical(10)\n&gt;&gt;&gt; generator\nUniformCategoricalTensorGenerator(num_categories=10)\n&gt;&gt;&gt; generator.generate(size=(4, 12))\ntensor([[...]])\n</code></pre>"},{"location":"refs/tensor/#startorch.tensor.UniformCategoricalTensorGenerator","title":"startorch.tensor.UniformCategoricalTensorGenerator","text":"<p>               Bases: <code>BaseTensorGenerator</code></p> <p>Implement a class to generate tensors of uniformly distributed categorical variables.</p> <p>All the categories have the same probability.</p> <p>Note: it is a more efficient implementation of <code>Multinomial.generate_uniform_weights</code>.</p> <p>Parameters:</p> Name Type Description Default <code>num_categories</code> <code>int</code> <p>The number of categories.</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>if <code>num_categories</code> is negative.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; from startorch.tensor import UniformCategorical\n&gt;&gt;&gt; generator = UniformCategorical(10)\n&gt;&gt;&gt; generator\nUniformCategoricalTensorGenerator(num_categories=10)\n&gt;&gt;&gt; generator.generate(size=(4, 12))\ntensor([[...]])\n</code></pre>"},{"location":"refs/tensor/#startorch.tensor.UniformTensorGenerator","title":"startorch.tensor.UniformTensorGenerator","text":"<p>               Bases: <code>BaseTensorGenerator</code></p> <p>Implement a tensor generator by sampling values from a uniform distribution.</p> <p>Parameters:</p> Name Type Description Default <code>low</code> <code>BaseTensorGenerator | dict</code> <p>A tensor generator (or its configuration) to generate the minimum value (inclusive).</p> required <code>high</code> <code>BaseTensorGenerator | dict</code> <p>A tensor generator (or its configuration) to generate the maximum value (exclusive).</p> required <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.tensor import RandUniform, Uniform\n&gt;&gt;&gt; generator = UniformTensorGenerator(\n...     low=RandUniform(low=0, high=2), high=RandUniform(low=8, high=10)\n... )\n&gt;&gt;&gt; generator\nUniformTensorGenerator(\n  (low): RandUniformTensorGenerator(low=0.0, high=2.0)\n  (high): RandUniformTensorGenerator(low=8.0, high=10.0)\n)\n&gt;&gt;&gt; generator.generate((2, 6))\ntensor([[...]])\n</code></pre>"},{"location":"refs/tensor/#startorch.tensor.is_tensor_generator_config","title":"startorch.tensor.is_tensor_generator_config","text":"<pre><code>is_tensor_generator_config(config: dict) -&gt; bool\n</code></pre> <p>Indicate if the input configuration is a configuration for a <code>BaseTensorGenerator</code>.</p> <p>This function only checks if the value of the key  <code>_target_</code> is valid. It does not check the other values. If <code>_target_</code> indicates a function, the returned type hint is used to check the class.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>dict</code> <p>The configuration to check.</p> required <p>Returns:</p> Type Description <code>bool</code> <p><code>True</code> if the input configuration is a configuration for a <code>BaseTensorGenerator</code> object.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.tensor import is_tensor_generator_config\n&gt;&gt;&gt; is_tensor_generator_config({\"_target_\": \"startorch.tensor.RandUniform\"})\nTrue\n</code></pre>"},{"location":"refs/tensor/#startorch.tensor.setup_tensor_generator","title":"startorch.tensor.setup_tensor_generator","text":"<pre><code>setup_tensor_generator(\n    generator: BaseTensorGenerator | dict,\n) -&gt; BaseTensorGenerator\n</code></pre> <p>Set up a tensor generator.</p> <p>The tensor generator is instantiated from its configuration by using the <code>BaseTensorGenerator</code> factory function.</p> <p>Parameters:</p> Name Type Description Default <code>generator</code> <code>BaseTensorGenerator | dict</code> <p>A tensor generator or its configuration.</p> required <p>Returns:</p> Type Description <code>BaseTensorGenerator</code> <p>A tensor generator.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.tensor import setup_tensor_generator\n&gt;&gt;&gt; setup_tensor_generator({\"_target_\": \"startorch.tensor.RandUniform\"})\nRandUniformTensorGenerator(low=0.0, high=1.0)\n</code></pre>"},{"location":"refs/timeseries/","title":"timeseries","text":""},{"location":"refs/timeseries/#startorch.timeseries","title":"startorch.timeseries","text":"<p>Contain time series generators.</p>"},{"location":"refs/timeseries/#startorch.timeseries.BaseTimeSeriesGenerator","title":"startorch.timeseries.BaseTimeSeriesGenerator","text":"<p>               Bases: <code>ABC</code></p> <p>Define the base class to implement a time series generator.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; from startorch.sequence import RandUniform\n&gt;&gt;&gt; from startorch.timeseries import TimeSeries\n&gt;&gt;&gt; generator = TimeSeries({\"value\": RandUniform(), \"time\": RandUniform()})\n&gt;&gt;&gt; generator\nTimeSeriesGenerator(\n  (value): RandUniformSequenceGenerator(low=0.0, high=1.0, feature_size=(1,))\n  (time): RandUniformSequenceGenerator(low=0.0, high=1.0, feature_size=(1,))\n)\n&gt;&gt;&gt; generator.generate(seq_len=12, batch_size=4)\n{'value': tensor([[...]]), 'time': tensor([[...]])}\n</code></pre>"},{"location":"refs/timeseries/#startorch.timeseries.BaseTimeSeriesGenerator.generate","title":"startorch.timeseries.BaseTimeSeriesGenerator.generate  <code>abstractmethod</code>","text":"<pre><code>generate(\n    seq_len: int,\n    batch_size: int = 1,\n    rng: Generator | None = None,\n) -&gt; dict[Hashable, Tensor]\n</code></pre> <p>Generate a time series.</p> <p>Parameters:</p> Name Type Description Default <code>seq_len</code> <code>int</code> <p>The sequence length.</p> required <code>batch_size</code> <code>int</code> <p>The batch size.</p> <code>1</code> <code>rng</code> <code>Generator | None</code> <p>An optional random number generator.</p> <code>None</code> <p>Returns:</p> Type Description <code>dict[Hashable, Tensor]</code> <p>A batch of time series.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; from startorch.sequence import RandUniform\n&gt;&gt;&gt; from startorch.timeseries import TimeSeries\n&gt;&gt;&gt; generator = TimeSeries({\"value\": RandUniform(), \"time\": RandUniform()})\n&gt;&gt;&gt; generator.generate(seq_len=12, batch_size=4)\n{'value': tensor([[...]]), 'time': tensor([[...]])}\n</code></pre>"},{"location":"refs/timeseries/#startorch.timeseries.Merge","title":"startorch.timeseries.Merge","text":"<p>               Bases: <code>BaseTimeSeriesGenerator</code></p> <p>Implement a time series creator that creates time series by combining several time series.</p> <p>The time series are combined by using the time information.</p> <p>Parameters:</p> Name Type Description Default <code>generators</code> <code>Sequence[BaseTimeSeriesGenerator | dict]</code> <p>The time series generators or their configuration.</p> required <code>time_key</code> <code>str</code> <p>The key used to merge the time series by time.</p> <code>TIME</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.timeseries import Merge, TimeSeries\n&gt;&gt;&gt; from startorch.sequence import RandUniform, RandNormal\n&gt;&gt;&gt; generator = Merge(\n...     (\n...         TimeSeries({\"value\": RandUniform(), \"time\": RandUniform()}),\n...         TimeSeries({\"value\": RandNormal(), \"time\": RandNormal()}),\n...     )\n... )\n&gt;&gt;&gt; generator\nMergeTimeSeriesGenerator(\n  (time_key): time\n  (0): TimeSeriesGenerator(\n      (value): RandUniformSequenceGenerator(low=0.0, high=1.0, feature_size=(1,))\n      (time): RandUniformSequenceGenerator(low=0.0, high=1.0, feature_size=(1,))\n    )\n  (1): TimeSeriesGenerator(\n      (value): RandNormalSequenceGenerator(mean=0.0, std=1.0, feature_size=(1,))\n      (time): RandNormalSequenceGenerator(mean=0.0, std=1.0, feature_size=(1,))\n    )\n)\n&gt;&gt;&gt; batch = generator.generate(seq_len=12, batch_size=10)\n&gt;&gt;&gt; batch\n{'value': tensor([[...]]), 'time': tensor([[...]])}\n</code></pre>"},{"location":"refs/timeseries/#startorch.timeseries.MergeTimeSeriesGenerator","title":"startorch.timeseries.MergeTimeSeriesGenerator","text":"<p>               Bases: <code>BaseTimeSeriesGenerator</code></p> <p>Implement a time series creator that creates time series by combining several time series.</p> <p>The time series are combined by using the time information.</p> <p>Parameters:</p> Name Type Description Default <code>generators</code> <code>Sequence[BaseTimeSeriesGenerator | dict]</code> <p>The time series generators or their configuration.</p> required <code>time_key</code> <code>str</code> <p>The key used to merge the time series by time.</p> <code>TIME</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.timeseries import Merge, TimeSeries\n&gt;&gt;&gt; from startorch.sequence import RandUniform, RandNormal\n&gt;&gt;&gt; generator = Merge(\n...     (\n...         TimeSeries({\"value\": RandUniform(), \"time\": RandUniform()}),\n...         TimeSeries({\"value\": RandNormal(), \"time\": RandNormal()}),\n...     )\n... )\n&gt;&gt;&gt; generator\nMergeTimeSeriesGenerator(\n  (time_key): time\n  (0): TimeSeriesGenerator(\n      (value): RandUniformSequenceGenerator(low=0.0, high=1.0, feature_size=(1,))\n      (time): RandUniformSequenceGenerator(low=0.0, high=1.0, feature_size=(1,))\n    )\n  (1): TimeSeriesGenerator(\n      (value): RandNormalSequenceGenerator(mean=0.0, std=1.0, feature_size=(1,))\n      (time): RandNormalSequenceGenerator(mean=0.0, std=1.0, feature_size=(1,))\n    )\n)\n&gt;&gt;&gt; batch = generator.generate(seq_len=12, batch_size=10)\n&gt;&gt;&gt; batch\n{'value': tensor([[...]]), 'time': tensor([[...]])}\n</code></pre>"},{"location":"refs/timeseries/#startorch.timeseries.MixedTimeSeries","title":"startorch.timeseries.MixedTimeSeries","text":"<p>               Bases: <code>BaseTimeSeriesGenerator</code></p> <p>Implement a time series generator that generates time series by mixing two sequences of a time series.</p> <p>Parameters:</p> Name Type Description Default <code>generator</code> <code>BaseTimeSeriesGenerator | dict</code> <p>The time series generator or its configuration.</p> required <code>key1</code> <code>str</code> <p>The key of the first sequence to mix.</p> required <code>key2</code> <code>str</code> <p>The key of the second sequence to mix.</p> required <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; from startorch.sequence import RandUniform\n&gt;&gt;&gt; from startorch.timeseries import MixedTimeSeries, TimeSeries\n&gt;&gt;&gt; generator = MixedTimeSeries(\n...     TimeSeries({\"key1\": RandUniform(), \"key2\": RandUniform()}),\n...     key1=\"key1\",\n...     key2=\"key2\",\n... )\n&gt;&gt;&gt; generator\nMixedTimeSeriesGenerator(\n  (generator): TimeSeriesGenerator(\n      (key1): RandUniformSequenceGenerator(low=0.0, high=1.0, feature_size=(1,))\n      (key2): RandUniformSequenceGenerator(low=0.0, high=1.0, feature_size=(1,))\n    )\n  (key1): key1\n  (key2): key2\n)\n&gt;&gt;&gt; generator.generate(seq_len=12, batch_size=10)\n{'key1': tensor([[...]]), 'key2': tensor([[...]])}\n</code></pre>"},{"location":"refs/timeseries/#startorch.timeseries.MixedTimeSeriesGenerator","title":"startorch.timeseries.MixedTimeSeriesGenerator","text":"<p>               Bases: <code>BaseTimeSeriesGenerator</code></p> <p>Implement a time series generator that generates time series by mixing two sequences of a time series.</p> <p>Parameters:</p> Name Type Description Default <code>generator</code> <code>BaseTimeSeriesGenerator | dict</code> <p>The time series generator or its configuration.</p> required <code>key1</code> <code>str</code> <p>The key of the first sequence to mix.</p> required <code>key2</code> <code>str</code> <p>The key of the second sequence to mix.</p> required <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; from startorch.sequence import RandUniform\n&gt;&gt;&gt; from startorch.timeseries import MixedTimeSeries, TimeSeries\n&gt;&gt;&gt; generator = MixedTimeSeries(\n...     TimeSeries({\"key1\": RandUniform(), \"key2\": RandUniform()}),\n...     key1=\"key1\",\n...     key2=\"key2\",\n... )\n&gt;&gt;&gt; generator\nMixedTimeSeriesGenerator(\n  (generator): TimeSeriesGenerator(\n      (key1): RandUniformSequenceGenerator(low=0.0, high=1.0, feature_size=(1,))\n      (key2): RandUniformSequenceGenerator(low=0.0, high=1.0, feature_size=(1,))\n    )\n  (key1): key1\n  (key2): key2\n)\n&gt;&gt;&gt; generator.generate(seq_len=12, batch_size=10)\n{'key1': tensor([[...]]), 'key2': tensor([[...]])}\n</code></pre>"},{"location":"refs/timeseries/#startorch.timeseries.MultinomialChoice","title":"startorch.timeseries.MultinomialChoice","text":"<p>               Bases: <code>BaseTimeSeriesGenerator</code></p> <p>Implement a time series generator that selecta a different time series generator at each batch.</p> <p>This time series generator is used to generate time series with different generation processes. The user can specify a list of time series generators with an associated weight. The weight is used to sample the time series generator with a multinomial distribution. Higher weight means that the time series generator has a higher probability to be selected at each batch. Each dictionary in the <code>generators</code> input should have the following items:</p> <pre><code>- a key ``'generator'`` which indicates the time series\n    generator or its configuration.\n- an optional key ``'weight'`` with a float value which\n    indicates the weight of the time series generator.\n    If this key is absent, the weight is set to ``1.0``.\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>generators</code> <code>Sequence[dict[str, BaseTimeSeriesGenerator | dict]]</code> <p>The time series generators and their weights. See above to learn about the expected format.</p> required <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.timeseries import MultinomialChoice, TimeSeries\n&gt;&gt;&gt; from startorch.sequence import RandUniform, RandNormal\n&gt;&gt;&gt; generator = MultinomialChoice(\n...     (\n...         {\n...             \"weight\": 2.0,\n...             \"generator\": TimeSeries({\"value\": RandUniform(), \"time\": RandUniform()}),\n...         },\n...         {\n...             \"weight\": 1.0,\n...             \"generator\": TimeSeries({\"value\": RandNormal(), \"time\": RandNormal()}),\n...         },\n...     )\n... )\n&gt;&gt;&gt; generator\nMultinomialChoiceTimeSeriesGenerator(\n  (0) [weight=2.0] TimeSeriesGenerator(\n      (value): RandUniformSequenceGenerator(low=0.0, high=1.0, feature_size=(1,))\n      (time): RandUniformSequenceGenerator(low=0.0, high=1.0, feature_size=(1,))\n    )\n  (1) [weight=1.0] TimeSeriesGenerator(\n      (value): RandNormalSequenceGenerator(mean=0.0, std=1.0, feature_size=(1,))\n      (time): RandNormalSequenceGenerator(mean=0.0, std=1.0, feature_size=(1,))\n    )\n)\n&gt;&gt;&gt; generator.generate(seq_len=12, batch_size=4)\n{'value': tensor([[...]]), 'time': tensor([[...]])}\n</code></pre>"},{"location":"refs/timeseries/#startorch.timeseries.MultinomialChoiceTimeSeriesGenerator","title":"startorch.timeseries.MultinomialChoiceTimeSeriesGenerator","text":"<p>               Bases: <code>BaseTimeSeriesGenerator</code></p> <p>Implement a time series generator that selecta a different time series generator at each batch.</p> <p>This time series generator is used to generate time series with different generation processes. The user can specify a list of time series generators with an associated weight. The weight is used to sample the time series generator with a multinomial distribution. Higher weight means that the time series generator has a higher probability to be selected at each batch. Each dictionary in the <code>generators</code> input should have the following items:</p> <pre><code>- a key ``'generator'`` which indicates the time series\n    generator or its configuration.\n- an optional key ``'weight'`` with a float value which\n    indicates the weight of the time series generator.\n    If this key is absent, the weight is set to ``1.0``.\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>generators</code> <code>Sequence[dict[str, BaseTimeSeriesGenerator | dict]]</code> <p>The time series generators and their weights. See above to learn about the expected format.</p> required <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.timeseries import MultinomialChoice, TimeSeries\n&gt;&gt;&gt; from startorch.sequence import RandUniform, RandNormal\n&gt;&gt;&gt; generator = MultinomialChoice(\n...     (\n...         {\n...             \"weight\": 2.0,\n...             \"generator\": TimeSeries({\"value\": RandUniform(), \"time\": RandUniform()}),\n...         },\n...         {\n...             \"weight\": 1.0,\n...             \"generator\": TimeSeries({\"value\": RandNormal(), \"time\": RandNormal()}),\n...         },\n...     )\n... )\n&gt;&gt;&gt; generator\nMultinomialChoiceTimeSeriesGenerator(\n  (0) [weight=2.0] TimeSeriesGenerator(\n      (value): RandUniformSequenceGenerator(low=0.0, high=1.0, feature_size=(1,))\n      (time): RandUniformSequenceGenerator(low=0.0, high=1.0, feature_size=(1,))\n    )\n  (1) [weight=1.0] TimeSeriesGenerator(\n      (value): RandNormalSequenceGenerator(mean=0.0, std=1.0, feature_size=(1,))\n      (time): RandNormalSequenceGenerator(mean=0.0, std=1.0, feature_size=(1,))\n    )\n)\n&gt;&gt;&gt; generator.generate(seq_len=12, batch_size=4)\n{'value': tensor([[...]]), 'time': tensor([[...]])}\n</code></pre>"},{"location":"refs/timeseries/#startorch.timeseries.Periodic","title":"startorch.timeseries.Periodic","text":"<p>               Bases: <code>BaseTimeSeriesGenerator</code></p> <p>Implement a time series generator to generate periodic time series from a regular time series generator.</p> <p>Parameters:</p> Name Type Description Default <code>timeseries</code> <code>BaseTimeSeriesGenerator | BasePeriodicTimeSeriesGenerator | dict</code> <p>A time series generator or its configuration that is used to generate the periodic pattern.</p> required <code>period</code> <code>BaseTensorGenerator | dict</code> <p>The period length sampler or its configuration. This sampler is used to sample the period length at each batch.</p> required <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.timeseries import Periodic, TimeSeries\n&gt;&gt;&gt; from startorch.sequence import RandUniform\n&gt;&gt;&gt; from startorch.tensor import RandInt\n&gt;&gt;&gt; generator = Periodic(\n...     TimeSeries({\"value\": RandUniform(), \"time\": RandUniform()}), period=RandInt(2, 5)\n... )\n&gt;&gt;&gt; generator\nPeriodicTimeSeriesGenerator(\n  (sequence): TimeSeriesGenerator(\n      (value): RandUniformSequenceGenerator(low=0.0, high=1.0, feature_size=(1,))\n      (time): RandUniformSequenceGenerator(low=0.0, high=1.0, feature_size=(1,))\n    )\n  (period): RandIntTensorGenerator(low=2, high=5)\n)\n&gt;&gt;&gt; generator.generate(seq_len=10, batch_size=2)\n{'value': tensor([[...]]), 'time': tensor([[...]])}\n</code></pre>"},{"location":"refs/timeseries/#startorch.timeseries.PeriodicTimeSeriesGenerator","title":"startorch.timeseries.PeriodicTimeSeriesGenerator","text":"<p>               Bases: <code>BaseTimeSeriesGenerator</code></p> <p>Implement a time series generator to generate periodic time series from a regular time series generator.</p> <p>Parameters:</p> Name Type Description Default <code>timeseries</code> <code>BaseTimeSeriesGenerator | BasePeriodicTimeSeriesGenerator | dict</code> <p>A time series generator or its configuration that is used to generate the periodic pattern.</p> required <code>period</code> <code>BaseTensorGenerator | dict</code> <p>The period length sampler or its configuration. This sampler is used to sample the period length at each batch.</p> required <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.timeseries import Periodic, TimeSeries\n&gt;&gt;&gt; from startorch.sequence import RandUniform\n&gt;&gt;&gt; from startorch.tensor import RandInt\n&gt;&gt;&gt; generator = Periodic(\n...     TimeSeries({\"value\": RandUniform(), \"time\": RandUniform()}), period=RandInt(2, 5)\n... )\n&gt;&gt;&gt; generator\nPeriodicTimeSeriesGenerator(\n  (sequence): TimeSeriesGenerator(\n      (value): RandUniformSequenceGenerator(low=0.0, high=1.0, feature_size=(1,))\n      (time): RandUniformSequenceGenerator(low=0.0, high=1.0, feature_size=(1,))\n    )\n  (period): RandIntTensorGenerator(low=2, high=5)\n)\n&gt;&gt;&gt; generator.generate(seq_len=10, batch_size=2)\n{'value': tensor([[...]]), 'time': tensor([[...]])}\n</code></pre>"},{"location":"refs/timeseries/#startorch.timeseries.TimeSeries","title":"startorch.timeseries.TimeSeries","text":"<p>               Bases: <code>BaseTimeSeriesGenerator</code></p> <p>Implement a generic time series generator.</p> <p>Parameters:</p> Name Type Description Default <code>sequences</code> <code>Mapping[str, BaseSequenceGenerator | dict]</code> <p>The sequence generators or their configurations.</p> required <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; from startorch.sequence import RandUniform\n&gt;&gt;&gt; from startorch.timeseries import TimeSeries\n&gt;&gt;&gt; generator = TimeSeries({\"value\": RandUniform(), \"time\": RandUniform()})\n&gt;&gt;&gt; generator\nTimeSeriesGenerator(\n  (value): RandUniformSequenceGenerator(low=0.0, high=1.0, feature_size=(1,))\n  (time): RandUniformSequenceGenerator(low=0.0, high=1.0, feature_size=(1,))\n)\n&gt;&gt;&gt; generator.generate(seq_len=12, batch_size=4)\n{'value': tensor([[...]]), 'time': tensor([[...]])}\n</code></pre>"},{"location":"refs/timeseries/#startorch.timeseries.TimeSeriesGenerator","title":"startorch.timeseries.TimeSeriesGenerator","text":"<p>               Bases: <code>BaseTimeSeriesGenerator</code></p> <p>Implement a generic time series generator.</p> <p>Parameters:</p> Name Type Description Default <code>sequences</code> <code>Mapping[str, BaseSequenceGenerator | dict]</code> <p>The sequence generators or their configurations.</p> required <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; from startorch.sequence import RandUniform\n&gt;&gt;&gt; from startorch.timeseries import TimeSeries\n&gt;&gt;&gt; generator = TimeSeries({\"value\": RandUniform(), \"time\": RandUniform()})\n&gt;&gt;&gt; generator\nTimeSeriesGenerator(\n  (value): RandUniformSequenceGenerator(low=0.0, high=1.0, feature_size=(1,))\n  (time): RandUniformSequenceGenerator(low=0.0, high=1.0, feature_size=(1,))\n)\n&gt;&gt;&gt; generator.generate(seq_len=12, batch_size=4)\n{'value': tensor([[...]]), 'time': tensor([[...]])}\n</code></pre>"},{"location":"refs/timeseries/#startorch.timeseries.is_timeseries_generator_config","title":"startorch.timeseries.is_timeseries_generator_config","text":"<pre><code>is_timeseries_generator_config(config: dict) -&gt; bool\n</code></pre> <p>Indicate if the input configuration is a configuration for a <code>BaseTimeSeriesGenerator</code>.</p> <p>This function only checks if the value of the key  <code>_target_</code> is valid. It does not check the other values. If <code>_target_</code> indicates a function, the returned type hint is used to check the class.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>dict</code> <p>The configuration to check.</p> required <p>Returns:</p> Type Description <code>bool</code> <p><code>True</code> if the input configuration is a configuration for a <code>BaseTimeSeriesGenerator</code> object.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.timeseries import is_timeseries_generator_config\n&gt;&gt;&gt; is_timeseries_generator_config(\n...     {\n...         \"_target_\": \"startorch.timeseries.TimeSeries\",\n...         \"sequences\": {\n...             \"value\": {\"_target_\": \"startorch.sequence.RandUniform\"},\n...             \"time\": {\"_target_\": \"startorch.sequence.RandUniform\"},\n...         },\n...     }\n... )\nTrue\n</code></pre>"},{"location":"refs/timeseries/#startorch.timeseries.setup_timeseries_generator","title":"startorch.timeseries.setup_timeseries_generator","text":"<pre><code>setup_timeseries_generator(\n    generator: BaseTimeSeriesGenerator | dict,\n) -&gt; BaseTimeSeriesGenerator\n</code></pre> <p>Set up a time series generator.</p> <p>The time series generator is instantiated from its configuration by using the <code>BaseTimeSeriesGenerator</code> factory function.</p> <p>Parameters:</p> Name Type Description Default <code>generator</code> <code>BaseTimeSeriesGenerator | dict</code> <p>A time series generator or its configuration.</p> required <p>Returns:</p> Type Description <code>BaseTimeSeriesGenerator</code> <p>A time series generator.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.timeseries import setup_timeseries_generator\n&gt;&gt;&gt; setup_timeseries_generator(\n...     {\n...         \"_target_\": \"startorch.timeseries.TimeSeries\",\n...         \"sequences\": {\n...             \"value\": {\"_target_\": \"startorch.sequence.RandUniform\"},\n...             \"time\": {\"_target_\": \"startorch.sequence.RandUniform\"},\n...         },\n...     }\n... )\nTimeSeriesGenerator(\n  (value): RandUniformSequenceGenerator(low=0.0, high=1.0, feature_size=(1,))\n  (time): RandUniformSequenceGenerator(low=0.0, high=1.0, feature_size=(1,))\n)\n</code></pre>"},{"location":"refs/transformer/","title":"transformer","text":""},{"location":"refs/transformer/#startorch.transformer","title":"startorch.transformer","text":"<p>Contain data transformers.</p>"},{"location":"refs/transformer/#startorch.transformer.Abs","title":"startorch.transformer.Abs","text":"<p>               Bases: <code>BaseTensorTransformer</code></p> <p>Implement a tensor transformer that computes the absolute value of a tensor.</p> <p>This tensor transformer is equivalent to: <code>output = abs(input)</code></p> <p>Parameters:</p> Name Type Description Default <code>input</code> <code>str</code> <p>The key that contains the input tensor.</p> required <code>output</code> <code>str</code> <p>The key that contains the output tensor.</p> required <code>exist_ok</code> <code>bool</code> <p>If <code>False</code>, an exception is raised if the output key already exists. Otherwise, the value associated to the output key is updated.</p> <code>False</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; from startorch.transformer import Abs\n&gt;&gt;&gt; transformer = Abs(input=\"input\", output=\"output\")\n&gt;&gt;&gt; transformer\nAbsTransformer(input=input, output=output, exist_ok=False)\n&gt;&gt;&gt; data = {\"input\": torch.tensor([[1.0, -2.0, 3.0], [-4.0, 5.0, -6.0]])}\n&gt;&gt;&gt; out = transformer.transform(data)\n&gt;&gt;&gt; out\n{'input': tensor([[ 1., -2.,  3.],\n                  [-4.,  5., -6.]]),\n 'output': tensor([[1., 2., 3.],\n                   [4., 5., 6.]])}\n</code></pre>"},{"location":"refs/transformer/#startorch.transformer.AbsTransformer","title":"startorch.transformer.AbsTransformer","text":"<p>               Bases: <code>BaseTensorTransformer</code></p> <p>Implement a tensor transformer that computes the absolute value of a tensor.</p> <p>This tensor transformer is equivalent to: <code>output = abs(input)</code></p> <p>Parameters:</p> Name Type Description Default <code>input</code> <code>str</code> <p>The key that contains the input tensor.</p> required <code>output</code> <code>str</code> <p>The key that contains the output tensor.</p> required <code>exist_ok</code> <code>bool</code> <p>If <code>False</code>, an exception is raised if the output key already exists. Otherwise, the value associated to the output key is updated.</p> <code>False</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; from startorch.transformer import Abs\n&gt;&gt;&gt; transformer = Abs(input=\"input\", output=\"output\")\n&gt;&gt;&gt; transformer\nAbsTransformer(input=input, output=output, exist_ok=False)\n&gt;&gt;&gt; data = {\"input\": torch.tensor([[1.0, -2.0, 3.0], [-4.0, 5.0, -6.0]])}\n&gt;&gt;&gt; out = transformer.transform(data)\n&gt;&gt;&gt; out\n{'input': tensor([[ 1., -2.,  3.],\n                  [-4.,  5., -6.]]),\n 'output': tensor([[1., 2., 3.],\n                   [4., 5., 6.]])}\n</code></pre>"},{"location":"refs/transformer/#startorch.transformer.Acosh","title":"startorch.transformer.Acosh","text":"<p>               Bases: <code>BaseTensorTransformer</code></p> <p>Implement a tensor transformer that computes the inverse hyperbolic cosine (arccosh) of each value.</p> <p>Parameters:</p> Name Type Description Default <code>input</code> <code>str</code> <p>The key that contains the input tensor.</p> required <code>output</code> <code>str</code> <p>The key that contains the output tensor.</p> required <code>exist_ok</code> <code>bool</code> <p>If <code>False</code>, an exception is raised if the output key already exists. Otherwise, the value associated to the output key is updated.</p> <code>False</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; from startorch.transformer import Acosh\n&gt;&gt;&gt; transformer = Acosh(input=\"input\", output=\"output\")\n&gt;&gt;&gt; transformer\nAcoshTransformer(input=input, output=output, exist_ok=False)\n&gt;&gt;&gt; data = {\"input\": torch.tensor([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])}\n&gt;&gt;&gt; out = transformer.transform(data)\n&gt;&gt;&gt; out\n{'input': tensor([[1., 2., 3.],\n                  [4., 5., 6.]]),\n 'output': tensor([[0.0000, 1.3170, 1.7627],\n                   [2.0634, 2.2924, 2.4779]])}\n</code></pre>"},{"location":"refs/transformer/#startorch.transformer.AcoshTransformer","title":"startorch.transformer.AcoshTransformer","text":"<p>               Bases: <code>BaseTensorTransformer</code></p> <p>Implement a tensor transformer that computes the inverse hyperbolic cosine (arccosh) of each value.</p> <p>Parameters:</p> Name Type Description Default <code>input</code> <code>str</code> <p>The key that contains the input tensor.</p> required <code>output</code> <code>str</code> <p>The key that contains the output tensor.</p> required <code>exist_ok</code> <code>bool</code> <p>If <code>False</code>, an exception is raised if the output key already exists. Otherwise, the value associated to the output key is updated.</p> <code>False</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; from startorch.transformer import Acosh\n&gt;&gt;&gt; transformer = Acosh(input=\"input\", output=\"output\")\n&gt;&gt;&gt; transformer\nAcoshTransformer(input=input, output=output, exist_ok=False)\n&gt;&gt;&gt; data = {\"input\": torch.tensor([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])}\n&gt;&gt;&gt; out = transformer.transform(data)\n&gt;&gt;&gt; out\n{'input': tensor([[1., 2., 3.],\n                  [4., 5., 6.]]),\n 'output': tensor([[0.0000, 1.3170, 1.7627],\n                   [2.0634, 2.2924, 2.4779]])}\n</code></pre>"},{"location":"refs/transformer/#startorch.transformer.Asinh","title":"startorch.transformer.Asinh","text":"<p>               Bases: <code>BaseTensorTransformer</code></p> <p>Implement a tensor transformer that computes the inverse hyperbolic sine (arcsinh) of each value.</p> <p>Parameters:</p> Name Type Description Default <code>input</code> <code>str</code> <p>The key that contains the input tensor.</p> required <code>output</code> <code>str</code> <p>The key that contains the output tensor.</p> required <code>exist_ok</code> <code>bool</code> <p>If <code>False</code>, an exception is raised if the output key already exists. Otherwise, the value associated to the output key is updated.</p> <code>False</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; from startorch.transformer import Asinh\n&gt;&gt;&gt; transformer = Asinh(input=\"input\", output=\"output\")\n&gt;&gt;&gt; transformer\nAsinhTransformer(input=input, output=output, exist_ok=False)\n&gt;&gt;&gt; data = {'input': torch.tensor([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])}\n&gt;&gt;&gt; out = transformer.transform(data)\n&gt;&gt;&gt; out\n{'input': tensor([[1., 2., 3.],\n                  [4., 5., 6.]]),\n 'output': tensor([[0.8814, 1.4436, 1.8184],\n                   [2.0947, 2.3124, 2.4918]])}\n</code></pre>"},{"location":"refs/transformer/#startorch.transformer.AsinhTransformer","title":"startorch.transformer.AsinhTransformer","text":"<p>               Bases: <code>BaseTensorTransformer</code></p> <p>Implement a tensor transformer that computes the inverse hyperbolic sine (arcsinh) of each value.</p> <p>Parameters:</p> Name Type Description Default <code>input</code> <code>str</code> <p>The key that contains the input tensor.</p> required <code>output</code> <code>str</code> <p>The key that contains the output tensor.</p> required <code>exist_ok</code> <code>bool</code> <p>If <code>False</code>, an exception is raised if the output key already exists. Otherwise, the value associated to the output key is updated.</p> <code>False</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; from startorch.transformer import Asinh\n&gt;&gt;&gt; transformer = Asinh(input=\"input\", output=\"output\")\n&gt;&gt;&gt; transformer\nAsinhTransformer(input=input, output=output, exist_ok=False)\n&gt;&gt;&gt; data = {'input': torch.tensor([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])}\n&gt;&gt;&gt; out = transformer.transform(data)\n&gt;&gt;&gt; out\n{'input': tensor([[1., 2., 3.],\n                  [4., 5., 6.]]),\n 'output': tensor([[0.8814, 1.4436, 1.8184],\n                   [2.0947, 2.3124, 2.4918]])}\n</code></pre>"},{"location":"refs/transformer/#startorch.transformer.Atanh","title":"startorch.transformer.Atanh","text":"<p>               Bases: <code>BaseTensorTransformer</code></p> <p>Implement a tensor transformer that computes the inverse hyperbolic tangent (arctanh) of each value.</p> <p>Parameters:</p> Name Type Description Default <code>input</code> <code>str</code> <p>The key that contains the input tensor.</p> required <code>output</code> <code>str</code> <p>The key that contains the output tensor.</p> required <code>exist_ok</code> <code>bool</code> <p>If <code>False</code>, an exception is raised if the output key already exists. Otherwise, the value associated to the output key is updated.</p> <code>False</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; from startorch.transformer import Atanh\n&gt;&gt;&gt; transformer = Atanh(input=\"input\", output=\"output\")\n&gt;&gt;&gt; transformer\nAtanhTransformer(input=input, output=output, exist_ok=False)\n&gt;&gt;&gt; data = {'input': torch.tensor([[-0.5, -0.1, 0.0], [0.1, 0.2, 0.5]])}\n&gt;&gt;&gt; out = transformer.transform(data)\n&gt;&gt;&gt; out\n{'input': tensor([[-0.5000, -0.1000,  0.0000],\n                  [ 0.1000,  0.2000,  0.5000]]),\n 'output': tensor([[-0.5493, -0.1003,  0.0000],\n                   [ 0.1003,  0.2027,  0.5493]])}\n</code></pre>"},{"location":"refs/transformer/#startorch.transformer.AtanhTransformer","title":"startorch.transformer.AtanhTransformer","text":"<p>               Bases: <code>BaseTensorTransformer</code></p> <p>Implement a tensor transformer that computes the inverse hyperbolic tangent (arctanh) of each value.</p> <p>Parameters:</p> Name Type Description Default <code>input</code> <code>str</code> <p>The key that contains the input tensor.</p> required <code>output</code> <code>str</code> <p>The key that contains the output tensor.</p> required <code>exist_ok</code> <code>bool</code> <p>If <code>False</code>, an exception is raised if the output key already exists. Otherwise, the value associated to the output key is updated.</p> <code>False</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; from startorch.transformer import Atanh\n&gt;&gt;&gt; transformer = Atanh(input=\"input\", output=\"output\")\n&gt;&gt;&gt; transformer\nAtanhTransformer(input=input, output=output, exist_ok=False)\n&gt;&gt;&gt; data = {'input': torch.tensor([[-0.5, -0.1, 0.0], [0.1, 0.2, 0.5]])}\n&gt;&gt;&gt; out = transformer.transform(data)\n&gt;&gt;&gt; out\n{'input': tensor([[-0.5000, -0.1000,  0.0000],\n                  [ 0.1000,  0.2000,  0.5000]]),\n 'output': tensor([[-0.5493, -0.1003,  0.0000],\n                   [ 0.1003,  0.2027,  0.5493]])}\n</code></pre>"},{"location":"refs/transformer/#startorch.transformer.BaseTensorTransformer","title":"startorch.transformer.BaseTensorTransformer","text":"<p>               Bases: <code>BaseTransformer</code></p> <p>Define the base class to transform a tensor.</p> <p>Parameters:</p> Name Type Description Default <code>input</code> <code>str</code> <p>The key that contains the input tensor.</p> required <code>output</code> <code>str</code> <p>The key that contains the output tensor.</p> required <code>exist_ok</code> <code>bool</code> <p>If <code>False</code>, an exception is raised if the output key already exists. Otherwise, the value associated to the output key is updated.</p> <code>False</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; from startorch.transformer import Tanh\n&gt;&gt;&gt; transformer = Tanh(input=\"input\", output=\"output\")\n&gt;&gt;&gt; transformer\nTanhTransformer(input=input, output=output, exist_ok=False)\n&gt;&gt;&gt; data = {\"input\": torch.tensor([[0.0, 1.0, 2.0], [4.0, 5.0, 6.0]])}\n&gt;&gt;&gt; out = transformer.transform(data)\n&gt;&gt;&gt; out\n{'input': tensor([[0., 1., 2.],\n                  [4., 5., 6.]]),\n 'output': tensor([[0.0000, 0.7616, 0.9640],\n                   [0.9993, 0.9999, 1.0000]])}\n</code></pre>"},{"location":"refs/transformer/#startorch.transformer.BaseTransformer","title":"startorch.transformer.BaseTransformer","text":"<p>               Bases: <code>ABC</code></p> <p>Define the base class to transform a batch of data.</p> <p>A child class has to implement the <code>transform</code> method.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; from startorch.transformer import Identity\n&gt;&gt;&gt; transformer = Identity()\n&gt;&gt;&gt; transformer\nIdentityTransformer(copy=True)\n&gt;&gt;&gt; data = {\"key\": torch.tensor([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])}\n&gt;&gt;&gt; out = transformer.transform(data)\n&gt;&gt;&gt; out\n{'key': tensor([[1., 2., 3.],\n                [4., 5., 6.]])}\n</code></pre>"},{"location":"refs/transformer/#startorch.transformer.BaseTransformer.transform","title":"startorch.transformer.BaseTransformer.transform  <code>abstractmethod</code>","text":"<pre><code>transform(\n    data: dict[Hashable, Tensor],\n    *,\n    rng: Transformer | None = None\n) -&gt; dict[Hashable, Tensor]\n</code></pre> <p>Transform the input data.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>dict[Hashable, Tensor]</code> <p>The data to transform.</p> required <code>rng</code> <code>Transformer | None</code> <p>An optional random number transformer.</p> <code>None</code> <p>Returns:</p> Type Description <code>dict[Hashable, Tensor]</code> <p>The transformed data.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; from startorch.transformer import Identity\n&gt;&gt;&gt; transformer = Identity()\n&gt;&gt;&gt; data = {'key': torch.tensor([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])}\n&gt;&gt;&gt; out = transformer.transform(data)\n&gt;&gt;&gt; out\n{'key': tensor([[1., 2., 3.],\n                [4., 5., 6.]])}\n</code></pre>"},{"location":"refs/transformer/#startorch.transformer.Clamp","title":"startorch.transformer.Clamp","text":"<p>               Bases: <code>BaseTensorTransformer</code></p> <p>Implement a tensor transformer to generate tensors where the values are clamped.</p> <p>Note: <code>min</code> and <code>max</code> cannot be both <code>None</code>.</p> <p>Parameters:</p> Name Type Description Default <code>input</code> <code>str</code> <p>The key that contains the input tensor.</p> required <code>output</code> <code>str</code> <p>The key that contains the output tensor.</p> required <code>min</code> <code>float | None</code> <p>The lower bound. If <code>min</code> is <code>None</code>, there is no lower bound.</p> required <code>max</code> <code>float | None</code> <p>The upper bound. If <code>max</code> is  <code>None</code>, there is no upper bound.</p> required <code>exist_ok</code> <code>bool</code> <p>If <code>False</code>, an exception is raised if the output key already exists. Otherwise, the value associated to the output key is updated.</p> <code>False</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>if both <code>min</code> and <code>max</code> are <code>None</code></p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; from startorch.transformer import Clamp\n&gt;&gt;&gt; transformer = Clamp(input=\"input\", output=\"output\", min=-2.0, max=2.0)\n&gt;&gt;&gt; transformer\nClampTransformer(input=input, output=output, min=-2.0, max=2.0, exist_ok=False)\n&gt;&gt;&gt; data = {\"input\": torch.tensor([[1.0, -2.0, 3.0], [-4.0, 5.0, -6.0]])}\n&gt;&gt;&gt; out = transformer.transform(data)\n&gt;&gt;&gt; out\n{'input': tensor([[ 1., -2.,  3.],\n                  [-4.,  5., -6.]]),\n 'output': tensor([[ 1., -2.,  2.],\n                   [-2.,  2., -2.]])}\n</code></pre>"},{"location":"refs/transformer/#startorch.transformer.ClampTransformer","title":"startorch.transformer.ClampTransformer","text":"<p>               Bases: <code>BaseTensorTransformer</code></p> <p>Implement a tensor transformer to generate tensors where the values are clamped.</p> <p>Note: <code>min</code> and <code>max</code> cannot be both <code>None</code>.</p> <p>Parameters:</p> Name Type Description Default <code>input</code> <code>str</code> <p>The key that contains the input tensor.</p> required <code>output</code> <code>str</code> <p>The key that contains the output tensor.</p> required <code>min</code> <code>float | None</code> <p>The lower bound. If <code>min</code> is <code>None</code>, there is no lower bound.</p> required <code>max</code> <code>float | None</code> <p>The upper bound. If <code>max</code> is  <code>None</code>, there is no upper bound.</p> required <code>exist_ok</code> <code>bool</code> <p>If <code>False</code>, an exception is raised if the output key already exists. Otherwise, the value associated to the output key is updated.</p> <code>False</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>if both <code>min</code> and <code>max</code> are <code>None</code></p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; from startorch.transformer import Clamp\n&gt;&gt;&gt; transformer = Clamp(input=\"input\", output=\"output\", min=-2.0, max=2.0)\n&gt;&gt;&gt; transformer\nClampTransformer(input=input, output=output, min=-2.0, max=2.0, exist_ok=False)\n&gt;&gt;&gt; data = {\"input\": torch.tensor([[1.0, -2.0, 3.0], [-4.0, 5.0, -6.0]])}\n&gt;&gt;&gt; out = transformer.transform(data)\n&gt;&gt;&gt; out\n{'input': tensor([[ 1., -2.,  3.],\n                  [-4.,  5., -6.]]),\n 'output': tensor([[ 1., -2.,  2.],\n                   [-2.,  2., -2.]])}\n</code></pre>"},{"location":"refs/transformer/#startorch.transformer.Cosh","title":"startorch.transformer.Cosh","text":"<p>               Bases: <code>BaseTensorTransformer</code></p> <p>Implement a tensor transformer that computes the hyperbolic cosine (cosh) of each value.</p> <p>Parameters:</p> Name Type Description Default <code>input</code> <code>str</code> <p>The key that contains the input tensor.</p> required <code>output</code> <code>str</code> <p>The key that contains the output tensor.</p> required <code>exist_ok</code> <code>bool</code> <p>If <code>False</code>, an exception is raised if the output key already exists. Otherwise, the value associated to the output key is updated.</p> <code>False</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; from startorch.transformer import Cosh\n&gt;&gt;&gt; transformer = Cosh(input=\"input\", output=\"output\")\n&gt;&gt;&gt; transformer\nCoshTransformer(input=input, output=output, exist_ok=False)\n&gt;&gt;&gt; data = {'input': torch.tensor([[1.0, 2.0, 3.0], [4.0, 4.5, 6.0]])}\n&gt;&gt;&gt; out = transformer.transform(data)\n&gt;&gt;&gt; out\n{'input': tensor([[1.0000, 2.0000, 3.0000],\n                  [4.0000, 4.5000, 6.0000]]),\n 'output': tensor([[  1.5431,   3.7622,  10.0677],\n                   [ 27.3082,  45.0141, 201.7156]])}\n</code></pre>"},{"location":"refs/transformer/#startorch.transformer.CoshTransformer","title":"startorch.transformer.CoshTransformer","text":"<p>               Bases: <code>BaseTensorTransformer</code></p> <p>Implement a tensor transformer that computes the hyperbolic cosine (cosh) of each value.</p> <p>Parameters:</p> Name Type Description Default <code>input</code> <code>str</code> <p>The key that contains the input tensor.</p> required <code>output</code> <code>str</code> <p>The key that contains the output tensor.</p> required <code>exist_ok</code> <code>bool</code> <p>If <code>False</code>, an exception is raised if the output key already exists. Otherwise, the value associated to the output key is updated.</p> <code>False</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; from startorch.transformer import Cosh\n&gt;&gt;&gt; transformer = Cosh(input=\"input\", output=\"output\")\n&gt;&gt;&gt; transformer\nCoshTransformer(input=input, output=output, exist_ok=False)\n&gt;&gt;&gt; data = {'input': torch.tensor([[1.0, 2.0, 3.0], [4.0, 4.5, 6.0]])}\n&gt;&gt;&gt; out = transformer.transform(data)\n&gt;&gt;&gt; out\n{'input': tensor([[1.0000, 2.0000, 3.0000],\n                  [4.0000, 4.5000, 6.0000]]),\n 'output': tensor([[  1.5431,   3.7622,  10.0677],\n                   [ 27.3082,  45.0141, 201.7156]])}\n</code></pre>"},{"location":"refs/transformer/#startorch.transformer.Exponential","title":"startorch.transformer.Exponential","text":"<p>               Bases: <code>BaseTensorTransformer</code></p> <p>Implement a tensor transformer that samples values from an Exponential distribution.</p> <p>The input must be a sequence of tensors with a single item. This tensor is interpreted as the rate parameters of the Exponential distribution.</p> <p>Parameters:</p> Name Type Description Default <code>rate</code> <code>str</code> <p>The key that contains the rate values of the Exponential distribution.</p> required <code>output</code> <code>str</code> <p>The key that contains the output values sampled from the Exponential distribution.</p> required <code>exist_ok</code> <code>bool</code> <p>If <code>False</code>, an exception is raised if the output key already exists. Otherwise, the value associated to the output key is updated.</p> <code>False</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; from startorch.transformer import Exponential\n&gt;&gt;&gt; transformer = Exponential(rate=\"rate\", output=\"output\")\n&gt;&gt;&gt; transformer\nExponentialTransformer(rate=rate, output=output, exist_ok=False)\n&gt;&gt;&gt; data = {\"rate\": torch.tensor([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])}\n&gt;&gt;&gt; out = transformer.transform(data)\n&gt;&gt;&gt; out\n{'rate': tensor([[1., 2., 3.],\n                 [4., 5., 6.]]),\n 'output': tensor([[...]])}\n</code></pre>"},{"location":"refs/transformer/#startorch.transformer.ExponentialTransformer","title":"startorch.transformer.ExponentialTransformer","text":"<p>               Bases: <code>BaseTensorTransformer</code></p> <p>Implement a tensor transformer that samples values from an Exponential distribution.</p> <p>The input must be a sequence of tensors with a single item. This tensor is interpreted as the rate parameters of the Exponential distribution.</p> <p>Parameters:</p> Name Type Description Default <code>rate</code> <code>str</code> <p>The key that contains the rate values of the Exponential distribution.</p> required <code>output</code> <code>str</code> <p>The key that contains the output values sampled from the Exponential distribution.</p> required <code>exist_ok</code> <code>bool</code> <p>If <code>False</code>, an exception is raised if the output key already exists. Otherwise, the value associated to the output key is updated.</p> <code>False</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; from startorch.transformer import Exponential\n&gt;&gt;&gt; transformer = Exponential(rate=\"rate\", output=\"output\")\n&gt;&gt;&gt; transformer\nExponentialTransformer(rate=rate, output=output, exist_ok=False)\n&gt;&gt;&gt; data = {\"rate\": torch.tensor([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])}\n&gt;&gt;&gt; out = transformer.transform(data)\n&gt;&gt;&gt; out\n{'rate': tensor([[1., 2., 3.],\n                 [4., 5., 6.]]),\n 'output': tensor([[...]])}\n</code></pre>"},{"location":"refs/transformer/#startorch.transformer.Identity","title":"startorch.transformer.Identity","text":"<p>               Bases: <code>BaseTransformer</code></p> <p>Implement the identity transformation.</p> <p>Parameters:</p> Name Type Description Default <code>copy</code> <code>bool</code> <p>If <code>True</code>, it returns a copy of the input tensor, otherwise it returns the input tensor.</p> <code>True</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; from startorch.transformer import Identity\n&gt;&gt;&gt; transformer = Identity()\n&gt;&gt;&gt; transformer\nIdentityTransformer(copy=True)\n&gt;&gt;&gt; data = {\"key\": torch.tensor([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])}\n&gt;&gt;&gt; out = transformer.transform(data)\n&gt;&gt;&gt; out\n{'key': tensor([[1., 2., 3.],\n                [4., 5., 6.]])}\n</code></pre>"},{"location":"refs/transformer/#startorch.transformer.IdentityTransformer","title":"startorch.transformer.IdentityTransformer","text":"<p>               Bases: <code>BaseTransformer</code></p> <p>Implement the identity transformation.</p> <p>Parameters:</p> Name Type Description Default <code>copy</code> <code>bool</code> <p>If <code>True</code>, it returns a copy of the input tensor, otherwise it returns the input tensor.</p> <code>True</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; from startorch.transformer import Identity\n&gt;&gt;&gt; transformer = Identity()\n&gt;&gt;&gt; transformer\nIdentityTransformer(copy=True)\n&gt;&gt;&gt; data = {\"key\": torch.tensor([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])}\n&gt;&gt;&gt; out = transformer.transform(data)\n&gt;&gt;&gt; out\n{'key': tensor([[1., 2., 3.],\n                [4., 5., 6.]])}\n</code></pre>"},{"location":"refs/transformer/#startorch.transformer.LookupTable","title":"startorch.transformer.LookupTable","text":"<p>               Bases: <code>BaseTensorTransformer</code></p> <p>Implement a tensor transformer that replaces indices by values from the lookup table.</p> <p>Parameters:</p> Name Type Description Default <code>weights</code> <code>Tensor</code> <p>The weights of the lookup table.</p> required <code>index</code> <code>str</code> <p>The key that contains the input indices of the lookup table. The tensor must be of long data type.</p> required <code>output</code> <code>str</code> <p>The key that contains the output values from the lookup  table.</p> required <code>exist_ok</code> <code>bool</code> <p>If <code>False</code>, an exception is raised if the output key already exists. Otherwise, the value associated to the output key is updated.</p> <code>False</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; from startorch.transformer import LookupTable\n&gt;&gt;&gt; transformer = LookupTable(\n...     weights=torch.tensor([5.0, 4.0, 3.0, 2.0, 1.0, 0.0]), index=\"index\", output=\"output\"\n... )\n&gt;&gt;&gt; transformer\nLookupTableTransformer(size=6, index=index, output=output, exist_ok=False)\n&gt;&gt;&gt; data = {\"index\": torch.tensor([[1, 2, 3], [4, 0, 2]])}\n&gt;&gt;&gt; out = transformer.transform(data)\n&gt;&gt;&gt; out\n{'index': tensor([[1, 2, 3], [4, 0, 2]]), 'output': tensor([[4., 3., 2.], [1., 5., 3.]])}\n</code></pre>"},{"location":"refs/transformer/#startorch.transformer.LookupTableTransformer","title":"startorch.transformer.LookupTableTransformer","text":"<p>               Bases: <code>BaseTensorTransformer</code></p> <p>Implement a tensor transformer that replaces indices by values from the lookup table.</p> <p>Parameters:</p> Name Type Description Default <code>weights</code> <code>Tensor</code> <p>The weights of the lookup table.</p> required <code>index</code> <code>str</code> <p>The key that contains the input indices of the lookup table. The tensor must be of long data type.</p> required <code>output</code> <code>str</code> <p>The key that contains the output values from the lookup  table.</p> required <code>exist_ok</code> <code>bool</code> <p>If <code>False</code>, an exception is raised if the output key already exists. Otherwise, the value associated to the output key is updated.</p> <code>False</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; from startorch.transformer import LookupTable\n&gt;&gt;&gt; transformer = LookupTable(\n...     weights=torch.tensor([5.0, 4.0, 3.0, 2.0, 1.0, 0.0]), index=\"index\", output=\"output\"\n... )\n&gt;&gt;&gt; transformer\nLookupTableTransformer(size=6, index=index, output=output, exist_ok=False)\n&gt;&gt;&gt; data = {\"index\": torch.tensor([[1, 2, 3], [4, 0, 2]])}\n&gt;&gt;&gt; out = transformer.transform(data)\n&gt;&gt;&gt; out\n{'index': tensor([[1, 2, 3], [4, 0, 2]]), 'output': tensor([[4., 3., 2.], [1., 5., 3.]])}\n</code></pre>"},{"location":"refs/transformer/#startorch.transformer.Poisson","title":"startorch.transformer.Poisson","text":"<p>               Bases: <code>BaseTensorTransformer</code></p> <p>Implement a tensor transformer that samples values from a Poisson distribution.</p> <p>The input must be a sequence of tensors with a single item. This tensor is interpreted as the rate parameters of the Poisson distribution.</p> <p>Parameters:</p> Name Type Description Default <code>rate</code> <code>str</code> <p>The key that contains the rate values of the Poisson distribution.</p> required <code>output</code> <code>str</code> <p>The key that contains the output values sampled from the Poisson distribution.</p> required <code>exist_ok</code> <code>bool</code> <p>If <code>False</code>, an exception is raised if the output key already exists. Otherwise, the value associated to the output key is updated.</p> <code>False</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; from startorch.transformer import Poisson\n&gt;&gt;&gt; transformer = Poisson(rate=\"rate\", output=\"output\")\n&gt;&gt;&gt; transformer\nPoissonTransformer(rate=rate, output=output, exist_ok=False)\n&gt;&gt;&gt; data = {\"rate\": torch.tensor([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])}\n&gt;&gt;&gt; out = transformer.transform(data)\n&gt;&gt;&gt; out\n{'rate': tensor([[1., 2., 3.],\n                 [4., 5., 6.]]),\n 'output': tensor([[...]])}\n</code></pre>"},{"location":"refs/transformer/#startorch.transformer.PoissonTransformer","title":"startorch.transformer.PoissonTransformer","text":"<p>               Bases: <code>BaseTensorTransformer</code></p> <p>Implement a tensor transformer that samples values from a Poisson distribution.</p> <p>The input must be a sequence of tensors with a single item. This tensor is interpreted as the rate parameters of the Poisson distribution.</p> <p>Parameters:</p> Name Type Description Default <code>rate</code> <code>str</code> <p>The key that contains the rate values of the Poisson distribution.</p> required <code>output</code> <code>str</code> <p>The key that contains the output values sampled from the Poisson distribution.</p> required <code>exist_ok</code> <code>bool</code> <p>If <code>False</code>, an exception is raised if the output key already exists. Otherwise, the value associated to the output key is updated.</p> <code>False</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; from startorch.transformer import Poisson\n&gt;&gt;&gt; transformer = Poisson(rate=\"rate\", output=\"output\")\n&gt;&gt;&gt; transformer\nPoissonTransformer(rate=rate, output=output, exist_ok=False)\n&gt;&gt;&gt; data = {\"rate\": torch.tensor([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])}\n&gt;&gt;&gt; out = transformer.transform(data)\n&gt;&gt;&gt; out\n{'rate': tensor([[1., 2., 3.],\n                 [4., 5., 6.]]),\n 'output': tensor([[...]])}\n</code></pre>"},{"location":"refs/transformer/#startorch.transformer.Sequential","title":"startorch.transformer.Sequential","text":"<p>               Bases: <code>BaseTransformer</code></p> <p>Implement a transformer that sequentially computes transformations.</p> <p>Parameters:</p> Name Type Description Default <code>transformers</code> <code>Sequence[BaseTransformer | dict]</code> <p>The sequence of transformers or their configurations.</p> required <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; from startorch.transformer import Sequential, Abs, Clamp\n&gt;&gt;&gt; transformer = Sequential(\n...     [\n...         Abs(input=\"input\", output=\"output1\"),\n...         Clamp(input=\"input\", output=\"output2\", min=-1, max=2),\n...     ]\n... )\n&gt;&gt;&gt; transformer\nSequentialTransformer(\n  (0): AbsTransformer(input=input, output=output1, exist_ok=False)\n  (1): ClampTransformer(input=input, output=output2, min=-1, max=2, exist_ok=False)\n)\n&gt;&gt;&gt; data = {\"input\": torch.tensor([[1.0, -2.0, 3.0], [-4.0, 5.0, -6.0]])}\n&gt;&gt;&gt; out = transformer.transform(data)\n&gt;&gt;&gt; out\n{'input': tensor([[ 1., -2.,  3.],\n                  [-4.,  5., -6.]]),\n 'output1': tensor([[1., 2., 3.],\n                    [4., 5., 6.]]),\n 'output2': tensor([[ 1., -1.,  2.],\n                    [-1.,  2., -1.]])}\n</code></pre>"},{"location":"refs/transformer/#startorch.transformer.SequentialTransformer","title":"startorch.transformer.SequentialTransformer","text":"<p>               Bases: <code>BaseTransformer</code></p> <p>Implement a transformer that sequentially computes transformations.</p> <p>Parameters:</p> Name Type Description Default <code>transformers</code> <code>Sequence[BaseTransformer | dict]</code> <p>The sequence of transformers or their configurations.</p> required <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; from startorch.transformer import Sequential, Abs, Clamp\n&gt;&gt;&gt; transformer = Sequential(\n...     [\n...         Abs(input=\"input\", output=\"output1\"),\n...         Clamp(input=\"input\", output=\"output2\", min=-1, max=2),\n...     ]\n... )\n&gt;&gt;&gt; transformer\nSequentialTransformer(\n  (0): AbsTransformer(input=input, output=output1, exist_ok=False)\n  (1): ClampTransformer(input=input, output=output2, min=-1, max=2, exist_ok=False)\n)\n&gt;&gt;&gt; data = {\"input\": torch.tensor([[1.0, -2.0, 3.0], [-4.0, 5.0, -6.0]])}\n&gt;&gt;&gt; out = transformer.transform(data)\n&gt;&gt;&gt; out\n{'input': tensor([[ 1., -2.,  3.],\n                  [-4.,  5., -6.]]),\n 'output1': tensor([[1., 2., 3.],\n                    [4., 5., 6.]]),\n 'output2': tensor([[ 1., -1.,  2.],\n                    [-1.,  2., -1.]])}\n</code></pre>"},{"location":"refs/transformer/#startorch.transformer.Sinh","title":"startorch.transformer.Sinh","text":"<p>               Bases: <code>BaseTensorTransformer</code></p> <p>Implement a tensor transformer that computes the hyperbolic sine (sinh) of each value.</p> <p>Parameters:</p> Name Type Description Default <code>input</code> <code>str</code> <p>The key that contains the input tensor.</p> required <code>output</code> <code>str</code> <p>The key that contains the output tensor.</p> required <code>exist_ok</code> <code>bool</code> <p>If <code>False</code>, an exception is raised if the output key already exists. Otherwise, the value associated to the output key is updated.</p> <code>False</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; from startorch.transformer import Sinh\n&gt;&gt;&gt; transformer = Sinh(input=\"input\", output=\"output\")\n&gt;&gt;&gt; transformer\nSinhTransformer(input=input, output=output, exist_ok=False)\n&gt;&gt;&gt; data = {'input': torch.tensor([[0.0, 1.0, 2.0], [4.0, 5.0, 6.0]])}\n&gt;&gt;&gt; out = transformer.transform(data)\n&gt;&gt;&gt; out\n{'input': tensor([[0., 1., 2.],\n                  [4., 5., 6.]]),\n 'output': tensor([[  0.0000,   1.1752,   3.6269],\n                   [ 27.2899,  74.2032, 201.7132]])}\n</code></pre>"},{"location":"refs/transformer/#startorch.transformer.SinhTransformer","title":"startorch.transformer.SinhTransformer","text":"<p>               Bases: <code>BaseTensorTransformer</code></p> <p>Implement a tensor transformer that computes the hyperbolic sine (sinh) of each value.</p> <p>Parameters:</p> Name Type Description Default <code>input</code> <code>str</code> <p>The key that contains the input tensor.</p> required <code>output</code> <code>str</code> <p>The key that contains the output tensor.</p> required <code>exist_ok</code> <code>bool</code> <p>If <code>False</code>, an exception is raised if the output key already exists. Otherwise, the value associated to the output key is updated.</p> <code>False</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; from startorch.transformer import Sinh\n&gt;&gt;&gt; transformer = Sinh(input=\"input\", output=\"output\")\n&gt;&gt;&gt; transformer\nSinhTransformer(input=input, output=output, exist_ok=False)\n&gt;&gt;&gt; data = {'input': torch.tensor([[0.0, 1.0, 2.0], [4.0, 5.0, 6.0]])}\n&gt;&gt;&gt; out = transformer.transform(data)\n&gt;&gt;&gt; out\n{'input': tensor([[0., 1., 2.],\n                  [4., 5., 6.]]),\n 'output': tensor([[  0.0000,   1.1752,   3.6269],\n                   [ 27.2899,  74.2032, 201.7132]])}\n</code></pre>"},{"location":"refs/transformer/#startorch.transformer.Tanh","title":"startorch.transformer.Tanh","text":"<p>               Bases: <code>BaseTensorTransformer</code></p> <p>Implement a tensor transformer that computes the hyperbolic tangent (tanh) of each value.</p> <p>Parameters:</p> Name Type Description Default <code>input</code> <code>str</code> <p>The key that contains the input tensor.</p> required <code>output</code> <code>str</code> <p>The key that contains the output tensor.</p> required <code>exist_ok</code> <code>bool</code> <p>If <code>False</code>, an exception is raised if the output key already exists. Otherwise, the value associated to the output key is updated.</p> <code>False</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; from startorch.transformer import Tanh\n&gt;&gt;&gt; transformer = Tanh(input=\"input\", output=\"output\")\n&gt;&gt;&gt; transformer\nTanhTransformer(input=input, output=output, exist_ok=False)\n&gt;&gt;&gt; data = {\"input\": torch.tensor([[0.0, 1.0, 2.0], [4.0, 5.0, 6.0]])}\n&gt;&gt;&gt; out = transformer.transform(data)\n&gt;&gt;&gt; out\n{'input': tensor([[0., 1., 2.],\n                  [4., 5., 6.]]),\n 'output': tensor([[0.0000, 0.7616, 0.9640],\n                   [0.9993, 0.9999, 1.0000]])}\n</code></pre>"},{"location":"refs/transformer/#startorch.transformer.TanhTransformer","title":"startorch.transformer.TanhTransformer","text":"<p>               Bases: <code>BaseTensorTransformer</code></p> <p>Implement a tensor transformer that computes the hyperbolic tangent (tanh) of each value.</p> <p>Parameters:</p> Name Type Description Default <code>input</code> <code>str</code> <p>The key that contains the input tensor.</p> required <code>output</code> <code>str</code> <p>The key that contains the output tensor.</p> required <code>exist_ok</code> <code>bool</code> <p>If <code>False</code>, an exception is raised if the output key already exists. Otherwise, the value associated to the output key is updated.</p> <code>False</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; from startorch.transformer import Tanh\n&gt;&gt;&gt; transformer = Tanh(input=\"input\", output=\"output\")\n&gt;&gt;&gt; transformer\nTanhTransformer(input=input, output=output, exist_ok=False)\n&gt;&gt;&gt; data = {\"input\": torch.tensor([[0.0, 1.0, 2.0], [4.0, 5.0, 6.0]])}\n&gt;&gt;&gt; out = transformer.transform(data)\n&gt;&gt;&gt; out\n{'input': tensor([[0., 1., 2.],\n                  [4., 5., 6.]]),\n 'output': tensor([[0.0000, 0.7616, 0.9640],\n                   [0.9993, 0.9999, 1.0000]])}\n</code></pre>"},{"location":"refs/transformer/#startorch.transformer.is_transformer_config","title":"startorch.transformer.is_transformer_config","text":"<pre><code>is_transformer_config(config: dict) -&gt; bool\n</code></pre> <p>Indicate if the input configuration is a configuration for a <code>BaseTransformer</code>.</p> <p>This function only checks if the value of the key  <code>_target_</code> is valid. It does not check the other values. If <code>_target_</code> indicates a function, the returned type hint is used to check the class.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>dict</code> <p>The configuration to check.</p> required <p>Returns:</p> Type Description <code>bool</code> <p><code>True</code> if the input configuration is a configuration for a <code>BaseTransformer</code> object.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.transformer import is_transformer_config\n&gt;&gt;&gt; is_transformer_config({\"_target_\": \"startorch.transformer.Identity\"})\nTrue\n</code></pre>"},{"location":"refs/transformer/#startorch.transformer.setup_transformer","title":"startorch.transformer.setup_transformer","text":"<pre><code>setup_transformer(\n    transformer: BaseTransformer | dict,\n) -&gt; BaseTransformer\n</code></pre> <p>Set up a tensor transformer.</p> <p>The tensor transformer is instantiated from its configuration by using the <code>BaseTransformer</code> factory function.</p> <p>Parameters:</p> Name Type Description Default <code>transformer</code> <code>BaseTransformer | dict</code> <p>A tensor transformer or its configuration.</p> required <p>Returns:</p> Type Description <code>BaseTransformer</code> <p>A tensor transformer.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.transformer import setup_transformer\n&gt;&gt;&gt; setup_transformer({\"_target_\": \"startorch.transformer.Identity\"})\nIdentityTransformer(copy=True)\n</code></pre>"},{"location":"refs/utils/","title":"utils","text":""},{"location":"refs/utils/#startorch.utils","title":"startorch.utils","text":"<p>Contain utility functions.</p>"},{"location":"refs/utils/#startorch.utils.batch","title":"startorch.utils.batch","text":"<p>Contain utility functions for batches.</p>"},{"location":"refs/utils/#startorch.utils.batch.scale_batch","title":"startorch.utils.batch.scale_batch","text":"<pre><code>scale_batch(\n    batch: Tensor, scale: str = \"identity\"\n) -&gt; Tensor\n</code></pre> <p>Scale a batch.</p> <p>Parameters:</p> Name Type Description Default <code>batch</code> <code>Tensor</code> <p>The batch to scale.</p> required <code>scale</code> <code>str</code> <p>The scaling transformation.</p> <code>'identity'</code> <p>Returns:</p> Type Description <code>Tensor</code> <p>The scaled batch.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; from startorch.utils.batch import scale_batch\n&gt;&gt;&gt; batch = torch.arange(10).view(2, 5)\n&gt;&gt;&gt; scale_batch(batch, scale=\"asinh\")\ntensor([[0.0000, 0.8814, 1.4436, 1.8184, 2.0947],\n        [2.3124, 2.4918, 2.6441, 2.7765, 2.8934]])\n</code></pre>"},{"location":"refs/utils/#startorch.utils.conversion","title":"startorch.utils.conversion","text":"<p>Contain utility functions to convert objects.</p>"},{"location":"refs/utils/#startorch.utils.conversion.to_array","title":"startorch.utils.conversion.to_array","text":"<pre><code>to_array(data: Sequence | Tensor | ndarray) -&gt; ndarray\n</code></pre> <p>Convert the input to a <code>numpy.ndarray</code>.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>Sequence | Tensor | ndarray</code> <p>The data to convert to an array.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>A NumPy array.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.utils.conversion import to_array\n&gt;&gt;&gt; x = to_array([1, 2, 3, 4, 5])\n&gt;&gt;&gt; x\narray([1, 2, 3, 4, 5])\n</code></pre>"},{"location":"refs/utils/#startorch.utils.conversion.to_tensor","title":"startorch.utils.conversion.to_tensor","text":"<pre><code>to_tensor(data: Tensor | ndarray | Sequence) -&gt; Tensor\n</code></pre> <p>Convert the input to a <code>torch.Tensor</code>.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>Tensor | ndarray | Sequence</code> <p>The data to convert to a tensor.</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>A tensor.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.utils.conversion import to_tensor\n&gt;&gt;&gt; x = to_tensor([1, 2, 3, 4, 5])\n&gt;&gt;&gt; x\ntensor([1, 2, 3, 4, 5])\n</code></pre>"},{"location":"refs/utils/#startorch.utils.conversion.to_tuple","title":"startorch.utils.conversion.to_tuple","text":"<pre><code>to_tuple(value: Any) -&gt; tuple\n</code></pre> <p>Convert a value to a tuple.</p> <p>This function is a no-op if the input is a tuple.</p> <p>Parameters:</p> Name Type Description Default <code>value</code> <code>Any</code> <p>The value to convert.</p> required <p>Returns:</p> Type Description <code>tuple</code> <p>The input value in a tuple.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.utils.conversion import to_tuple\n&gt;&gt;&gt; to_tuple(1)\n(1,)\n&gt;&gt;&gt; to_tuple(\"abc\")\n('abc',)\n</code></pre>"},{"location":"refs/utils/#startorch.utils.format","title":"startorch.utils.format","text":"<p>Contain utility functions to format strings.</p>"},{"location":"refs/utils/#startorch.utils.format.str_target_object","title":"startorch.utils.format.str_target_object","text":"<pre><code>str_target_object(config: dict) -&gt; str\n</code></pre> <p>Get a string that indicates the target object in the config.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>dict</code> <p>A config using the <code>object_factory</code> library. This dict is expected to have a key <code>'_target_'</code> to indicate the target object.</p> required <p>Returns:</p> Type Description <code>str</code> <p>A string with the target object.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.utils.format import str_target_object\n&gt;&gt;&gt; str_target_object({OBJECT_TARGET: \"something.MyClass\"})\n[_target_: something.MyClass]\n&gt;&gt;&gt; str_target_object({})\n[_target_: N/A]\n</code></pre>"},{"location":"refs/utils/#startorch.utils.format.str_weighted_modules","title":"startorch.utils.format.str_weighted_modules","text":"<pre><code>str_weighted_modules(\n    modules: Sequence,\n    weights: Sequence,\n    num_spaces: int = 2,\n) -&gt; str\n</code></pre> <p>Compute a pretty representation of a sequence of modules where each module is associated to a weight.</p> <p>Parameters:</p> Name Type Description Default <code>modules</code> <code>Sequence</code> <p>The modules.</p> required <code>weights</code> <code>Sequence</code> <p>The weights. The <code>weights</code> should have the same length that <code>modules</code>.</p> required <code>num_spaces</code> <code>int</code> <p>The number of spaces used for the indentation.</p> <code>2</code> <p>Returns:</p> Type Description <code>str</code> <p>The string representation of the modules.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.utils.format import str_weighted_modules\n&gt;&gt;&gt; print(str_weighted_modules(modules=[\"abc\", \"something\\nelse\"], weights=[1, 2]))\n(0) [weight=1] abc\n(1) [weight=2] something\n  else\n</code></pre>"},{"location":"refs/utils/#startorch.utils.imports","title":"startorch.utils.imports","text":"<p>Implement some utility functions to manage optional dependencies.</p>"},{"location":"refs/utils/#startorch.utils.imports.check_iden","title":"startorch.utils.imports.check_iden","text":"<pre><code>check_iden() -&gt; None\n</code></pre> <p>Check if the <code>iden</code> package is installed.</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>if the <code>iden</code> package is not installed.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.utils.imports import check_iden\n&gt;&gt;&gt; check_iden()\n</code></pre>"},{"location":"refs/utils/#startorch.utils.imports.check_matplotlib","title":"startorch.utils.imports.check_matplotlib","text":"<pre><code>check_matplotlib() -&gt; None\n</code></pre> <p>Check if the <code>matplotlib</code> package is installed.</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>if the <code>matplotlib</code> package is not installed.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.utils.imports import check_matplotlib\n&gt;&gt;&gt; check_matplotlib()\n</code></pre>"},{"location":"refs/utils/#startorch.utils.imports.check_plotly","title":"startorch.utils.imports.check_plotly","text":"<pre><code>check_plotly() -&gt; None\n</code></pre> <p>Check if the <code>plotly</code> package is installed.</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>if the <code>plotly</code> package is not installed.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.utils.imports import check_plotly\n&gt;&gt;&gt; check_plotly()\n</code></pre>"},{"location":"refs/utils/#startorch.utils.imports.is_iden_available","title":"startorch.utils.imports.is_iden_available","text":"<pre><code>is_iden_available() -&gt; bool\n</code></pre> <p>Indicate if the <code>iden</code> package is installed or not.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.utils.imports import is_iden_available\n&gt;&gt;&gt; is_iden_available()\n</code></pre>"},{"location":"refs/utils/#startorch.utils.imports.is_matplotlib_available","title":"startorch.utils.imports.is_matplotlib_available","text":"<pre><code>is_matplotlib_available() -&gt; bool\n</code></pre> <p>Indicate if the <code>matplotlib</code> package is installed or not.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.utils.imports import is_matplotlib_available\n&gt;&gt;&gt; is_matplotlib_available()\n</code></pre>"},{"location":"refs/utils/#startorch.utils.imports.is_plotly_available","title":"startorch.utils.imports.is_plotly_available","text":"<pre><code>is_plotly_available() -&gt; bool\n</code></pre> <p>Indicate if the <code>plotly</code> package is installed or not.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.utils.imports import is_plotly_available\n&gt;&gt;&gt; is_plotly_available()\n</code></pre>"},{"location":"refs/utils/#startorch.utils.tensor","title":"startorch.utils.tensor","text":"<p>Contain utility functions for PyTorch tensors.</p>"},{"location":"refs/utils/#startorch.utils.tensor.shapes_are_equal","title":"startorch.utils.tensor.shapes_are_equal","text":"<pre><code>shapes_are_equal(tensors: Sequence[Tensor]) -&gt; bool\n</code></pre> <p>Return <code>True</code> if the shapes of several tensors are equal, otherwise <code>False</code>.</p> <p>This method does not check the values or the data type of the tensors.</p> <p>Parameters:</p> Name Type Description Default <code>tensors</code> <code>Sequence[Tensor]</code> <p>The tensors to check.</p> required <p>Returns:</p> Type Description <code>bool</code> <p><code>True</code> if all the tensors have the same shape, otherwise <code>False</code>. By design, this function returns <code>False</code> if no tensor is provided.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; from startorch.utils.tensor import shapes_are_equal\n&gt;&gt;&gt; shapes_are_equal([torch.rand(2, 3), torch.rand(2, 3)])\nTrue\n&gt;&gt;&gt; shapes_are_equal([torch.rand(2, 3), torch.rand(2, 3, 1)])\nFalse\n</code></pre>"},{"location":"refs/utils/#startorch.utils.validation","title":"startorch.utils.validation","text":"<p>Contain utility functions to validate values.</p>"},{"location":"refs/utils/#startorch.utils.validation.check_feature_size","title":"startorch.utils.validation.check_feature_size","text":"<pre><code>check_feature_size(value: int | Any, low: int = 1) -&gt; None\n</code></pre> <p>Check if the given value is a valid feature size i.e. number of features.</p> <p>Parameters:</p> Name Type Description Default <code>value</code> <code>int | Any</code> <p>The value to check.</p> required <code>low</code> <code>int</code> <p>The minimum value (inclusive).</p> <code>1</code> <p>Raises:</p> Type Description <code>TypeError</code> <p>if the input is not an integer.</p> <code>RuntimeError</code> <p>if the value is not greater than 0</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; from startorch.utils.validation import check_feature_size\n&gt;&gt;&gt; check_feature_size(5)\n</code></pre>"},{"location":"refs/utils/#startorch.utils.validation.check_integer_ge","title":"startorch.utils.validation.check_integer_ge","text":"<pre><code>check_integer_ge(\n    value: int | Any, low: int, name: str\n) -&gt; None\n</code></pre> <p>Check if the given value is a valid positive integer.</p> <p>Parameters:</p> Name Type Description Default <code>value</code> <code>int | Any</code> <p>The value to check.</p> required <code>low</code> <code>int</code> <p>The minimum value (inclusive).</p> required <code>name</code> <code>str</code> <p>The variable name.</p> required <p>Raises:</p> Type Description <code>TypeError</code> <p>if the input is not an integer.</p> <code>RuntimeError</code> <p>if the value is not greater than 0</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; from startorch.utils.validation import check_integer_ge\n&gt;&gt;&gt; check_integer_ge(5, low=0, name=\"feature_size\")\n</code></pre>"},{"location":"refs/utils/#startorch.utils.validation.check_interval","title":"startorch.utils.validation.check_interval","text":"<pre><code>check_interval(\n    value: float | Any, low: float, high: float, name: str\n) -&gt; None\n</code></pre> <p>Check if the given value is an interval.</p> <p>Parameters:</p> Name Type Description Default <code>value</code> <code>float | Any</code> <p>The value to check.</p> required <code>low</code> <code>float</code> <p>The minimum value (inclusive).</p> required <code>high</code> <code>float</code> <p>The maximum value (exclusive).</p> required <code>name</code> <code>str</code> <p>The variable name.</p> required <p>Raises:</p> Type Description <code>TypeError</code> <p>if the input is not an integer or float.</p> <code>RuntimeError</code> <p>if the value is not in the interval</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; from startorch.utils.validation import check_interval\n&gt;&gt;&gt; check_interval(1, low=-1.0, high=2.0, name=\"my_variable\")\n</code></pre>"},{"location":"refs/utils/#startorch.utils.validation.check_num_examples","title":"startorch.utils.validation.check_num_examples","text":"<pre><code>check_num_examples(value: int | Any) -&gt; None\n</code></pre> <p>Check if the given value is a valid number of examples.</p> <p>Parameters:</p> Name Type Description Default <code>value</code> <code>int | Any</code> <p>The value to check.</p> required <p>Raises:</p> Type Description <code>TypeError</code> <p>if the input is not an integer.</p> <code>RuntimeError</code> <p>if the value is not greater than 0</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; from startorch.utils.validation import check_num_examples\n&gt;&gt;&gt; check_num_examples(5)\n</code></pre>"},{"location":"refs/utils/#startorch.utils.validation.check_std","title":"startorch.utils.validation.check_std","text":"<pre><code>check_std(value: float | Any, name: str = 'std') -&gt; None\n</code></pre> <p>Check if the given value is a valid standard deviation.</p> <p>Parameters:</p> Name Type Description Default <code>value</code> <code>float | Any</code> <p>The value to check.</p> required <code>name</code> <code>str</code> <p>The variable name.</p> <code>'std'</code> <p>Raises:</p> Type Description <code>TypeError</code> <p>if the input is not an integer or float.</p> <code>RuntimeError</code> <p>if the value is not greater than 0</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; from startorch.utils.validation import check_std\n&gt;&gt;&gt; check_std(1.2)\n</code></pre>"},{"location":"refs/utils/#startorch.utils.weight","title":"startorch.utils.weight","text":"<p>Contain utility functions to prepare weighted generators.</p>"},{"location":"refs/utils/#startorch.utils.weight.prepare_probabilities","title":"startorch.utils.weight.prepare_probabilities","text":"<pre><code>prepare_probabilities(\n    weights: Tensor | Sequence[float],\n) -&gt; Tensor\n</code></pre> <p>Convert un-normalized positive weights to probabilities.</p> <p>Parameters:</p> Name Type Description Default <code>weights</code> <code>Tensor | Sequence[float]</code> <p>The vector of weights associated to each category. The weights have to be positive. It must be a float tensor of shape <code>(num_categories,)</code> or a <code>Sequence</code>.</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>The vector of probability associated at each category. The output is a <code>torch.Tensor</code> of type float and shape <code>(num_categories,)</code></p> <p>Raises:</p> Type Description <code>ValueError</code> <p>if the weights are not valid.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.utils.weight import prepare_probabilities\n&gt;&gt;&gt; prepare_probabilities([1, 1, 1, 1])\ntensor([0.2500, 0.2500, 0.2500, 0.2500])\n</code></pre>"},{"location":"refs/utils/#startorch.utils.weight.prepare_weighted_generators","title":"startorch.utils.weight.prepare_weighted_generators","text":"<pre><code>prepare_weighted_generators(\n    generators: Sequence[dict],\n) -&gt; tuple[tuple[Any, ...], tuple[float, ...]]\n</code></pre> <p>Prepare the tensor generators.</p> <p>Each dictionary in the input tuple/list should have the following items:</p> <pre><code>- a key ``'generator'`` which indicates the tensor generator\n    or its configuration.\n- an optional key ``'weight'`` with a float value which\n    indicates the weight of the tensor generator.\n    If this key is absent, the weight is set to ``1.0``.\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>generators</code> <code>Sequence[dict]</code> <p>The tensor generators and their weights. See above to learn about the expected format.</p> required <p>Returns:</p> Type Description <code>tuple[tuple[Any, ...], tuple[float, ...]]</code> <p>A tuple with two items: - a tuple of generators or their configurations - a tuple of generator weights</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from startorch.utils.weight import prepare_weighted_generators\n&gt;&gt;&gt; from startorch.tensor import RandUniform, RandNormal\n&gt;&gt;&gt; prepare_weighted_generators(\n...     (\n...         {\"weight\": 2.0, \"generator\": RandUniform()},\n...         {\"weight\": 1.0, \"generator\": RandNormal()},\n...     )\n... )\n((RandUniformTensorGenerator(low=0.0, high=1.0), RandNormalTensorGenerator(mean=0.0, std=1.0)), (2.0, 1.0))\n</code></pre>"}]}