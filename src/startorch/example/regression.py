from __future__ import annotations

__all__ = ["make_normal_linear_regression", "get_uniform_weights"]


import torch
from redcat import BatchDict, BatchedTensor
from torch import Tensor

from startorch import constants as ct
from startorch.random import rand_normal, rand_uniform


def make_normal_linear_regression(
    num_examples: int = 100,
    feature_size: int = 100,
    noise_std: float = 0.0,
    weights: Tensor | None = None,
    bias: float = 0.0,
    generator: torch.Generator | None = None,
) -> BatchDict[BatchedTensor]:
    r"""Generates a regression dataset where the data are generated with
    an underlying linear model.

    The features are sampled from a Normal distribution.
    Then, the targets are generated by applying a random linear
    regression model.

    Args:
    ----
        num_examples (int, optional): Specifies the number of examples
            to generate. Default: ``100``
        feature_size (int, optional): Specifies the feature size i.e.
            the number of features. Default: ``100``
        noise_std (float, optional): Specifies the standard deviation
            of the Gaussian noise. Default: ``0.0``
        weights (``torch.Tensor`` or ``None``): Specifies the linear
            weights in the underlying linear model. Default: ``None``
        bias (float, optional): Specifies the bias term in the
            underlying linear model. Default: ``0.0``
        generator (``torch.Generator`` or ``None``, optional):
            Specifies an optional random generator. Default: ``None``

    Returns:
    -------
        ``BatchDict``: A batch with two items:
            - ``'input'``: a ``BatchedTensor`` of type float and
                shape ``(num_examples, feature_size)``. This
                tensor represents the input features.
            - ``'target'``: a ``BatchedTensor`` of type float and
                shape ``(num_examples,)``. This tensor represents
                the targets.

    Raises:
    ------
        RuntimeError if one of the parameters is not valid.

    Example usage:

    .. code-block:: pycon

        >>> from startorch.example import make_normal_linear_regression
        >>> batch = make_normal_linear_regression(num_examples=10)
        >>> batch
        BatchDict(
          (target): tensor([...], batch_dim=0)
          (feature): tensor([[...]], batch_dim=0)
        )
    """
    if num_examples < 1:
        raise RuntimeError(f"The number of examples ({num_examples}) has to be greater than 0")
    if feature_size < 1:
        raise RuntimeError(f"feature_size ({feature_size}) has to be greater than 0")
    if noise_std < 0:
        raise RuntimeError(
            f"The standard deviation of the Gaussian noise ({noise_std}) has to be "
            "greater or equal than 0"
        )
    if weights is None:
        weights = get_uniform_weights(
            feature_size=feature_size, informative_feature_size=feature_size, generator=generator
        )
    features = rand_normal(size=(num_examples, feature_size), generator=generator)
    targets = torch.mm(features, weights.view(feature_size, 1)) + bias
    if noise_std > 0.0:
        features += rand_normal(
            size=(num_examples, feature_size), std=noise_std, generator=generator
        )
    return BatchDict(
        {ct.TARGET: BatchedTensor(targets.flatten()), ct.FEATURE: BatchedTensor(features)}
    )


def get_uniform_weights(
    feature_size: int,
    informative_feature_size: int,
    generator: torch.Generator | None = None,
) -> Tensor:
    """Generates the weights of the linear combination used to generate
    the targets from the features.

    The weights of the informative features are sampled from a uniform
    distribution. The other weights are set to 0.
    This function was designed to be used with
    ``make_normal_regression``.

    Args:
    ----
        feature_size (int): Specifies the feature size i.e. the
            number of features.
        informative_feature_size (int): Specifies the number of
            informative features.
        generator (``torch.Generator`` or ``None``, optional):
            Specifies an optional random generator. Default: ``None``

    Returns:
    -------
        ``torch.Tensor``: The generated weights.

    Example usage:

    .. code-block:: pycon

        >>> from startorch.example.regression import get_uniform_weights
        >>> weights = get_uniform_weights(feature_size=10, informative_feature_size=5)
        >>> weights
        tensor([...])
    """
    informative_feature_size = min(feature_size, informative_feature_size)
    weights = torch.zeros(feature_size, 1)
    weights[:informative_feature_size, :] = 100 * rand_uniform(
        size=(informative_feature_size, 1), generator=generator
    )
    # TODO: add option to shuffle the weights
    return weights
